{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "360e08d3",
   "metadata": {
    "id": "360e08d3"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, SimpleRNN\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') \n",
    "import random\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70ac3668",
   "metadata": {
    "id": "70ac3668"
   },
   "outputs": [],
   "source": [
    "# pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8203d305",
   "metadata": {},
   "source": [
    "## RNN1 / window size 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a24d8ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome\n"
     ]
    }
   ],
   "source": [
    "# 전처리 모듈 import 후 train, test 데이터 프레임 불러오기\n",
    "\n",
    "import DataProcessing\n",
    "\n",
    "path = './'\n",
    "train_df, test_df = DataProcessing.processing(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f3f2b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27367, 96, 1) (27367, 336) (7992, 96, 1) (7992, 336) (8425, 96, 1) (8425, 336)\n"
     ]
    }
   ],
   "source": [
    "# window_size 설정 후 시계열 데이터 생성\n",
    "\n",
    "pre_day = 28 # (31 - pre_month) * 24 = windowsize /27 : 96//28 : 72//29 : 48//30 : 24//\n",
    "x_train, y_train, x_test, y_test, submission_x, submission_y = DataProcessing.data_form_descision(train_df, test_df, pre_day)\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape, submission_x.shape, submission_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c28d2632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_2 (SimpleRNN)    (None, 96, 64)            4224      \n",
      "                                                                 \n",
      " simple_rnn_3 (SimpleRNN)    (None, 32)                3104      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 336)               11088     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,608\n",
      "Trainable params: 22,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model 생성\n",
    "\n",
    "initializer = tf.keras.initializers.GlorotNormal(seed=15)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(64, activation='relu', input_shape=(x_train[0].shape), \n",
    "               return_sequences=True, kernel_initializer=initializer))\n",
    "model.add(SimpleRNN(32, activation='relu', kernel_initializer=initializer))\n",
    "model.add(Dense(64, activation='relu', kernel_initializer=initializer))\n",
    "model.add(Dense(32, activation='relu', kernel_initializer=initializer))\n",
    "model.add(Dense(336, activation='linear', kernel_initializer=initializer))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.00004)\n",
    "model.compile(loss='mae', optimizer=optimizer, metrics=['mae'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da5d69aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 44.4663 - mae: 44.4663\n",
      "Epoch 1: val_mae improved from inf to 35.68876, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 20s 11ms/step - loss: 44.4461 - mae: 44.4461 - val_loss: 35.6888 - val_mae: 35.6888\n",
      "Epoch 2/100\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 34.1480 - mae: 34.1480\n",
      "Epoch 2: val_mae improved from 35.68876 to 35.44551, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 34.1482 - mae: 34.1482 - val_loss: 35.4455 - val_mae: 35.4455\n",
      "Epoch 3/100\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 33.4653 - mae: 33.4653\n",
      "Epoch 3: val_mae improved from 35.44551 to 33.91630, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 33.4649 - mae: 33.4649 - val_loss: 33.9163 - val_mae: 33.9163\n",
      "Epoch 4/100\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 31.4520 - mae: 31.4520\n",
      "Epoch 4: val_mae improved from 33.91630 to 31.46778, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 31.4520 - mae: 31.4520 - val_loss: 31.4678 - val_mae: 31.4678\n",
      "Epoch 5/100\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 29.0481 - mae: 29.0481\n",
      "Epoch 5: val_mae improved from 31.46778 to 28.65073, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 29.0452 - mae: 29.0452 - val_loss: 28.6507 - val_mae: 28.6507\n",
      "Epoch 6/100\n",
      "1706/1711 [============================>.] - ETA: 0s - loss: 26.6068 - mae: 26.6068\n",
      "Epoch 6: val_mae improved from 28.65073 to 26.55347, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 26.6044 - mae: 26.6044 - val_loss: 26.5535 - val_mae: 26.5535\n",
      "Epoch 7/100\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 25.1453 - mae: 25.1453\n",
      "Epoch 7: val_mae improved from 26.55347 to 25.17487, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 25.1453 - mae: 25.1453 - val_loss: 25.1749 - val_mae: 25.1749\n",
      "Epoch 8/100\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 24.0792 - mae: 24.0792\n",
      "Epoch 8: val_mae improved from 25.17487 to 24.49022, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 24.0783 - mae: 24.0783 - val_loss: 24.4902 - val_mae: 24.4902\n",
      "Epoch 9/100\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 23.4385 - mae: 23.4385\n",
      "Epoch 9: val_mae improved from 24.49022 to 24.02306, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 23.4381 - mae: 23.4381 - val_loss: 24.0231 - val_mae: 24.0231\n",
      "Epoch 10/100\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 23.1762 - mae: 23.1762\n",
      "Epoch 10: val_mae improved from 24.02306 to 23.77567, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 23.1760 - mae: 23.1760 - val_loss: 23.7757 - val_mae: 23.7757\n",
      "Epoch 11/100\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 23.0782 - mae: 23.0782\n",
      "Epoch 11: val_mae did not improve from 23.77567\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 23.0782 - mae: 23.0782 - val_loss: 23.8176 - val_mae: 23.8176\n",
      "Epoch 12/100\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 23.0273 - mae: 23.0273\n",
      "Epoch 12: val_mae improved from 23.77567 to 23.60628, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 23.0274 - mae: 23.0274 - val_loss: 23.6063 - val_mae: 23.6063\n",
      "Epoch 13/100\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 22.9914 - mae: 22.9914\n",
      "Epoch 13: val_mae did not improve from 23.60628\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.9912 - mae: 22.9912 - val_loss: 23.6615 - val_mae: 23.6615\n",
      "Epoch 14/100\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 22.9567 - mae: 22.9567\n",
      "Epoch 14: val_mae did not improve from 23.60628\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.9564 - mae: 22.9564 - val_loss: 23.6387 - val_mae: 23.6387\n",
      "Epoch 15/100\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 22.9226 - mae: 22.9226\n",
      "Epoch 15: val_mae did not improve from 23.60628\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.9228 - mae: 22.9228 - val_loss: 23.6127 - val_mae: 23.6127\n",
      "Epoch 16/100\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 22.8921 - mae: 22.8921\n",
      "Epoch 16: val_mae improved from 23.60628 to 23.49737, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.8917 - mae: 22.8917 - val_loss: 23.4974 - val_mae: 23.4974\n",
      "Epoch 17/100\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 22.8587 - mae: 22.8587\n",
      "Epoch 17: val_mae did not improve from 23.49737\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.8587 - mae: 22.8587 - val_loss: 23.5286 - val_mae: 23.5286\n",
      "Epoch 18/100\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 22.8288 - mae: 22.8288\n",
      "Epoch 18: val_mae improved from 23.49737 to 23.41940, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 20s 11ms/step - loss: 22.8290 - mae: 22.8290 - val_loss: 23.4194 - val_mae: 23.4194\n",
      "Epoch 19/100\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 22.7890 - mae: 22.7890\n",
      "Epoch 19: val_mae did not improve from 23.41940\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.7890 - mae: 22.7890 - val_loss: 23.5212 - val_mae: 23.5212\n",
      "Epoch 20/100\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 22.7423 - mae: 22.7423\n",
      "Epoch 20: val_mae improved from 23.41940 to 23.38191, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.7424 - mae: 22.7424 - val_loss: 23.3819 - val_mae: 23.3819\n",
      "Epoch 21/100\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 22.7126 - mae: 22.7126\n",
      "Epoch 21: val_mae improved from 23.38191 to 23.30401, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 20s 11ms/step - loss: 22.7123 - mae: 22.7123 - val_loss: 23.3040 - val_mae: 23.3040\n",
      "Epoch 22/100\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 22.6684 - mae: 22.6684\n",
      "Epoch 22: val_mae improved from 23.30401 to 23.24812, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.6690 - mae: 22.6690 - val_loss: 23.2481 - val_mae: 23.2481\n",
      "Epoch 23/100\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 22.6264 - mae: 22.6264\n",
      "Epoch 23: val_mae did not improve from 23.24812\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.6261 - mae: 22.6261 - val_loss: 23.3891 - val_mae: 23.3891\n",
      "Epoch 24/100\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 22.5842 - mae: 22.5842\n",
      "Epoch 24: val_mae did not improve from 23.24812\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.5839 - mae: 22.5839 - val_loss: 23.2626 - val_mae: 23.2626\n",
      "Epoch 25/100\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 22.5325 - mae: 22.5325\n",
      "Epoch 25: val_mae improved from 23.24812 to 23.10704, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.5325 - mae: 22.5325 - val_loss: 23.1070 - val_mae: 23.1070\n",
      "Epoch 26/100\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 22.4826 - mae: 22.4826\n",
      "Epoch 26: val_mae did not improve from 23.10704\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.4824 - mae: 22.4824 - val_loss: 23.1177 - val_mae: 23.1177\n",
      "Epoch 27/100\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 22.4470 - mae: 22.4470\n",
      "Epoch 27: val_mae improved from 23.10704 to 23.04458, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.4471 - mae: 22.4471 - val_loss: 23.0446 - val_mae: 23.0446\n",
      "Epoch 28/100\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 22.4082 - mae: 22.4082\n",
      "Epoch 28: val_mae did not improve from 23.04458\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.4083 - mae: 22.4083 - val_loss: 23.0987 - val_mae: 23.0987\n",
      "Epoch 29/100\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 22.3604 - mae: 22.3604\n",
      "Epoch 29: val_mae improved from 23.04458 to 22.99884, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.3603 - mae: 22.3603 - val_loss: 22.9988 - val_mae: 22.9988\n",
      "Epoch 30/100\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 22.3237 - mae: 22.3237\n",
      "Epoch 30: val_mae did not improve from 22.99884\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.3238 - mae: 22.3238 - val_loss: 23.1276 - val_mae: 23.1276\n",
      "Epoch 31/100\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 22.2869 - mae: 22.2869\n",
      "Epoch 31: val_mae improved from 22.99884 to 22.96342, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.2870 - mae: 22.2870 - val_loss: 22.9634 - val_mae: 22.9634\n",
      "Epoch 32/100\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 22.2515 - mae: 22.2515\n",
      "Epoch 32: val_mae did not improve from 22.96342\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.2515 - mae: 22.2515 - val_loss: 23.1355 - val_mae: 23.1355\n",
      "Epoch 33/100\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 22.2174 - mae: 22.2174\n",
      "Epoch 33: val_mae improved from 22.96342 to 22.83941, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.2171 - mae: 22.2171 - val_loss: 22.8394 - val_mae: 22.8394\n",
      "Epoch 34/100\n",
      "1706/1711 [============================>.] - ETA: 0s - loss: 22.1872 - mae: 22.1872\n",
      "Epoch 34: val_mae improved from 22.83941 to 22.81422, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.1875 - mae: 22.1875 - val_loss: 22.8142 - val_mae: 22.8142\n",
      "Epoch 35/100\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 22.1553 - mae: 22.1553\n",
      "Epoch 35: val_mae improved from 22.81422 to 22.81052, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.1557 - mae: 22.1557 - val_loss: 22.8105 - val_mae: 22.8105\n",
      "Epoch 36/100\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 22.1333 - mae: 22.1333\n",
      "Epoch 36: val_mae improved from 22.81052 to 22.74471, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.1336 - mae: 22.1336 - val_loss: 22.7447 - val_mae: 22.7447\n",
      "Epoch 37/100\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 22.1068 - mae: 22.1068\n",
      "Epoch 37: val_mae did not improve from 22.74471\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.1069 - mae: 22.1069 - val_loss: 22.8103 - val_mae: 22.8103\n",
      "Epoch 38/100\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 22.0890 - mae: 22.0890\n",
      "Epoch 38: val_mae did not improve from 22.74471\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.0887 - mae: 22.0887 - val_loss: 22.8153 - val_mae: 22.8153\n",
      "Epoch 39/100\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 22.0605 - mae: 22.0605\n",
      "Epoch 39: val_mae improved from 22.74471 to 22.71981, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.0605 - mae: 22.0605 - val_loss: 22.7198 - val_mae: 22.7198\n",
      "Epoch 40/100\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 22.0437 - mae: 22.0437\n",
      "Epoch 40: val_mae did not improve from 22.71981\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.0438 - mae: 22.0438 - val_loss: 22.8707 - val_mae: 22.8707\n",
      "Epoch 41/100\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 22.0282 - mae: 22.0282\n",
      "Epoch 41: val_mae did not improve from 22.71981\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.0283 - mae: 22.0283 - val_loss: 22.7330 - val_mae: 22.7330\n",
      "Epoch 42/100\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 22.0116 - mae: 22.0116\n",
      "Epoch 42: val_mae improved from 22.71981 to 22.67953, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.0112 - mae: 22.0112 - val_loss: 22.6795 - val_mae: 22.6795\n",
      "Epoch 43/100\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 21.9927 - mae: 21.9927\n",
      "Epoch 43: val_mae did not improve from 22.67953\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.9928 - mae: 21.9928 - val_loss: 22.8263 - val_mae: 22.8263\n",
      "Epoch 44/100\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 21.9837 - mae: 21.9837\n",
      "Epoch 44: val_mae improved from 22.67953 to 22.63259, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.9837 - mae: 21.9837 - val_loss: 22.6326 - val_mae: 22.6326\n",
      "Epoch 45/100\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 21.9705 - mae: 21.9705\n",
      "Epoch 45: val_mae did not improve from 22.63259\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.9703 - mae: 21.9703 - val_loss: 22.7227 - val_mae: 22.7227\n",
      "Epoch 46/100\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 21.9505 - mae: 21.9505\n",
      "Epoch 46: val_mae improved from 22.63259 to 22.60793, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.9509 - mae: 21.9509 - val_loss: 22.6079 - val_mae: 22.6079\n",
      "Epoch 47/100\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 21.9478 - mae: 21.9478\n",
      "Epoch 47: val_mae did not improve from 22.60793\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.9478 - mae: 21.9478 - val_loss: 22.7150 - val_mae: 22.7150\n",
      "Epoch 48/100\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 21.9306 - mae: 21.9306\n",
      "Epoch 48: val_mae did not improve from 22.60793\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.9306 - mae: 21.9306 - val_loss: 22.9725 - val_mae: 22.9725\n",
      "Epoch 49/100\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 21.9227 - mae: 21.9227\n",
      "Epoch 49: val_mae did not improve from 22.60793\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.9228 - mae: 21.9228 - val_loss: 22.7846 - val_mae: 22.7846\n",
      "Epoch 50/100\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 21.9148 - mae: 21.9148\n",
      "Epoch 50: val_mae did not improve from 22.60793\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.9148 - mae: 21.9148 - val_loss: 22.6979 - val_mae: 22.6979\n",
      "Epoch 51/100\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 21.9076 - mae: 21.9076\n",
      "Epoch 51: val_mae improved from 22.60793 to 22.57082, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.9076 - mae: 21.9076 - val_loss: 22.5708 - val_mae: 22.5708\n",
      "Epoch 52/100\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 21.8922 - mae: 21.8922\n",
      "Epoch 52: val_mae improved from 22.57082 to 22.56944, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.8921 - mae: 21.8921 - val_loss: 22.5694 - val_mae: 22.5694\n",
      "Epoch 53/100\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 21.8855 - mae: 21.8855\n",
      "Epoch 53: val_mae improved from 22.56944 to 22.54024, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.8855 - mae: 21.8855 - val_loss: 22.5402 - val_mae: 22.5402\n",
      "Epoch 54/100\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 21.8861 - mae: 21.8861\n",
      "Epoch 54: val_mae improved from 22.54024 to 22.53179, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.8864 - mae: 21.8864 - val_loss: 22.5318 - val_mae: 22.5318\n",
      "Epoch 55/100\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 21.8796 - mae: 21.8796\n",
      "Epoch 55: val_mae did not improve from 22.53179\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.8796 - mae: 21.8796 - val_loss: 22.5628 - val_mae: 22.5628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 21.8593 - mae: 21.8593\n",
      "Epoch 56: val_mae did not improve from 22.53179\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.8594 - mae: 21.8594 - val_loss: 22.6363 - val_mae: 22.6363\n",
      "Epoch 57/100\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 21.8501 - mae: 21.8501\n",
      "Epoch 57: val_mae did not improve from 22.53179\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.8501 - mae: 21.8501 - val_loss: 22.5543 - val_mae: 22.5543\n",
      "Epoch 58/100\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 21.8498 - mae: 21.8498\n",
      "Epoch 58: val_mae did not improve from 22.53179\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.8498 - mae: 21.8498 - val_loss: 22.5509 - val_mae: 22.5509\n",
      "Epoch 59/100\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 21.8421 - mae: 21.8421\n",
      "Epoch 59: val_mae did not improve from 22.53179\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.8421 - mae: 21.8421 - val_loss: 22.6249 - val_mae: 22.6249\n",
      "Epoch 60/100\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 21.8305 - mae: 21.8305\n",
      "Epoch 60: val_mae did not improve from 22.53179\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.8305 - mae: 21.8305 - val_loss: 22.8833 - val_mae: 22.8833\n",
      "Epoch 61/100\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 21.8296 - mae: 21.8296\n",
      "Epoch 61: val_mae did not improve from 22.53179\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.8292 - mae: 21.8292 - val_loss: 22.5476 - val_mae: 22.5476\n",
      "Epoch 62/100\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 21.8220 - mae: 21.8220\n",
      "Epoch 62: val_mae improved from 22.53179 to 22.49915, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.8220 - mae: 21.8220 - val_loss: 22.4992 - val_mae: 22.4992\n",
      "Epoch 63/100\n",
      "1706/1711 [============================>.] - ETA: 0s - loss: 21.8097 - mae: 21.8097\n",
      "Epoch 63: val_mae did not improve from 22.49915\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.8103 - mae: 21.8103 - val_loss: 22.6074 - val_mae: 22.6074\n",
      "Epoch 64/100\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 21.8097 - mae: 21.8097\n",
      "Epoch 64: val_mae did not improve from 22.49915\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.8096 - mae: 21.8096 - val_loss: 22.5294 - val_mae: 22.5294\n",
      "Epoch 65/100\n",
      "1705/1711 [============================>.] - ETA: 0s - loss: 21.7956 - mae: 21.7956\n",
      "Epoch 65: val_mae did not improve from 22.49915\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.7957 - mae: 21.7957 - val_loss: 22.5681 - val_mae: 22.5681\n",
      "Epoch 66/100\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 21.7977 - mae: 21.7977\n",
      "Epoch 66: val_mae did not improve from 22.49915\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.7973 - mae: 21.7973 - val_loss: 22.6520 - val_mae: 22.6520\n",
      "Epoch 67/100\n",
      "1706/1711 [============================>.] - ETA: 0s - loss: 21.7859 - mae: 21.7859\n",
      "Epoch 67: val_mae did not improve from 22.49915\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.7859 - mae: 21.7859 - val_loss: 22.5486 - val_mae: 22.5486\n",
      "Epoch 68/100\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 21.7818 - mae: 21.7818\n",
      "Epoch 68: val_mae improved from 22.49915 to 22.49561, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.7819 - mae: 21.7819 - val_loss: 22.4956 - val_mae: 22.4956\n",
      "Epoch 69/100\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 21.7730 - mae: 21.7730\n",
      "Epoch 69: val_mae did not improve from 22.49561\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.7730 - mae: 21.7730 - val_loss: 22.5924 - val_mae: 22.5924\n",
      "Epoch 70/100\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 21.7664 - mae: 21.7664\n",
      "Epoch 70: val_mae did not improve from 22.49561\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.7664 - mae: 21.7664 - val_loss: 22.8366 - val_mae: 22.8366\n",
      "Epoch 71/100\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 21.7656 - mae: 21.7656\n",
      "Epoch 71: val_mae did not improve from 22.49561\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.7659 - mae: 21.7659 - val_loss: 22.5290 - val_mae: 22.5290\n",
      "Epoch 72/100\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 21.7579 - mae: 21.7579\n",
      "Epoch 72: val_mae did not improve from 22.49561\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.7578 - mae: 21.7578 - val_loss: 22.6303 - val_mae: 22.6303\n",
      "Epoch 73/100\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 21.7520 - mae: 21.7520\n",
      "Epoch 73: val_mae did not improve from 22.49561\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.7520 - mae: 21.7520 - val_loss: 22.6004 - val_mae: 22.6004\n",
      "Epoch 74/100\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 21.7506 - mae: 21.7506\n",
      "Epoch 74: val_mae improved from 22.49561 to 22.47991, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.7506 - mae: 21.7506 - val_loss: 22.4799 - val_mae: 22.4799\n",
      "Epoch 75/100\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 21.7362 - mae: 21.7362\n",
      "Epoch 75: val_mae improved from 22.47991 to 22.46074, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.7362 - mae: 21.7362 - val_loss: 22.4607 - val_mae: 22.4607\n",
      "Epoch 76/100\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 21.7312 - mae: 21.7312\n",
      "Epoch 76: val_mae improved from 22.46074 to 22.45506, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.7311 - mae: 21.7311 - val_loss: 22.4551 - val_mae: 22.4551\n",
      "Epoch 77/100\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 21.7249 - mae: 21.7249\n",
      "Epoch 77: val_mae did not improve from 22.45506\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.7249 - mae: 21.7249 - val_loss: 22.6978 - val_mae: 22.6978\n",
      "Epoch 78/100\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 21.7148 - mae: 21.7148\n",
      "Epoch 78: val_mae did not improve from 22.45506\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.7149 - mae: 21.7149 - val_loss: 22.5172 - val_mae: 22.5172\n",
      "Epoch 79/100\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 21.7142 - mae: 21.7142\n",
      "Epoch 79: val_mae did not improve from 22.45506\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.7138 - mae: 21.7138 - val_loss: 22.5158 - val_mae: 22.5158\n",
      "Epoch 80/100\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 21.7067 - mae: 21.7067\n",
      "Epoch 80: val_mae did not improve from 22.45506\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.7072 - mae: 21.7072 - val_loss: 22.4596 - val_mae: 22.4596\n",
      "Epoch 81/100\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 21.6991 - mae: 21.6991\n",
      "Epoch 81: val_mae did not improve from 22.45506\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.6991 - mae: 21.6991 - val_loss: 22.4598 - val_mae: 22.4598\n",
      "Epoch 82/100\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 21.7039 - mae: 21.7039\n",
      "Epoch 82: val_mae did not improve from 22.45506\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.7040 - mae: 21.7040 - val_loss: 22.4796 - val_mae: 22.4796\n",
      "Epoch 83/100\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 21.6867 - mae: 21.6867\n",
      "Epoch 83: val_mae did not improve from 22.45506\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.6868 - mae: 21.6868 - val_loss: 22.6077 - val_mae: 22.6077\n",
      "Epoch 84/100\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 21.6882 - mae: 21.6882\n",
      "Epoch 84: val_mae improved from 22.45506 to 22.44266, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.6883 - mae: 21.6883 - val_loss: 22.4427 - val_mae: 22.4427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 21.6782 - mae: 21.6782\n",
      "Epoch 85: val_mae did not improve from 22.44266\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.6779 - mae: 21.6779 - val_loss: 22.5597 - val_mae: 22.5597\n",
      "Epoch 86/100\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 21.6781 - mae: 21.6781\n",
      "Epoch 86: val_mae improved from 22.44266 to 22.43375, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.6778 - mae: 21.6778 - val_loss: 22.4338 - val_mae: 22.4338\n",
      "Epoch 87/100\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 21.6724 - mae: 21.6724\n",
      "Epoch 87: val_mae did not improve from 22.43375\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.6727 - mae: 21.6727 - val_loss: 22.6754 - val_mae: 22.6754\n",
      "Epoch 88/100\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 21.6710 - mae: 21.6710\n",
      "Epoch 88: val_mae did not improve from 22.43375\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.6710 - mae: 21.6710 - val_loss: 22.5779 - val_mae: 22.5779\n",
      "Epoch 89/100\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 21.6622 - mae: 21.6622\n",
      "Epoch 89: val_mae did not improve from 22.43375\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.6621 - mae: 21.6621 - val_loss: 22.4341 - val_mae: 22.4341\n",
      "Epoch 90/100\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 21.6549 - mae: 21.6549\n",
      "Epoch 90: val_mae did not improve from 22.43375\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.6545 - mae: 21.6545 - val_loss: 22.5002 - val_mae: 22.5002\n",
      "Epoch 91/100\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 21.6551 - mae: 21.6551\n",
      "Epoch 91: val_mae did not improve from 22.43375\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.6551 - mae: 21.6551 - val_loss: 22.5100 - val_mae: 22.5100\n",
      "Epoch 92/100\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 21.6454 - mae: 21.6454\n",
      "Epoch 92: val_mae improved from 22.43375 to 22.42258, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.6454 - mae: 21.6454 - val_loss: 22.4226 - val_mae: 22.4226\n",
      "Epoch 93/100\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 21.6379 - mae: 21.6379\n",
      "Epoch 93: val_mae improved from 22.42258 to 22.39924, saving model to .\\RNN1_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.6380 - mae: 21.6380 - val_loss: 22.3992 - val_mae: 22.3992\n",
      "Epoch 94/100\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 21.6314 - mae: 21.6314\n",
      "Epoch 94: val_mae did not improve from 22.39924\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.6316 - mae: 21.6316 - val_loss: 22.4985 - val_mae: 22.4985\n",
      "Epoch 95/100\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 21.6221 - mae: 21.6221\n",
      "Epoch 95: val_mae did not improve from 22.39924\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.6216 - mae: 21.6216 - val_loss: 22.5018 - val_mae: 22.5018\n",
      "Epoch 96/100\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 21.6245 - mae: 21.6245\n",
      "Epoch 96: val_mae did not improve from 22.39924\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.6241 - mae: 21.6241 - val_loss: 22.7399 - val_mae: 22.7399\n",
      "Epoch 97/100\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 21.6078 - mae: 21.6078\n",
      "Epoch 97: val_mae did not improve from 22.39924\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.6078 - mae: 21.6078 - val_loss: 22.4046 - val_mae: 22.4046\n",
      "Epoch 98/100\n",
      "1705/1711 [============================>.] - ETA: 0s - loss: 21.6149 - mae: 21.6149\n",
      "Epoch 98: val_mae did not improve from 22.39924\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.6152 - mae: 21.6152 - val_loss: 22.4219 - val_mae: 22.4219\n",
      "Epoch 99/100\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 21.6058 - mae: 21.6058\n",
      "Epoch 99: val_mae did not improve from 22.39924\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.6058 - mae: 21.6058 - val_loss: 22.4100 - val_mae: 22.4100\n",
      "Epoch 100/100\n",
      "1706/1711 [============================>.] - ETA: 0s - loss: 21.5962 - mae: 21.5962\n",
      "Epoch 100: val_mae did not improve from 22.39924\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.5962 - mae: 21.5962 - val_loss: 22.6679 - val_mae: 22.6679\n"
     ]
    }
   ],
   "source": [
    "random_seed = 15\n",
    "tf.keras.utils.set_random_seed(random_seed)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "file_path = './RNN1_best_model.h5'\n",
    "checkpoint = ModelCheckpoint(file_path,\n",
    "                            monitor = 'val_mae',\n",
    "                            verbose=1,\n",
    "                            save_best_only=True,\n",
    "                            mode='auto')\n",
    "\n",
    "hist = model.fit(x_train, y_train, validation_data=(x_test, y_test), \n",
    "                 epochs=100, batch_size=16, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5e1e5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 3ms/step - loss: 22.3992 - mae: 22.3992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[22.39923858642578, 22.39923858642578]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.save('model.h5')\n",
    "RNN1_model = tf.keras.models.load_model('./RNN1_best_model.h5')\n",
    "RNN1_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "921837bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264/264 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "RNN1_pred = RNN1_model.predict(submission_x)\n",
    "pd.DataFrame(RNN1_pred).to_csv('RNN1_pred.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531cd64e",
   "metadata": {
    "id": "90f6fa65"
   },
   "source": [
    "## RNN2 / window size 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c617eb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27367, 96, 1) (27367, 336) (7992, 96, 1) (7992, 336) (8425, 96, 1) (8425, 336)\n"
     ]
    }
   ],
   "source": [
    "pre_day = 28 # (31 - pre_month) * 24 = windowsize /27 : 96//28 : 72//29 : 48//30 : 24//\n",
    "x_train, y_train, x_test, y_test, submission_x, submission_y = DataProcessing.data_form_descision(train_df, test_df, pre_day)\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape, submission_x.shape, submission_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80b67635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_4 (SimpleRNN)    (None, 96, 32)            1088      \n",
      "                                                                 \n",
      " simple_rnn_5 (SimpleRNN)    (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               4224      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 336)               11088     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,608\n",
      "Trainable params: 22,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model 생성\n",
    "\n",
    "initializer = tf.keras.initializers.GlorotNormal(seed=42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(32, activation='relu', input_shape=(x_train[0].shape), \n",
    "               return_sequences=True, kernel_initializer=initializer))\n",
    "model.add(SimpleRNN(32, activation='relu', kernel_initializer=initializer))\n",
    "model.add(Dense(128, activation='relu', kernel_initializer=initializer))\n",
    "model.add(Dense(32, activation='relu', kernel_initializer=initializer))\n",
    "model.add(Dense(336, activation='linear', kernel_initializer=initializer))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.00002)\n",
    "model.compile(loss='mae', optimizer=optimizer, metrics=['mae'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84dc50ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 55.1947 - mae: 55.1947\n",
      "Epoch 1: val_mae improved from inf to 36.56512, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 20s 11ms/step - loss: 55.1545 - mae: 55.1545 - val_loss: 36.5651 - val_mae: 36.5651\n",
      "Epoch 2/90\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 34.3202 - mae: 34.3202\n",
      "Epoch 2: val_mae improved from 36.56512 to 35.61407, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 34.3208 - mae: 34.3208 - val_loss: 35.6141 - val_mae: 35.6141\n",
      "Epoch 3/90\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 34.1401 - mae: 34.1401\n",
      "Epoch 3: val_mae improved from 35.61407 to 35.56163, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 34.1397 - mae: 34.1397 - val_loss: 35.5616 - val_mae: 35.5616\n",
      "Epoch 4/90\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 33.9674 - mae: 33.9674\n",
      "Epoch 4: val_mae improved from 35.56163 to 35.13660, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 33.9660 - mae: 33.9660 - val_loss: 35.1366 - val_mae: 35.1366\n",
      "Epoch 5/90\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 32.9475 - mae: 32.9475\n",
      "Epoch 5: val_mae improved from 35.13660 to 33.30785, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 32.9475 - mae: 32.9475 - val_loss: 33.3079 - val_mae: 33.3079\n",
      "Epoch 6/90\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 31.2407 - mae: 31.2407\n",
      "Epoch 6: val_mae improved from 33.30785 to 31.71493, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 31.2407 - mae: 31.2407 - val_loss: 31.7149 - val_mae: 31.7149\n",
      "Epoch 7/90\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 29.8284 - mae: 29.8284\n",
      "Epoch 7: val_mae improved from 31.71493 to 30.23381, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 29.8282 - mae: 29.8282 - val_loss: 30.2338 - val_mae: 30.2338\n",
      "Epoch 8/90\n",
      "1706/1711 [============================>.] - ETA: 0s - loss: 28.6317 - mae: 28.6317\n",
      "Epoch 8: val_mae improved from 30.23381 to 29.05677, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 28.6302 - mae: 28.6302 - val_loss: 29.0568 - val_mae: 29.0568\n",
      "Epoch 9/90\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 27.6410 - mae: 27.6410\n",
      "Epoch 9: val_mae improved from 29.05677 to 28.05573, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 27.6410 - mae: 27.6410 - val_loss: 28.0557 - val_mae: 28.0557\n",
      "Epoch 10/90\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 26.7759 - mae: 26.7759\n",
      "Epoch 10: val_mae improved from 28.05573 to 27.14934, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 26.7749 - mae: 26.7749 - val_loss: 27.1493 - val_mae: 27.1493\n",
      "Epoch 11/90\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 25.8714 - mae: 25.8714\n",
      "Epoch 11: val_mae improved from 27.14934 to 25.97994, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 25.8705 - mae: 25.8705 - val_loss: 25.9799 - val_mae: 25.9799\n",
      "Epoch 12/90\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 24.7663 - mae: 24.7663\n",
      "Epoch 12: val_mae improved from 25.97994 to 24.95197, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 24.7655 - mae: 24.7655 - val_loss: 24.9520 - val_mae: 24.9520\n",
      "Epoch 13/90\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 23.9504 - mae: 23.9504\n",
      "Epoch 13: val_mae improved from 24.95197 to 24.31003, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 23.9501 - mae: 23.9501 - val_loss: 24.3100 - val_mae: 24.3100\n",
      "Epoch 14/90\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 23.4953 - mae: 23.4953\n",
      "Epoch 14: val_mae improved from 24.31003 to 23.93738, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 20s 12ms/step - loss: 23.4953 - mae: 23.4953 - val_loss: 23.9374 - val_mae: 23.9374\n",
      "Epoch 15/90\n",
      "1706/1711 [============================>.] - ETA: 0s - loss: 23.2608 - mae: 23.2608\n",
      "Epoch 15: val_mae improved from 23.93738 to 23.90533, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 20s 11ms/step - loss: 23.2611 - mae: 23.2611 - val_loss: 23.9053 - val_mae: 23.9053\n",
      "Epoch 16/90\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 23.1512 - mae: 23.1512\n",
      "Epoch 16: val_mae improved from 23.90533 to 23.71056, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 23.1512 - mae: 23.1512 - val_loss: 23.7106 - val_mae: 23.7106\n",
      "Epoch 17/90\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 23.0870 - mae: 23.0870\n",
      "Epoch 17: val_mae did not improve from 23.71056\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 23.0869 - mae: 23.0869 - val_loss: 23.7171 - val_mae: 23.7171\n",
      "Epoch 18/90\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 23.0486 - mae: 23.0486\n",
      "Epoch 18: val_mae did not improve from 23.71056\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 23.0480 - mae: 23.0480 - val_loss: 23.7273 - val_mae: 23.7273\n",
      "Epoch 19/90\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 23.0221 - mae: 23.0221\n",
      "Epoch 19: val_mae improved from 23.71056 to 23.63737, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 23.0221 - mae: 23.0221 - val_loss: 23.6374 - val_mae: 23.6374\n",
      "Epoch 20/90\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 22.9976 - mae: 22.9976\n",
      "Epoch 20: val_mae did not improve from 23.63737\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.9969 - mae: 22.9969 - val_loss: 23.6413 - val_mae: 23.6413\n",
      "Epoch 21/90\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 22.9770 - mae: 22.9770\n",
      "Epoch 21: val_mae improved from 23.63737 to 23.63662, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.9770 - mae: 22.9770 - val_loss: 23.6366 - val_mae: 23.6366\n",
      "Epoch 22/90\n",
      "1706/1711 [============================>.] - ETA: 0s - loss: 22.9583 - mae: 22.9583\n",
      "Epoch 22: val_mae did not improve from 23.63662\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.9584 - mae: 22.9584 - val_loss: 23.7646 - val_mae: 23.7646\n",
      "Epoch 23/90\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 22.9390 - mae: 22.9390\n",
      "Epoch 23: val_mae improved from 23.63662 to 23.59328, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.9387 - mae: 22.9387 - val_loss: 23.5933 - val_mae: 23.5933\n",
      "Epoch 24/90\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 22.9191 - mae: 22.9191\n",
      "Epoch 24: val_mae improved from 23.59328 to 23.53950, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.9190 - mae: 22.9190 - val_loss: 23.5395 - val_mae: 23.5395\n",
      "Epoch 25/90\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 22.9010 - mae: 22.9010\n",
      "Epoch 25: val_mae did not improve from 23.53950\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.9007 - mae: 22.9007 - val_loss: 23.5414 - val_mae: 23.5414\n",
      "Epoch 26/90\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 22.8806 - mae: 22.8806\n",
      "Epoch 26: val_mae improved from 23.53950 to 23.53878, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.8808 - mae: 22.8808 - val_loss: 23.5388 - val_mae: 23.5388\n",
      "Epoch 27/90\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 22.8676 - mae: 22.8676\n",
      "Epoch 27: val_mae improved from 23.53878 to 23.53505, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.8675 - mae: 22.8675 - val_loss: 23.5350 - val_mae: 23.5350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/90\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 22.8496 - mae: 22.8496\n",
      "Epoch 28: val_mae improved from 23.53505 to 23.47664, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.8492 - mae: 22.8492 - val_loss: 23.4766 - val_mae: 23.4766\n",
      "Epoch 29/90\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 22.8337 - mae: 22.8337\n",
      "Epoch 29: val_mae improved from 23.47664 to 23.46666, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.8333 - mae: 22.8333 - val_loss: 23.4667 - val_mae: 23.4667\n",
      "Epoch 30/90\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 22.8147 - mae: 22.8147\n",
      "Epoch 30: val_mae improved from 23.46666 to 23.46392, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.8144 - mae: 22.8144 - val_loss: 23.4639 - val_mae: 23.4639\n",
      "Epoch 31/90\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 22.7933 - mae: 22.7933\n",
      "Epoch 31: val_mae improved from 23.46392 to 23.43384, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.7933 - mae: 22.7933 - val_loss: 23.4338 - val_mae: 23.4338\n",
      "Epoch 32/90\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 22.7801 - mae: 22.7801\n",
      "Epoch 32: val_mae did not improve from 23.43384\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.7799 - mae: 22.7799 - val_loss: 23.5488 - val_mae: 23.5488\n",
      "Epoch 33/90\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 22.7669 - mae: 22.7669\n",
      "Epoch 33: val_mae did not improve from 23.43384\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.7669 - mae: 22.7669 - val_loss: 23.7138 - val_mae: 23.7138\n",
      "Epoch 34/90\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 22.7509 - mae: 22.7509\n",
      "Epoch 34: val_mae did not improve from 23.43384\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.7507 - mae: 22.7507 - val_loss: 23.6668 - val_mae: 23.6668\n",
      "Epoch 35/90\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 22.7369 - mae: 22.7369\n",
      "Epoch 35: val_mae did not improve from 23.43384\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.7372 - mae: 22.7372 - val_loss: 23.5188 - val_mae: 23.5188\n",
      "Epoch 36/90\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 22.7195 - mae: 22.7195\n",
      "Epoch 36: val_mae improved from 23.43384 to 23.37477, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.7195 - mae: 22.7195 - val_loss: 23.3748 - val_mae: 23.3748\n",
      "Epoch 37/90\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 22.7029 - mae: 22.7029\n",
      "Epoch 37: val_mae did not improve from 23.37477\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.7029 - mae: 22.7029 - val_loss: 23.4953 - val_mae: 23.4953\n",
      "Epoch 38/90\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 22.6879 - mae: 22.6879\n",
      "Epoch 38: val_mae did not improve from 23.37477\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.6877 - mae: 22.6877 - val_loss: 23.3933 - val_mae: 23.3933\n",
      "Epoch 39/90\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 22.6706 - mae: 22.6706\n",
      "Epoch 39: val_mae improved from 23.37477 to 23.32274, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.6706 - mae: 22.6706 - val_loss: 23.3227 - val_mae: 23.3227\n",
      "Epoch 40/90\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 22.6519 - mae: 22.6519\n",
      "Epoch 40: val_mae improved from 23.32274 to 23.29111, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.6522 - mae: 22.6522 - val_loss: 23.2911 - val_mae: 23.2911\n",
      "Epoch 41/90\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 22.6336 - mae: 22.6336\n",
      "Epoch 41: val_mae improved from 23.29111 to 23.26629, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.6336 - mae: 22.6336 - val_loss: 23.2663 - val_mae: 23.2663\n",
      "Epoch 42/90\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 22.6131 - mae: 22.6131\n",
      "Epoch 42: val_mae did not improve from 23.26629\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.6133 - mae: 22.6133 - val_loss: 23.3370 - val_mae: 23.3370\n",
      "Epoch 43/90\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 22.5959 - mae: 22.5959\n",
      "Epoch 43: val_mae improved from 23.26629 to 23.22897, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.5962 - mae: 22.5962 - val_loss: 23.2290 - val_mae: 23.2290\n",
      "Epoch 44/90\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 22.5793 - mae: 22.5793\n",
      "Epoch 44: val_mae did not improve from 23.22897\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.5785 - mae: 22.5785 - val_loss: 23.3375 - val_mae: 23.3375\n",
      "Epoch 45/90\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 22.5577 - mae: 22.5577\n",
      "Epoch 45: val_mae did not improve from 23.22897\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.5570 - mae: 22.5570 - val_loss: 23.2583 - val_mae: 23.2583\n",
      "Epoch 46/90\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 22.5341 - mae: 22.5341\n",
      "Epoch 46: val_mae improved from 23.22897 to 23.19049, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.5342 - mae: 22.5342 - val_loss: 23.1905 - val_mae: 23.1905\n",
      "Epoch 47/90\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 22.5114 - mae: 22.5114\n",
      "Epoch 47: val_mae improved from 23.19049 to 23.15411, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.5114 - mae: 22.5114 - val_loss: 23.1541 - val_mae: 23.1541\n",
      "Epoch 48/90\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 22.4909 - mae: 22.4909\n",
      "Epoch 48: val_mae improved from 23.15411 to 23.13322, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.4912 - mae: 22.4912 - val_loss: 23.1332 - val_mae: 23.1332\n",
      "Epoch 49/90\n",
      "1706/1711 [============================>.] - ETA: 0s - loss: 22.4709 - mae: 22.4709\n",
      "Epoch 49: val_mae did not improve from 23.13322\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.4709 - mae: 22.4709 - val_loss: 23.2121 - val_mae: 23.2121\n",
      "Epoch 50/90\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 22.4442 - mae: 22.4442\n",
      "Epoch 50: val_mae improved from 23.13322 to 23.08565, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.4442 - mae: 22.4442 - val_loss: 23.0857 - val_mae: 23.0857\n",
      "Epoch 51/90\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 22.4244 - mae: 22.4244\n",
      "Epoch 51: val_mae did not improve from 23.08565\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.4243 - mae: 22.4243 - val_loss: 23.2400 - val_mae: 23.2400\n",
      "Epoch 52/90\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 22.4007 - mae: 22.4007\n",
      "Epoch 52: val_mae did not improve from 23.08565\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.4007 - mae: 22.4007 - val_loss: 23.1922 - val_mae: 23.1922\n",
      "Epoch 53/90\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 22.3778 - mae: 22.3778\n",
      "Epoch 53: val_mae did not improve from 23.08565\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.3777 - mae: 22.3777 - val_loss: 23.1390 - val_mae: 23.1390\n",
      "Epoch 54/90\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 22.3583 - mae: 22.3583\n",
      "Epoch 54: val_mae improved from 23.08565 to 22.98200, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.3583 - mae: 22.3583 - val_loss: 22.9820 - val_mae: 22.9820\n",
      "Epoch 55/90\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 22.3295 - mae: 22.3295\n",
      "Epoch 55: val_mae improved from 22.98200 to 22.96575, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.3301 - mae: 22.3301 - val_loss: 22.9658 - val_mae: 22.9658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/90\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 22.3078 - mae: 22.3078\n",
      "Epoch 56: val_mae did not improve from 22.96575\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.3076 - mae: 22.3076 - val_loss: 23.0516 - val_mae: 23.0516\n",
      "Epoch 57/90\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 22.2872 - mae: 22.2872\n",
      "Epoch 57: val_mae did not improve from 22.96575\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.2873 - mae: 22.2873 - val_loss: 23.0080 - val_mae: 23.0080\n",
      "Epoch 58/90\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 22.2708 - mae: 22.2708\n",
      "Epoch 58: val_mae improved from 22.96575 to 22.90912, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.2707 - mae: 22.2707 - val_loss: 22.9091 - val_mae: 22.9091\n",
      "Epoch 59/90\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 22.2427 - mae: 22.2427\n",
      "Epoch 59: val_mae improved from 22.90912 to 22.87478, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.2428 - mae: 22.2428 - val_loss: 22.8748 - val_mae: 22.8748\n",
      "Epoch 60/90\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 22.2253 - mae: 22.2253\n",
      "Epoch 60: val_mae did not improve from 22.87478\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.2249 - mae: 22.2249 - val_loss: 22.8748 - val_mae: 22.8748\n",
      "Epoch 61/90\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 22.2018 - mae: 22.2018\n",
      "Epoch 61: val_mae did not improve from 22.87478\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.2014 - mae: 22.2014 - val_loss: 22.9410 - val_mae: 22.9410\n",
      "Epoch 62/90\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 22.1830 - mae: 22.1830\n",
      "Epoch 62: val_mae improved from 22.87478 to 22.83145, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.1828 - mae: 22.1828 - val_loss: 22.8315 - val_mae: 22.8315\n",
      "Epoch 63/90\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 22.1642 - mae: 22.1642\n",
      "Epoch 63: val_mae did not improve from 22.83145\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.1647 - mae: 22.1647 - val_loss: 22.8723 - val_mae: 22.8723\n",
      "Epoch 64/90\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 22.1436 - mae: 22.1436\n",
      "Epoch 64: val_mae improved from 22.83145 to 22.82869, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.1438 - mae: 22.1438 - val_loss: 22.8287 - val_mae: 22.8287\n",
      "Epoch 65/90\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 22.1289 - mae: 22.1289\n",
      "Epoch 65: val_mae did not improve from 22.82869\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.1290 - mae: 22.1290 - val_loss: 23.0172 - val_mae: 23.0172\n",
      "Epoch 66/90\n",
      "1706/1711 [============================>.] - ETA: 0s - loss: 22.1150 - mae: 22.1150\n",
      "Epoch 66: val_mae improved from 22.82869 to 22.76291, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.1153 - mae: 22.1153 - val_loss: 22.7629 - val_mae: 22.7629\n",
      "Epoch 67/90\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 22.0936 - mae: 22.0936\n",
      "Epoch 67: val_mae did not improve from 22.76291\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.0936 - mae: 22.0936 - val_loss: 22.8054 - val_mae: 22.8054\n",
      "Epoch 68/90\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 22.0800 - mae: 22.0800\n",
      "Epoch 68: val_mae improved from 22.76291 to 22.74275, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.0795 - mae: 22.0795 - val_loss: 22.7427 - val_mae: 22.7427\n",
      "Epoch 69/90\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 22.0676 - mae: 22.0676\n",
      "Epoch 69: val_mae did not improve from 22.74275\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.0676 - mae: 22.0676 - val_loss: 22.9422 - val_mae: 22.9422\n",
      "Epoch 70/90\n",
      "1705/1711 [============================>.] - ETA: 0s - loss: 22.0572 - mae: 22.0572\n",
      "Epoch 70: val_mae did not improve from 22.74275\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.0571 - mae: 22.0571 - val_loss: 22.7869 - val_mae: 22.7869\n",
      "Epoch 71/90\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 22.0427 - mae: 22.0427\n",
      "Epoch 71: val_mae improved from 22.74275 to 22.68159, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.0427 - mae: 22.0427 - val_loss: 22.6816 - val_mae: 22.6816\n",
      "Epoch 72/90\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 22.0265 - mae: 22.0265\n",
      "Epoch 72: val_mae did not improve from 22.68159\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.0265 - mae: 22.0265 - val_loss: 22.6817 - val_mae: 22.6817\n",
      "Epoch 73/90\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 22.0185 - mae: 22.0185\n",
      "Epoch 73: val_mae did not improve from 22.68159\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.0185 - mae: 22.0185 - val_loss: 22.7041 - val_mae: 22.7041\n",
      "Epoch 74/90\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 22.0087 - mae: 22.0087\n",
      "Epoch 74: val_mae did not improve from 22.68159\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 22.0087 - mae: 22.0087 - val_loss: 22.7740 - val_mae: 22.7740\n",
      "Epoch 75/90\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 21.9970 - mae: 21.9970\n",
      "Epoch 75: val_mae improved from 22.68159 to 22.63139, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.9970 - mae: 21.9970 - val_loss: 22.6314 - val_mae: 22.6314\n",
      "Epoch 76/90\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 21.9901 - mae: 21.9901\n",
      "Epoch 76: val_mae did not improve from 22.63139\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.9899 - mae: 21.9899 - val_loss: 22.6995 - val_mae: 22.6995\n",
      "Epoch 77/90\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 21.9796 - mae: 21.9796\n",
      "Epoch 77: val_mae did not improve from 22.63139\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.9796 - mae: 21.9796 - val_loss: 22.6323 - val_mae: 22.6323\n",
      "Epoch 78/90\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 21.9691 - mae: 21.9691\n",
      "Epoch 78: val_mae did not improve from 22.63139\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.9691 - mae: 21.9691 - val_loss: 22.7387 - val_mae: 22.7387\n",
      "Epoch 79/90\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 21.9601 - mae: 21.9601\n",
      "Epoch 79: val_mae did not improve from 22.63139\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.9608 - mae: 21.9608 - val_loss: 22.6367 - val_mae: 22.6367\n",
      "Epoch 80/90\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 21.9510 - mae: 21.9510\n",
      "Epoch 80: val_mae improved from 22.63139 to 22.61602, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.9504 - mae: 21.9504 - val_loss: 22.6160 - val_mae: 22.6160\n",
      "Epoch 81/90\n",
      "1705/1711 [============================>.] - ETA: 0s - loss: 21.9488 - mae: 21.9488\n",
      "Epoch 81: val_mae did not improve from 22.61602\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.9481 - mae: 21.9481 - val_loss: 22.7111 - val_mae: 22.7111\n",
      "Epoch 82/90\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 21.9395 - mae: 21.9395\n",
      "Epoch 82: val_mae improved from 22.61602 to 22.59425, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.9395 - mae: 21.9395 - val_loss: 22.5943 - val_mae: 22.5943\n",
      "Epoch 83/90\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 21.9335 - mae: 21.9335\n",
      "Epoch 83: val_mae did not improve from 22.59425\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.9335 - mae: 21.9335 - val_loss: 22.7547 - val_mae: 22.7547\n",
      "Epoch 84/90\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 21.9274 - mae: 21.9274\n",
      "Epoch 84: val_mae improved from 22.59425 to 22.56621, saving model to .\\RNN2_best_model.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.9273 - mae: 21.9273 - val_loss: 22.5662 - val_mae: 22.5662\n",
      "Epoch 85/90\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 21.9195 - mae: 21.9195\n",
      "Epoch 85: val_mae did not improve from 22.56621\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.9195 - mae: 21.9195 - val_loss: 22.6530 - val_mae: 22.6530\n",
      "Epoch 86/90\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 21.9131 - mae: 21.9131\n",
      "Epoch 86: val_mae did not improve from 22.56621\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.9131 - mae: 21.9131 - val_loss: 22.7868 - val_mae: 22.7868\n",
      "Epoch 87/90\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 21.9105 - mae: 21.9105\n",
      "Epoch 87: val_mae did not improve from 22.56621\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.9107 - mae: 21.9107 - val_loss: 22.6784 - val_mae: 22.6784\n",
      "Epoch 88/90\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 21.9109 - mae: 21.9109\n",
      "Epoch 88: val_mae improved from 22.56621 to 22.55945, saving model to .\\RNN2_best_model.h5\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.9109 - mae: 21.9109 - val_loss: 22.5595 - val_mae: 22.5595\n",
      "Epoch 89/90\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 21.8986 - mae: 21.8986\n",
      "Epoch 89: val_mae did not improve from 22.55945\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.8986 - mae: 21.8986 - val_loss: 22.5718 - val_mae: 22.5718\n",
      "Epoch 90/90\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 21.8949 - mae: 21.8949\n",
      "Epoch 90: val_mae did not improve from 22.55945\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 21.8950 - mae: 21.8950 - val_loss: 22.6199 - val_mae: 22.6199\n"
     ]
    }
   ],
   "source": [
    "random_seed = 42\n",
    "tf.keras.utils.set_random_seed(random_seed)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "file_path = './RNN2_best_model.h5'\n",
    "checkpoint = ModelCheckpoint(file_path,\n",
    "                            monitor = 'val_mae',\n",
    "                            verbose=1,\n",
    "                            save_best_only=True,\n",
    "                            mode='auto')  \n",
    "\n",
    "hist = model.fit(x_train, y_train, validation_data=(x_test, y_test), \n",
    "                 epochs=90, batch_size=16, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b571ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 3ms/step - loss: 22.5595 - mae: 22.5595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[22.5594539642334, 22.5594539642334]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN2_model = tf.keras.models.load_model('./RNN2_best_model.h5')\n",
    "RNN2_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59733cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264/264 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "RNN2_pred = RNN2_model.predict(submission_x)\n",
    "pd.DataFrame(RNN2_pred).to_csv('RNN2_pred.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b28886a",
   "metadata": {},
   "source": [
    "## RNN3 / window size 240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c7e90f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27223, 240, 1) (27223, 336) (7848, 240, 1) (7848, 336) (8425, 240, 1) (8425, 336)\n"
     ]
    }
   ],
   "source": [
    "pre_day = 22 # (31 - pre_month) * 24 = windowsize /27 : 96//28 : 72//29 : 48//30 : 24//\n",
    "x_train, y_train, x_test, y_test, submission_x, submission_y = DataProcessing.data_form_descision(train_df, test_df, pre_day)\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape, submission_x.shape, submission_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50aa60dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_6 (SimpleRNN)    (None, 240, 64)           4224      \n",
      "                                                                 \n",
      " simple_rnn_7 (SimpleRNN)    (None, 240, 32)           3104      \n",
      "                                                                 \n",
      " simple_rnn_8 (SimpleRNN)    (None, 16)                784       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                1088      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 336)               11088     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,368\n",
      "Trainable params: 22,368\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "initializer = tf.keras.initializers.GlorotNormal(seed=15)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(64, activation='relu', input_shape=(x_train[0].shape), \n",
    "               return_sequences=True, kernel_initializer=initializer))\n",
    "model.add(SimpleRNN(32, activation='relu',return_sequences=True, kernel_initializer=initializer))\n",
    "model.add(SimpleRNN(16, activation='relu', kernel_initializer=initializer))\n",
    "model.add(Dense(64, activation='relu', kernel_initializer=initializer))\n",
    "model.add(Dense(32, activation='relu', kernel_initializer=initializer))\n",
    "model.add(Dense(336, activation='linear', kernel_initializer=initializer))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.00006)\n",
    "model.compile(loss='mae', optimizer=optimizer, metrics=['mae'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f6a3ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 41.6768 - mae: 41.6768\n",
      "Epoch 1: val_mae improved from inf to 35.77845, saving model to .\\RNN3_best_model.h5\n",
      "1702/1702 [==============================] - 76s 44ms/step - loss: 41.6750 - mae: 41.6750 - val_loss: 35.7784 - val_mae: 35.7784\n",
      "Epoch 2/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 34.2880 - mae: 34.2880\n",
      "Epoch 2: val_mae improved from 35.77845 to 35.70729, saving model to .\\RNN3_best_model.h5\n",
      "1702/1702 [==============================] - 75s 44ms/step - loss: 34.2880 - mae: 34.2880 - val_loss: 35.7073 - val_mae: 35.7073\n",
      "Epoch 3/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 34.2565 - mae: 34.2565\n",
      "Epoch 3: val_mae did not improve from 35.70729\n",
      "1702/1702 [==============================] - 75s 44ms/step - loss: 34.2565 - mae: 34.2565 - val_loss: 35.7394 - val_mae: 35.7394\n",
      "Epoch 4/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 34.2130 - mae: 34.2130\n",
      "Epoch 4: val_mae improved from 35.70729 to 35.68599, saving model to .\\RNN3_best_model.h5\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 34.2126 - mae: 34.2126 - val_loss: 35.6860 - val_mae: 35.6860\n",
      "Epoch 5/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 34.1233 - mae: 34.1233\n",
      "Epoch 5: val_mae improved from 35.68599 to 35.44973, saving model to .\\RNN3_best_model.h5\n",
      "1702/1702 [==============================] - 77s 46ms/step - loss: 34.1233 - mae: 34.1233 - val_loss: 35.4497 - val_mae: 35.4497\n",
      "Epoch 6/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 33.6648 - mae: 33.6648\n",
      "Epoch 6: val_mae improved from 35.44973 to 34.22913, saving model to .\\RNN3_best_model.h5\n",
      "1702/1702 [==============================] - 76s 44ms/step - loss: 33.6648 - mae: 33.6648 - val_loss: 34.2291 - val_mae: 34.2291\n",
      "Epoch 7/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 30.7535 - mae: 30.7535\n",
      "Epoch 7: val_mae improved from 34.22913 to 29.69607, saving model to .\\RNN3_best_model.h5\n",
      "1702/1702 [==============================] - 75s 44ms/step - loss: 30.7530 - mae: 30.7530 - val_loss: 29.6961 - val_mae: 29.6961\n",
      "Epoch 8/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 28.0319 - mae: 28.0319\n",
      "Epoch 8: val_mae improved from 29.69607 to 28.31941, saving model to .\\RNN3_best_model.h5\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 28.0320 - mae: 28.0320 - val_loss: 28.3194 - val_mae: 28.3194\n",
      "Epoch 9/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 27.1711 - mae: 27.1711\n",
      "Epoch 9: val_mae improved from 28.31941 to 27.49312, saving model to .\\RNN3_best_model.h5\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 27.1711 - mae: 27.1711 - val_loss: 27.4931 - val_mae: 27.4931\n",
      "Epoch 10/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 25.7396 - mae: 25.7396\n",
      "Epoch 10: val_mae improved from 27.49312 to 25.55316, saving model to .\\RNN3_best_model.h5\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 25.7396 - mae: 25.7396 - val_loss: 25.5532 - val_mae: 25.5532\n",
      "Epoch 11/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 24.1685 - mae: 24.1685\n",
      "Epoch 11: val_mae improved from 25.55316 to 24.27686, saving model to .\\RNN3_best_model.h5\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 24.1685 - mae: 24.1685 - val_loss: 24.2769 - val_mae: 24.2769\n",
      "Epoch 12/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 23.3496 - mae: 23.3496\n",
      "Epoch 12: val_mae improved from 24.27686 to 23.55467, saving model to .\\RNN3_best_model.h5\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 23.3496 - mae: 23.3496 - val_loss: 23.5547 - val_mae: 23.5547\n",
      "Epoch 13/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 23.1482 - mae: 23.1482\n",
      "Epoch 13: val_mae did not improve from 23.55467\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 23.1480 - mae: 23.1480 - val_loss: 23.6456 - val_mae: 23.6456\n",
      "Epoch 14/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 23.0764 - mae: 23.0764\n",
      "Epoch 14: val_mae improved from 23.55467 to 23.52684, saving model to .\\RNN3_best_model.h5\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 23.0764 - mae: 23.0764 - val_loss: 23.5268 - val_mae: 23.5268\n",
      "Epoch 15/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 23.0438 - mae: 23.0438\n",
      "Epoch 15: val_mae did not improve from 23.52684\n",
      "1702/1702 [==============================] - 75s 44ms/step - loss: 23.0436 - mae: 23.0436 - val_loss: 23.6634 - val_mae: 23.6634\n",
      "Epoch 16/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 23.0239 - mae: 23.0239\n",
      "Epoch 16: val_mae did not improve from 23.52684\n",
      "1702/1702 [==============================] - 73s 43ms/step - loss: 23.0239 - mae: 23.0239 - val_loss: 23.6823 - val_mae: 23.6823\n",
      "Epoch 17/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 22.9858 - mae: 22.9858\n",
      "Epoch 17: val_mae improved from 23.52684 to 23.33898, saving model to .\\RNN3_best_model.h5\n",
      "1702/1702 [==============================] - 74s 44ms/step - loss: 22.9858 - mae: 22.9858 - val_loss: 23.3390 - val_mae: 23.3390\n",
      "Epoch 18/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 22.9467 - mae: 22.9467\n",
      "Epoch 18: val_mae did not improve from 23.33898\n",
      "1702/1702 [==============================] - 74s 43ms/step - loss: 22.9465 - mae: 22.9465 - val_loss: 23.5089 - val_mae: 23.5089\n",
      "Epoch 19/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 22.9338 - mae: 22.9338\n",
      "Epoch 19: val_mae improved from 23.33898 to 23.29144, saving model to .\\RNN3_best_model.h5\n",
      "1702/1702 [==============================] - 72s 42ms/step - loss: 22.9337 - mae: 22.9337 - val_loss: 23.2914 - val_mae: 23.2914\n",
      "Epoch 20/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 22.9065 - mae: 22.9065\n",
      "Epoch 20: val_mae did not improve from 23.29144\n",
      "1702/1702 [==============================] - 73s 43ms/step - loss: 22.9066 - mae: 22.9066 - val_loss: 23.3283 - val_mae: 23.3283\n",
      "Epoch 21/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 22.8734 - mae: 22.8734\n",
      "Epoch 21: val_mae improved from 23.29144 to 23.28429, saving model to .\\RNN3_best_model.h5\n",
      "1702/1702 [==============================] - 74s 44ms/step - loss: 22.8734 - mae: 22.8734 - val_loss: 23.2843 - val_mae: 23.2843\n",
      "Epoch 22/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 22.8456 - mae: 22.8456\n",
      "Epoch 22: val_mae did not improve from 23.28429\n",
      "1702/1702 [==============================] - 72s 42ms/step - loss: 22.8456 - mae: 22.8456 - val_loss: 23.4856 - val_mae: 23.4856\n",
      "Epoch 23/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 22.8018 - mae: 22.8018\n",
      "Epoch 23: val_mae improved from 23.28429 to 23.14268, saving model to .\\RNN3_best_model.h5\n",
      "1702/1702 [==============================] - 72s 42ms/step - loss: 22.8017 - mae: 22.8017 - val_loss: 23.1427 - val_mae: 23.1427\n",
      "Epoch 24/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 22.7679 - mae: 22.7679\n",
      "Epoch 24: val_mae did not improve from 23.14268\n",
      "1702/1702 [==============================] - 72s 42ms/step - loss: 22.7679 - mae: 22.7679 - val_loss: 23.3074 - val_mae: 23.3074\n",
      "Epoch 25/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 22.7363 - mae: 22.7363\n",
      "Epoch 25: val_mae did not improve from 23.14268\n",
      "1702/1702 [==============================] - 72s 42ms/step - loss: 22.7363 - mae: 22.7363 - val_loss: 23.4547 - val_mae: 23.4547\n",
      "Epoch 26/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 22.7056 - mae: 22.7056\n",
      "Epoch 26: val_mae improved from 23.14268 to 23.13989, saving model to .\\RNN3_best_model.h5\n",
      "1702/1702 [==============================] - 74s 43ms/step - loss: 22.7056 - mae: 22.7056 - val_loss: 23.1399 - val_mae: 23.1399\n",
      "Epoch 27/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 22.6718 - mae: 22.6718\n",
      "Epoch 27: val_mae improved from 23.13989 to 23.02766, saving model to .\\RNN3_best_model.h5\n",
      "1702/1702 [==============================] - 75s 44ms/step - loss: 22.6718 - mae: 22.6718 - val_loss: 23.0277 - val_mae: 23.0277\n",
      "Epoch 28/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 22.6389 - mae: 22.6389\n",
      "Epoch 28: val_mae improved from 23.02766 to 22.96411, saving model to .\\RNN3_best_model.h5\n",
      "1702/1702 [==============================] - 75s 44ms/step - loss: 22.6392 - mae: 22.6392 - val_loss: 22.9641 - val_mae: 22.9641\n",
      "Epoch 29/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 22.6002 - mae: 22.6002\n",
      "Epoch 29: val_mae improved from 22.96411 to 22.92835, saving model to .\\RNN3_best_model.h5\n",
      "1702/1702 [==============================] - 74s 44ms/step - loss: 22.6001 - mae: 22.6001 - val_loss: 22.9283 - val_mae: 22.9283\n",
      "Epoch 30/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 22.5598 - mae: 22.5598\n",
      "Epoch 30: val_mae did not improve from 22.92835\n",
      "1702/1702 [==============================] - 73s 43ms/step - loss: 22.5598 - mae: 22.5598 - val_loss: 23.1101 - val_mae: 23.1101\n",
      "Epoch 31/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 22.5242 - mae: 22.5242\n",
      "Epoch 31: val_mae did not improve from 22.92835\n",
      "1702/1702 [==============================] - 72s 42ms/step - loss: 22.5242 - mae: 22.5242 - val_loss: 23.3629 - val_mae: 23.3629\n",
      "Epoch 32/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 22.4866 - mae: 22.4866\n",
      "Epoch 32: val_mae improved from 22.92835 to 22.77896, saving model to .\\RNN3_best_model.h5\n",
      "1702/1702 [==============================] - 72s 42ms/step - loss: 22.4867 - mae: 22.4867 - val_loss: 22.7790 - val_mae: 22.7790\n",
      "Epoch 33/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 22.4599 - mae: 22.4599\n",
      "Epoch 33: val_mae improved from 22.77896 to 22.75919, saving model to .\\RNN3_best_model.h5\n",
      "1702/1702 [==============================] - 71s 41ms/step - loss: 22.4599 - mae: 22.4599 - val_loss: 22.7592 - val_mae: 22.7592\n",
      "Epoch 34/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 22.4309 - mae: 22.4309\n",
      "Epoch 34: val_mae did not improve from 22.75919\n",
      "1702/1702 [==============================] - 71s 42ms/step - loss: 22.4309 - mae: 22.4309 - val_loss: 23.1394 - val_mae: 23.1394\n",
      "Epoch 35/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 22.3937 - mae: 22.3937\n",
      "Epoch 35: val_mae improved from 22.75919 to 22.71873, saving model to .\\RNN3_best_model.h5\n",
      "1702/1702 [==============================] - 71s 42ms/step - loss: 22.3936 - mae: 22.3936 - val_loss: 22.7187 - val_mae: 22.7187\n",
      "Epoch 36/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 22.3565 - mae: 22.3565\n",
      "Epoch 36: val_mae did not improve from 22.71873\n",
      "1702/1702 [==============================] - 71s 42ms/step - loss: 22.3564 - mae: 22.3564 - val_loss: 23.0833 - val_mae: 23.0833\n",
      "Epoch 37/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 22.3418 - mae: 22.3418\n",
      "Epoch 37: val_mae improved from 22.71873 to 22.63947, saving model to .\\RNN3_best_model.h5\n",
      "1702/1702 [==============================] - 70s 41ms/step - loss: 22.3418 - mae: 22.3418 - val_loss: 22.6395 - val_mae: 22.6395\n",
      "Epoch 38/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 22.3250 - mae: 22.3250\n",
      "Epoch 38: val_mae did not improve from 22.63947\n",
      "1702/1702 [==============================] - 71s 42ms/step - loss: 22.3250 - mae: 22.3250 - val_loss: 22.7677 - val_mae: 22.7677\n",
      "Epoch 39/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 22.3094 - mae: 22.3094\n",
      "Epoch 39: val_mae did not improve from 22.63947\n",
      "1702/1702 [==============================] - 72s 42ms/step - loss: 22.3094 - mae: 22.3094 - val_loss: 22.6605 - val_mae: 22.6605\n",
      "Epoch 40/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 22.2834 - mae: 22.2834\n",
      "Epoch 40: val_mae did not improve from 22.63947\n",
      "1702/1702 [==============================] - 73s 43ms/step - loss: 22.2833 - mae: 22.2833 - val_loss: 22.6466 - val_mae: 22.6466\n",
      "Epoch 41/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 22.2787 - mae: 22.2787\n",
      "Epoch 41: val_mae did not improve from 22.63947\n",
      "1702/1702 [==============================] - 73s 43ms/step - loss: 22.2788 - mae: 22.2788 - val_loss: 22.7904 - val_mae: 22.7904\n",
      "Epoch 42/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 22.2518 - mae: 22.2518\n",
      "Epoch 42: val_mae improved from 22.63947 to 22.53737, saving model to .\\RNN3_best_model.h5\n",
      "1702/1702 [==============================] - 74s 43ms/step - loss: 22.2518 - mae: 22.2518 - val_loss: 22.5374 - val_mae: 22.5374\n",
      "Epoch 43/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 22.2348 - mae: 22.2348\n",
      "Epoch 43: val_mae did not improve from 22.53737\n",
      "1702/1702 [==============================] - 74s 43ms/step - loss: 22.2348 - mae: 22.2348 - val_loss: 22.7689 - val_mae: 22.7689\n",
      "Epoch 44/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 22.2272 - mae: 22.2272\n",
      "Epoch 44: val_mae did not improve from 22.53737\n",
      "1702/1702 [==============================] - 72s 42ms/step - loss: 22.2272 - mae: 22.2272 - val_loss: 22.9000 - val_mae: 22.9000\n",
      "Epoch 45/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 22.2105 - mae: 22.2105\n",
      "Epoch 45: val_mae did not improve from 22.53737\n",
      "1702/1702 [==============================] - 74s 43ms/step - loss: 22.2105 - mae: 22.2105 - val_loss: 22.5617 - val_mae: 22.5617\n",
      "Epoch 46/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 22.1993 - mae: 22.1993\n",
      "Epoch 46: val_mae improved from 22.53737 to 22.51825, saving model to .\\RNN3_best_model.h5\n",
      "1702/1702 [==============================] - 74s 43ms/step - loss: 22.1993 - mae: 22.1993 - val_loss: 22.5182 - val_mae: 22.5182\n",
      "Epoch 47/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 22.1983 - mae: 22.1983\n",
      "Epoch 47: val_mae did not improve from 22.51825\n",
      "1702/1702 [==============================] - 74s 43ms/step - loss: 22.1983 - mae: 22.1983 - val_loss: 22.5387 - val_mae: 22.5387\n",
      "Epoch 48/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 22.1884 - mae: 22.1884\n",
      "Epoch 48: val_mae improved from 22.51825 to 22.47110, saving model to .\\RNN3_best_model.h5\n",
      "1702/1702 [==============================] - 76s 44ms/step - loss: 22.1882 - mae: 22.1882 - val_loss: 22.4711 - val_mae: 22.4711\n",
      "Epoch 49/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 22.1760 - mae: 22.1760\n",
      "Epoch 49: val_mae did not improve from 22.47110\n",
      "1702/1702 [==============================] - 76s 44ms/step - loss: 22.1758 - mae: 22.1758 - val_loss: 22.5393 - val_mae: 22.5393\n",
      "Epoch 50/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 22.1715 - mae: 22.1715\n",
      "Epoch 50: val_mae did not improve from 22.47110\n",
      "1702/1702 [==============================] - 75s 44ms/step - loss: 22.1715 - mae: 22.1715 - val_loss: 22.6387 - val_mae: 22.6387\n",
      "Epoch 51/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 22.1634 - mae: 22.1634\n",
      "Epoch 51: val_mae did not improve from 22.47110\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 22.1634 - mae: 22.1634 - val_loss: 22.4964 - val_mae: 22.4964\n",
      "Epoch 52/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 22.1623 - mae: 22.1623\n",
      "Epoch 52: val_mae did not improve from 22.47110\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 22.1625 - mae: 22.1625 - val_loss: 22.6100 - val_mae: 22.6100\n",
      "Epoch 53/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 22.1494 - mae: 22.1494\n",
      "Epoch 53: val_mae did not improve from 22.47110\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 22.1495 - mae: 22.1495 - val_loss: 22.5346 - val_mae: 22.5346\n",
      "Epoch 54/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 22.1418 - mae: 22.1418\n",
      "Epoch 54: val_mae did not improve from 22.47110\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 22.1418 - mae: 22.1418 - val_loss: 22.8892 - val_mae: 22.8892\n",
      "Epoch 55/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 22.1328 - mae: 22.1328\n",
      "Epoch 55: val_mae did not improve from 22.47110\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 22.1329 - mae: 22.1329 - val_loss: 22.9091 - val_mae: 22.9091\n",
      "Epoch 56/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 22.1334 - mae: 22.1334\n",
      "Epoch 56: val_mae did not improve from 22.47110\n",
      "1702/1702 [==============================] - 77s 45ms/step - loss: 22.1331 - mae: 22.1331 - val_loss: 22.6373 - val_mae: 22.6373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 22.1310 - mae: 22.1310\n",
      "Epoch 57: val_mae improved from 22.47110 to 22.42070, saving model to .\\RNN3_best_model.h5\n",
      "1702/1702 [==============================] - 77s 45ms/step - loss: 22.1310 - mae: 22.1310 - val_loss: 22.4207 - val_mae: 22.4207\n",
      "Epoch 58/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 22.1083 - mae: 22.1083\n",
      "Epoch 58: val_mae did not improve from 22.42070\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 22.1083 - mae: 22.1083 - val_loss: 22.4349 - val_mae: 22.4349\n",
      "Epoch 59/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 22.1216 - mae: 22.1216\n",
      "Epoch 59: val_mae did not improve from 22.42070\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 22.1217 - mae: 22.1217 - val_loss: 22.4363 - val_mae: 22.4363\n",
      "Epoch 60/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 22.1066 - mae: 22.1066\n",
      "Epoch 60: val_mae did not improve from 22.42070\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 22.1066 - mae: 22.1066 - val_loss: 22.4711 - val_mae: 22.4711\n",
      "Epoch 61/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 22.1109 - mae: 22.1109\n",
      "Epoch 61: val_mae did not improve from 22.42070\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 22.1110 - mae: 22.1110 - val_loss: 22.6004 - val_mae: 22.6004\n",
      "Epoch 62/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 22.0909 - mae: 22.0909\n",
      "Epoch 62: val_mae did not improve from 22.42070\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 22.0909 - mae: 22.0909 - val_loss: 22.4319 - val_mae: 22.4319\n",
      "Epoch 63/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 22.1021 - mae: 22.1021\n",
      "Epoch 63: val_mae improved from 22.42070 to 22.40178, saving model to .\\RNN3_best_model.h5\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 22.1021 - mae: 22.1021 - val_loss: 22.4018 - val_mae: 22.4018\n",
      "Epoch 64/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 22.0865 - mae: 22.0865\n",
      "Epoch 64: val_mae did not improve from 22.40178\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 22.0865 - mae: 22.0865 - val_loss: 22.4721 - val_mae: 22.4721\n",
      "Epoch 65/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 22.0917 - mae: 22.0917\n",
      "Epoch 65: val_mae did not improve from 22.40178\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 22.0917 - mae: 22.0917 - val_loss: 22.4210 - val_mae: 22.4210\n",
      "Epoch 66/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 22.0733 - mae: 22.0733\n",
      "Epoch 66: val_mae did not improve from 22.40178\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 22.0732 - mae: 22.0732 - val_loss: 22.5452 - val_mae: 22.5452\n",
      "Epoch 67/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 22.0674 - mae: 22.0674\n",
      "Epoch 67: val_mae did not improve from 22.40178\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 22.0674 - mae: 22.0674 - val_loss: 22.5434 - val_mae: 22.5434\n",
      "Epoch 68/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 22.0744 - mae: 22.0744\n",
      "Epoch 68: val_mae did not improve from 22.40178\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 22.0745 - mae: 22.0745 - val_loss: 22.4137 - val_mae: 22.4137\n",
      "Epoch 69/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 22.0643 - mae: 22.0643\n",
      "Epoch 69: val_mae did not improve from 22.40178\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 22.0643 - mae: 22.0643 - val_loss: 22.5060 - val_mae: 22.5060\n",
      "Epoch 70/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 22.0495 - mae: 22.0495\n",
      "Epoch 70: val_mae did not improve from 22.40178\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 22.0494 - mae: 22.0494 - val_loss: 22.7479 - val_mae: 22.7479\n",
      "Epoch 71/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 22.0415 - mae: 22.0415\n",
      "Epoch 71: val_mae did not improve from 22.40178\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 22.0415 - mae: 22.0415 - val_loss: 22.5427 - val_mae: 22.5427\n",
      "Epoch 72/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 22.0482 - mae: 22.0482\n",
      "Epoch 72: val_mae did not improve from 22.40178\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 22.0482 - mae: 22.0482 - val_loss: 22.4654 - val_mae: 22.4654\n",
      "Epoch 73/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 22.0466 - mae: 22.0466\n",
      "Epoch 73: val_mae improved from 22.40178 to 22.35211, saving model to .\\RNN3_best_model.h5\n",
      "1702/1702 [==============================] - 77s 45ms/step - loss: 22.0467 - mae: 22.0467 - val_loss: 22.3521 - val_mae: 22.3521\n",
      "Epoch 74/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 22.0297 - mae: 22.0297\n",
      "Epoch 74: val_mae did not improve from 22.35211\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 22.0297 - mae: 22.0297 - val_loss: 22.8268 - val_mae: 22.8268\n",
      "Epoch 75/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 22.0317 - mae: 22.0317\n",
      "Epoch 75: val_mae did not improve from 22.35211\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 22.0317 - mae: 22.0317 - val_loss: 22.6231 - val_mae: 22.6231\n",
      "Epoch 76/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 22.0390 - mae: 22.0390\n",
      "Epoch 76: val_mae did not improve from 22.35211\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 22.0390 - mae: 22.0390 - val_loss: 22.4079 - val_mae: 22.4079\n",
      "Epoch 77/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 22.0169 - mae: 22.0169\n",
      "Epoch 77: val_mae improved from 22.35211 to 22.32522, saving model to .\\RNN3_best_model.h5\n",
      "1702/1702 [==============================] - 77s 45ms/step - loss: 22.0169 - mae: 22.0169 - val_loss: 22.3252 - val_mae: 22.3252\n",
      "Epoch 78/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 22.0204 - mae: 22.0204\n",
      "Epoch 78: val_mae did not improve from 22.32522\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 22.0202 - mae: 22.0202 - val_loss: 22.4936 - val_mae: 22.4936\n",
      "Epoch 79/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 22.0216 - mae: 22.0216\n",
      "Epoch 79: val_mae did not improve from 22.32522\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 22.0216 - mae: 22.0216 - val_loss: 22.4216 - val_mae: 22.4216\n",
      "Epoch 80/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 22.0089 - mae: 22.0089\n",
      "Epoch 80: val_mae did not improve from 22.32522\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 22.0090 - mae: 22.0090 - val_loss: 22.4240 - val_mae: 22.4240\n",
      "Epoch 81/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 21.9971 - mae: 21.9971\n",
      "Epoch 81: val_mae did not improve from 22.32522\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 21.9971 - mae: 21.9971 - val_loss: 22.6782 - val_mae: 22.6782\n",
      "Epoch 82/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 21.9970 - mae: 21.9970\n",
      "Epoch 82: val_mae did not improve from 22.32522\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 21.9969 - mae: 21.9969 - val_loss: 22.5801 - val_mae: 22.5801\n",
      "Epoch 83/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 22.0003 - mae: 22.0003\n",
      "Epoch 83: val_mae improved from 22.32522 to 22.32244, saving model to .\\RNN3_best_model.h5\n",
      "1702/1702 [==============================] - 77s 45ms/step - loss: 22.0003 - mae: 22.0003 - val_loss: 22.3224 - val_mae: 22.3224\n",
      "Epoch 84/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 21.9938 - mae: 21.9938\n",
      "Epoch 84: val_mae did not improve from 22.32244\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 21.9938 - mae: 21.9938 - val_loss: 22.3229 - val_mae: 22.3229\n",
      "Epoch 85/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 21.9786 - mae: 21.9786\n",
      "Epoch 85: val_mae did not improve from 22.32244\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 21.9786 - mae: 21.9786 - val_loss: 22.5217 - val_mae: 22.5217\n",
      "Epoch 86/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 21.9897 - mae: 21.9897\n",
      "Epoch 86: val_mae did not improve from 22.32244\n",
      "1702/1702 [==============================] - 77s 45ms/step - loss: 21.9897 - mae: 21.9897 - val_loss: 22.3434 - val_mae: 22.3434\n",
      "Epoch 87/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 21.9770 - mae: 21.9770\n",
      "Epoch 87: val_mae improved from 22.32244 to 22.31792, saving model to .\\RNN3_best_model.h5\n",
      "1702/1702 [==============================] - 77s 45ms/step - loss: 21.9770 - mae: 21.9770 - val_loss: 22.3179 - val_mae: 22.3179\n",
      "Epoch 88/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 21.9725 - mae: 21.9725\n",
      "Epoch 88: val_mae did not improve from 22.31792\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 21.9722 - mae: 21.9722 - val_loss: 22.6846 - val_mae: 22.6846\n",
      "Epoch 89/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 21.9631 - mae: 21.9631\n",
      "Epoch 89: val_mae did not improve from 22.31792\n",
      "1702/1702 [==============================] - 77s 45ms/step - loss: 21.9631 - mae: 21.9631 - val_loss: 22.3327 - val_mae: 22.3327\n",
      "Epoch 90/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 21.9594 - mae: 21.9594\n",
      "Epoch 90: val_mae did not improve from 22.31792\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 21.9594 - mae: 21.9594 - val_loss: 22.4320 - val_mae: 22.4320\n",
      "Epoch 91/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 21.9489 - mae: 21.9489\n",
      "Epoch 91: val_mae did not improve from 22.31792\n",
      "1702/1702 [==============================] - 77s 45ms/step - loss: 21.9488 - mae: 21.9488 - val_loss: 22.3308 - val_mae: 22.3308\n",
      "Epoch 92/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 21.9576 - mae: 21.9576\n",
      "Epoch 92: val_mae did not improve from 22.31792\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 21.9576 - mae: 21.9576 - val_loss: 22.3544 - val_mae: 22.3544\n",
      "Epoch 93/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 21.9459 - mae: 21.9459\n",
      "Epoch 93: val_mae did not improve from 22.31792\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 21.9459 - mae: 21.9459 - val_loss: 22.4049 - val_mae: 22.4049\n",
      "Epoch 94/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 21.9537 - mae: 21.9537\n",
      "Epoch 94: val_mae improved from 22.31792 to 22.31007, saving model to .\\RNN3_best_model.h5\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 21.9540 - mae: 21.9540 - val_loss: 22.3101 - val_mae: 22.3101\n",
      "Epoch 95/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 21.9430 - mae: 21.9430\n",
      "Epoch 95: val_mae did not improve from 22.31007\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 21.9430 - mae: 21.9430 - val_loss: 22.3807 - val_mae: 22.3807\n",
      "Epoch 96/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 21.9335 - mae: 21.9335\n",
      "Epoch 96: val_mae did not improve from 22.31007\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 21.9335 - mae: 21.9335 - val_loss: 22.5864 - val_mae: 22.5864\n",
      "Epoch 97/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 21.9326 - mae: 21.9326\n",
      "Epoch 97: val_mae did not improve from 22.31007\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 21.9326 - mae: 21.9326 - val_loss: 22.3662 - val_mae: 22.3662\n",
      "Epoch 98/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 21.9313 - mae: 21.9313\n",
      "Epoch 98: val_mae did not improve from 22.31007\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 21.9313 - mae: 21.9313 - val_loss: 22.3127 - val_mae: 22.3127\n",
      "Epoch 99/100\n",
      "1702/1702 [==============================] - ETA: 0s - loss: 21.9275 - mae: 21.9275\n",
      "Epoch 99: val_mae improved from 22.31007 to 22.29933, saving model to .\\RNN3_best_model.h5\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 21.9275 - mae: 21.9275 - val_loss: 22.2993 - val_mae: 22.2993\n",
      "Epoch 100/100\n",
      "1701/1702 [============================>.] - ETA: 0s - loss: 21.9120 - mae: 21.9120\n",
      "Epoch 100: val_mae did not improve from 22.29933\n",
      "1702/1702 [==============================] - 76s 45ms/step - loss: 21.9122 - mae: 21.9122 - val_loss: 22.5703 - val_mae: 22.5703\n"
     ]
    }
   ],
   "source": [
    "random_seed = 15\n",
    "tf.keras.utils.set_random_seed(random_seed)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "file_path = './RNN3_best_model.h5'\n",
    "checkpoint = ModelCheckpoint(file_path,\n",
    "                            monitor = 'val_mae',\n",
    "                            verbose=1,\n",
    "                            save_best_only=True,\n",
    "                            mode='auto')  \n",
    "\n",
    "hist = model.fit(x_train, y_train, validation_data=(x_test, y_test), \n",
    "                 epochs=100, batch_size=16, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bcd19a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 [==============================] - 3s 11ms/step - loss: 22.2993 - mae: 22.2993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[22.2993221282959, 22.2993221282959]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN3_model = tf.keras.models.load_model('./RNN3_best_model.h5')\n",
    "RNN3_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b367385d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264/264 [==============================] - 3s 10ms/step\n"
     ]
    }
   ],
   "source": [
    "RNN3_pred = RNN3_model.predict(submission_x)\n",
    "pd.DataFrame(RNN3_pred).to_csv('RNN3_pred.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81b9cc0",
   "metadata": {},
   "source": [
    "## RNN6 / window size 192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8afe1d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27271, 192, 1) (27271, 336) (7896, 192, 1) (7896, 336) (8425, 192, 1) (8425, 336)\n"
     ]
    }
   ],
   "source": [
    "pre_day = 24 # (31 - pre_month) * 24 = windowsize /27 : 96//28 : 72//29 : 48//30 : 24//\n",
    "x_train, y_train, x_test, y_test, submission_x, submission_y = DataProcessing.data_form_descision(train_df, test_df, pre_day)\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape, submission_x.shape, submission_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7dd808e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_15 (SimpleRNN)   (None, 192, 64)           4224      \n",
      "                                                                 \n",
      " simple_rnn_16 (SimpleRNN)   (None, 192, 32)           3104      \n",
      "                                                                 \n",
      " simple_rnn_17 (SimpleRNN)   (None, 16)                784       \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 64)                1088      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 336)               11088     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,368\n",
      "Trainable params: 22,368\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "initializer = tf.keras.initializers.GlorotNormal(seed=15)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(64, activation='relu', input_shape=(x_train[0].shape), \n",
    "               return_sequences=True, kernel_initializer=initializer))\n",
    "model.add(SimpleRNN(32, activation='relu',return_sequences=True, kernel_initializer=initializer))\n",
    "model.add(SimpleRNN(16, activation='relu', kernel_initializer=initializer))\n",
    "model.add(Dense(64, activation='relu', kernel_initializer=initializer))\n",
    "model.add(Dense(32, activation='relu', kernel_initializer=initializer))\n",
    "model.add(Dense(336, activation='linear', kernel_initializer=initializer))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0008)\n",
    "model.compile(loss='mae', optimizer=optimizer, metrics=['mae'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1b2c7846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 29.0948 - mae: 29.0948\n",
      "Epoch 1: val_mae improved from inf to 23.90384, saving model to .\\RNN6_best_model.h5\n",
      "1705/1705 [==============================] - 57s 32ms/step - loss: 29.0948 - mae: 29.0948 - val_loss: 23.9038 - val_mae: 23.9038\n",
      "Epoch 2/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 25.1454 - mae: 25.1454\n",
      "Epoch 2: val_mae did not improve from 23.90384\n",
      "1705/1705 [==============================] - 55s 32ms/step - loss: 25.1454 - mae: 25.1454 - val_loss: 25.2738 - val_mae: 25.2738\n",
      "Epoch 3/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 23.3222 - mae: 23.3222\n",
      "Epoch 3: val_mae improved from 23.90384 to 23.04234, saving model to .\\RNN6_best_model.h5\n",
      "1705/1705 [==============================] - 55s 32ms/step - loss: 23.3223 - mae: 23.3223 - val_loss: 23.0423 - val_mae: 23.0423\n",
      "Epoch 4/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 22.6920 - mae: 22.6920\n",
      "Epoch 4: val_mae improved from 23.04234 to 22.96283, saving model to .\\RNN6_best_model.h5\n",
      "1705/1705 [==============================] - 55s 32ms/step - loss: 22.6920 - mae: 22.6920 - val_loss: 22.9628 - val_mae: 22.9628\n",
      "Epoch 5/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 22.4588 - mae: 22.4588\n",
      "Epoch 5: val_mae improved from 22.96283 to 22.85033, saving model to .\\RNN6_best_model.h5\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 22.4588 - mae: 22.4588 - val_loss: 22.8503 - val_mae: 22.8503\n",
      "Epoch 6/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 22.3634 - mae: 22.3634\n",
      "Epoch 6: val_mae improved from 22.85033 to 22.72001, saving model to .\\RNN6_best_model.h5\n",
      "1705/1705 [==============================] - 56s 33ms/step - loss: 22.3632 - mae: 22.3632 - val_loss: 22.7200 - val_mae: 22.7200\n",
      "Epoch 7/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 22.2542 - mae: 22.2542\n",
      "Epoch 7: val_mae did not improve from 22.72001\n",
      "1705/1705 [==============================] - 56s 33ms/step - loss: 22.2544 - mae: 22.2544 - val_loss: 22.7727 - val_mae: 22.7727\n",
      "Epoch 8/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 22.1579 - mae: 22.1579\n",
      "Epoch 8: val_mae improved from 22.72001 to 22.47517, saving model to .\\RNN6_best_model.h5\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 22.1579 - mae: 22.1579 - val_loss: 22.4752 - val_mae: 22.4752\n",
      "Epoch 9/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 22.0892 - mae: 22.0892\n",
      "Epoch 9: val_mae improved from 22.47517 to 22.44015, saving model to .\\RNN6_best_model.h5\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 22.0892 - mae: 22.0892 - val_loss: 22.4402 - val_mae: 22.4402\n",
      "Epoch 10/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 22.0149 - mae: 22.0149\n",
      "Epoch 10: val_mae did not improve from 22.44015\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 22.0148 - mae: 22.0148 - val_loss: 22.4740 - val_mae: 22.4740\n",
      "Epoch 11/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 22.0005 - mae: 22.0005\n",
      "Epoch 11: val_mae did not improve from 22.44015\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 22.0006 - mae: 22.0006 - val_loss: 22.5167 - val_mae: 22.5167\n",
      "Epoch 12/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.9534 - mae: 21.9534\n",
      "Epoch 12: val_mae did not improve from 22.44015\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.9534 - mae: 21.9534 - val_loss: 22.5317 - val_mae: 22.5317\n",
      "Epoch 13/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.9202 - mae: 21.9202\n",
      "Epoch 13: val_mae did not improve from 22.44015\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.9202 - mae: 21.9202 - val_loss: 22.7759 - val_mae: 22.7759\n",
      "Epoch 14/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.8881 - mae: 21.8881\n",
      "Epoch 14: val_mae improved from 22.44015 to 22.41467, saving model to .\\RNN6_best_model.h5\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.8881 - mae: 21.8881 - val_loss: 22.4147 - val_mae: 22.4147\n",
      "Epoch 15/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.8558 - mae: 21.8558\n",
      "Epoch 15: val_mae did not improve from 22.41467\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.8558 - mae: 21.8558 - val_loss: 22.4476 - val_mae: 22.4476\n",
      "Epoch 16/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.8760 - mae: 21.8760\n",
      "Epoch 16: val_mae did not improve from 22.41467\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.8760 - mae: 21.8760 - val_loss: 22.7260 - val_mae: 22.7260\n",
      "Epoch 17/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.8497 - mae: 21.8497\n",
      "Epoch 17: val_mae improved from 22.41467 to 22.30109, saving model to .\\RNN6_best_model.h5\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.8497 - mae: 21.8497 - val_loss: 22.3011 - val_mae: 22.3011\n",
      "Epoch 18/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.8013 - mae: 21.8013\n",
      "Epoch 18: val_mae did not improve from 22.30109\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.8013 - mae: 21.8013 - val_loss: 22.4065 - val_mae: 22.4065\n",
      "Epoch 19/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.7907 - mae: 21.7907\n",
      "Epoch 19: val_mae did not improve from 22.30109\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.7907 - mae: 21.7907 - val_loss: 22.3749 - val_mae: 22.3749\n",
      "Epoch 20/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.7601 - mae: 21.7601\n",
      "Epoch 20: val_mae did not improve from 22.30109\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.7601 - mae: 21.7601 - val_loss: 23.8294 - val_mae: 23.8294\n",
      "Epoch 21/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.7270 - mae: 21.7270\n",
      "Epoch 21: val_mae did not improve from 22.30109\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.7270 - mae: 21.7270 - val_loss: 23.2646 - val_mae: 23.2646\n",
      "Epoch 22/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.7085 - mae: 21.7085\n",
      "Epoch 22: val_mae did not improve from 22.30109\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.7085 - mae: 21.7085 - val_loss: 23.4265 - val_mae: 23.4265\n",
      "Epoch 23/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.6998 - mae: 21.6998\n",
      "Epoch 23: val_mae did not improve from 22.30109\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.6995 - mae: 21.6995 - val_loss: 22.4277 - val_mae: 22.4277\n",
      "Epoch 24/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.6653 - mae: 21.6653\n",
      "Epoch 24: val_mae improved from 22.30109 to 22.26663, saving model to .\\RNN6_best_model.h5\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.6653 - mae: 21.6653 - val_loss: 22.2666 - val_mae: 22.2666\n",
      "Epoch 25/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.6368 - mae: 21.6368\n",
      "Epoch 25: val_mae did not improve from 22.26663\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.6369 - mae: 21.6369 - val_loss: 22.3891 - val_mae: 22.3891\n",
      "Epoch 26/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.6371 - mae: 21.6371\n",
      "Epoch 26: val_mae did not improve from 22.26663\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.6371 - mae: 21.6371 - val_loss: 24.6362 - val_mae: 24.6362\n",
      "Epoch 27/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.6070 - mae: 21.6070\n",
      "Epoch 27: val_mae did not improve from 22.26663\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.6069 - mae: 21.6069 - val_loss: 22.9140 - val_mae: 22.9140\n",
      "Epoch 28/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 22.0087 - mae: 22.0087\n",
      "Epoch 28: val_mae did not improve from 22.26663\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 22.0089 - mae: 22.0089 - val_loss: 22.2697 - val_mae: 22.2697\n",
      "Epoch 29/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.9197 - mae: 21.9197\n",
      "Epoch 29: val_mae did not improve from 22.26663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.9197 - mae: 21.9197 - val_loss: 22.6502 - val_mae: 22.6502\n",
      "Epoch 30/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.8544 - mae: 21.8544\n",
      "Epoch 30: val_mae did not improve from 22.26663\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.8544 - mae: 21.8544 - val_loss: 22.9571 - val_mae: 22.9571\n",
      "Epoch 31/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.7366 - mae: 21.7366\n",
      "Epoch 31: val_mae did not improve from 22.26663\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.7368 - mae: 21.7368 - val_loss: 22.4453 - val_mae: 22.4453\n",
      "Epoch 32/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.7145 - mae: 21.7145\n",
      "Epoch 32: val_mae did not improve from 22.26663\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.7145 - mae: 21.7145 - val_loss: 22.2895 - val_mae: 22.2895\n",
      "Epoch 33/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.6807 - mae: 21.6807\n",
      "Epoch 33: val_mae did not improve from 22.26663\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.6807 - mae: 21.6807 - val_loss: 22.9464 - val_mae: 22.9464\n",
      "Epoch 34/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.6742 - mae: 21.6742\n",
      "Epoch 34: val_mae did not improve from 22.26663\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.6741 - mae: 21.6741 - val_loss: 22.9977 - val_mae: 22.9977\n",
      "Epoch 35/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.6765 - mae: 21.6765\n",
      "Epoch 35: val_mae did not improve from 22.26663\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.6766 - mae: 21.6766 - val_loss: 22.6068 - val_mae: 22.6068\n",
      "Epoch 36/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.6452 - mae: 21.6452\n",
      "Epoch 36: val_mae did not improve from 22.26663\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.6453 - mae: 21.6453 - val_loss: 23.4254 - val_mae: 23.4254\n",
      "Epoch 37/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 22.2144 - mae: 22.2144\n",
      "Epoch 37: val_mae did not improve from 22.26663\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 22.2144 - mae: 22.2144 - val_loss: 25.2165 - val_mae: 25.2165\n",
      "Epoch 38/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 22.0619 - mae: 22.0619\n",
      "Epoch 38: val_mae did not improve from 22.26663\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 22.0619 - mae: 22.0619 - val_loss: 22.8286 - val_mae: 22.8286\n",
      "Epoch 39/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.9722 - mae: 21.9722\n",
      "Epoch 39: val_mae did not improve from 22.26663\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.9724 - mae: 21.9724 - val_loss: 22.5083 - val_mae: 22.5083\n",
      "Epoch 40/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.9526 - mae: 21.9526\n",
      "Epoch 40: val_mae did not improve from 22.26663\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.9523 - mae: 21.9523 - val_loss: 23.3865 - val_mae: 23.3865\n",
      "Epoch 41/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.8906 - mae: 21.8906\n",
      "Epoch 41: val_mae did not improve from 22.26663\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.8906 - mae: 21.8906 - val_loss: 22.2943 - val_mae: 22.2943\n",
      "Epoch 42/100\n",
      "1703/1705 [============================>.] - ETA: 0s - loss: 21.8491 - mae: 21.8491\n",
      "Epoch 42: val_mae did not improve from 22.26663\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.8489 - mae: 21.8489 - val_loss: 22.3837 - val_mae: 22.3837\n",
      "Epoch 43/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.8282 - mae: 21.8282\n",
      "Epoch 43: val_mae did not improve from 22.26663\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.8282 - mae: 21.8282 - val_loss: 22.2952 - val_mae: 22.2952\n",
      "Epoch 44/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.7936 - mae: 21.7936\n",
      "Epoch 44: val_mae did not improve from 22.26663\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.7936 - mae: 21.7936 - val_loss: 22.5335 - val_mae: 22.5335\n",
      "Epoch 45/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.7665 - mae: 21.7665\n",
      "Epoch 45: val_mae did not improve from 22.26663\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.7666 - mae: 21.7666 - val_loss: 22.8277 - val_mae: 22.8277\n",
      "Epoch 46/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.8078 - mae: 21.8078\n",
      "Epoch 46: val_mae improved from 22.26663 to 22.19493, saving model to .\\RNN6_best_model.h5\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.8077 - mae: 21.8077 - val_loss: 22.1949 - val_mae: 22.1949\n",
      "Epoch 47/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.7300 - mae: 21.7300\n",
      "Epoch 47: val_mae did not improve from 22.19493\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.7300 - mae: 21.7300 - val_loss: 22.4989 - val_mae: 22.4989\n",
      "Epoch 48/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.7147 - mae: 21.7147\n",
      "Epoch 48: val_mae did not improve from 22.19493\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.7147 - mae: 21.7147 - val_loss: 22.7247 - val_mae: 22.7247\n",
      "Epoch 49/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.6888 - mae: 21.6888\n",
      "Epoch 49: val_mae did not improve from 22.19493\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.6888 - mae: 21.6888 - val_loss: 22.3356 - val_mae: 22.3356\n",
      "Epoch 50/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.6866 - mae: 21.6866\n",
      "Epoch 50: val_mae did not improve from 22.19493\n",
      "1705/1705 [==============================] - 55s 32ms/step - loss: 21.6865 - mae: 21.6865 - val_loss: 22.5480 - val_mae: 22.5480\n",
      "Epoch 51/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.6751 - mae: 21.6751\n",
      "Epoch 51: val_mae did not improve from 22.19493\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.6748 - mae: 21.6748 - val_loss: 22.2320 - val_mae: 22.2320\n",
      "Epoch 52/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.6478 - mae: 21.6478\n",
      "Epoch 52: val_mae did not improve from 22.19493\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.6478 - mae: 21.6478 - val_loss: 22.8506 - val_mae: 22.8506\n",
      "Epoch 53/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.6416 - mae: 21.6416\n",
      "Epoch 53: val_mae did not improve from 22.19493\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.6416 - mae: 21.6416 - val_loss: 22.2663 - val_mae: 22.2663\n",
      "Epoch 54/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.6134 - mae: 21.6134\n",
      "Epoch 54: val_mae did not improve from 22.19493\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.6134 - mae: 21.6134 - val_loss: 22.8627 - val_mae: 22.8627\n",
      "Epoch 55/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.5989 - mae: 21.5989\n",
      "Epoch 55: val_mae did not improve from 22.19493\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.5991 - mae: 21.5991 - val_loss: 22.3720 - val_mae: 22.3720\n",
      "Epoch 56/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.6461 - mae: 21.6461\n",
      "Epoch 56: val_mae did not improve from 22.19493\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.6460 - mae: 21.6460 - val_loss: 22.8891 - val_mae: 22.8891\n",
      "Epoch 57/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.6071 - mae: 21.6071\n",
      "Epoch 57: val_mae did not improve from 22.19493\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.6071 - mae: 21.6071 - val_loss: 22.4170 - val_mae: 22.4170\n",
      "Epoch 58/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.6047 - mae: 21.6047\n",
      "Epoch 58: val_mae improved from 22.19493 to 22.15073, saving model to .\\RNN6_best_model.h5\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.6048 - mae: 21.6048 - val_loss: 22.1507 - val_mae: 22.1507\n",
      "Epoch 59/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.5508 - mae: 21.5508\n",
      "Epoch 59: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.5508 - mae: 21.5508 - val_loss: 22.3682 - val_mae: 22.3682\n",
      "Epoch 60/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.5277 - mae: 21.5277\n",
      "Epoch 60: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.5276 - mae: 21.5276 - val_loss: 22.4124 - val_mae: 22.4124\n",
      "Epoch 61/100\n",
      "1703/1705 [============================>.] - ETA: 0s - loss: 21.6630 - mae: 21.6630\n",
      "Epoch 61: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.6630 - mae: 21.6630 - val_loss: 23.0509 - val_mae: 23.0509\n",
      "Epoch 62/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.5354 - mae: 21.5354\n",
      "Epoch 62: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.5352 - mae: 21.5352 - val_loss: 22.5341 - val_mae: 22.5341\n",
      "Epoch 63/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.5041 - mae: 21.5041\n",
      "Epoch 63: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.5041 - mae: 21.5041 - val_loss: 23.2870 - val_mae: 23.2870\n",
      "Epoch 64/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.5069 - mae: 21.5069\n",
      "Epoch 64: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.5069 - mae: 21.5069 - val_loss: 23.6796 - val_mae: 23.6796\n",
      "Epoch 65/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.5121 - mae: 21.5121\n",
      "Epoch 65: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.5121 - mae: 21.5121 - val_loss: 22.7852 - val_mae: 22.7852\n",
      "Epoch 66/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.4727 - mae: 21.4727\n",
      "Epoch 66: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.4727 - mae: 21.4727 - val_loss: 24.1924 - val_mae: 24.1924\n",
      "Epoch 67/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.4600 - mae: 21.4600\n",
      "Epoch 67: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.4601 - mae: 21.4601 - val_loss: 23.3366 - val_mae: 23.3366\n",
      "Epoch 68/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.4560 - mae: 21.4560\n",
      "Epoch 68: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.4562 - mae: 21.4562 - val_loss: 23.0225 - val_mae: 23.0225\n",
      "Epoch 69/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.4334 - mae: 21.4334\n",
      "Epoch 69: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.4334 - mae: 21.4334 - val_loss: 23.4300 - val_mae: 23.4300\n",
      "Epoch 70/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.4146 - mae: 21.4146\n",
      "Epoch 70: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.4144 - mae: 21.4144 - val_loss: 23.0135 - val_mae: 23.0135\n",
      "Epoch 71/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.4147 - mae: 21.4147\n",
      "Epoch 71: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.4145 - mae: 21.4145 - val_loss: 22.5082 - val_mae: 22.5082\n",
      "Epoch 72/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.3882 - mae: 21.3882\n",
      "Epoch 72: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.3882 - mae: 21.3882 - val_loss: 22.7121 - val_mae: 22.7121\n",
      "Epoch 73/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.3737 - mae: 21.3737\n",
      "Epoch 73: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.3737 - mae: 21.3737 - val_loss: 22.5522 - val_mae: 22.5522\n",
      "Epoch 74/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.3524 - mae: 21.3524\n",
      "Epoch 74: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.3524 - mae: 21.3524 - val_loss: 22.8434 - val_mae: 22.8434\n",
      "Epoch 75/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.3656 - mae: 21.3656\n",
      "Epoch 75: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.3654 - mae: 21.3654 - val_loss: 23.1787 - val_mae: 23.1787\n",
      "Epoch 76/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.3340 - mae: 21.3340\n",
      "Epoch 76: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.3342 - mae: 21.3342 - val_loss: 23.0025 - val_mae: 23.0025\n",
      "Epoch 77/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.3266 - mae: 21.3266\n",
      "Epoch 77: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.3266 - mae: 21.3266 - val_loss: 23.4193 - val_mae: 23.4193\n",
      "Epoch 78/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.3361 - mae: 21.3361\n",
      "Epoch 78: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.3362 - mae: 21.3362 - val_loss: 23.4639 - val_mae: 23.4639\n",
      "Epoch 79/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.2970 - mae: 21.2970\n",
      "Epoch 79: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.2966 - mae: 21.2966 - val_loss: 23.2404 - val_mae: 23.2404\n",
      "Epoch 80/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.2979 - mae: 21.2979\n",
      "Epoch 80: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.2979 - mae: 21.2979 - val_loss: 23.9799 - val_mae: 23.9799\n",
      "Epoch 81/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.3368 - mae: 21.3368\n",
      "Epoch 81: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.3367 - mae: 21.3367 - val_loss: 22.9187 - val_mae: 22.9187\n",
      "Epoch 82/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.2924 - mae: 21.2924\n",
      "Epoch 82: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.2925 - mae: 21.2925 - val_loss: 22.6994 - val_mae: 22.6994\n",
      "Epoch 83/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.2675 - mae: 21.2675\n",
      "Epoch 83: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 56s 33ms/step - loss: 21.2675 - mae: 21.2675 - val_loss: 22.3376 - val_mae: 22.3376\n",
      "Epoch 84/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.2700 - mae: 21.2700\n",
      "Epoch 84: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 55s 32ms/step - loss: 21.2700 - mae: 21.2700 - val_loss: 24.3210 - val_mae: 24.3210\n",
      "Epoch 85/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.2760 - mae: 21.2760\n",
      "Epoch 85: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 55s 32ms/step - loss: 21.2760 - mae: 21.2760 - val_loss: 22.7261 - val_mae: 22.7261\n",
      "Epoch 86/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.2603 - mae: 21.2603\n",
      "Epoch 86: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 55s 32ms/step - loss: 21.2603 - mae: 21.2603 - val_loss: 22.7879 - val_mae: 22.7879\n",
      "Epoch 87/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.2527 - mae: 21.2527\n",
      "Epoch 87: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 56s 33ms/step - loss: 21.2527 - mae: 21.2527 - val_loss: 22.6580 - val_mae: 22.6580\n",
      "Epoch 88/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.3464 - mae: 21.3464\n",
      "Epoch 88: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.3464 - mae: 21.3464 - val_loss: 23.4320 - val_mae: 23.4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.2973 - mae: 21.2973\n",
      "Epoch 89: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.2973 - mae: 21.2973 - val_loss: 23.1287 - val_mae: 23.1287\n",
      "Epoch 90/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.2566 - mae: 21.2566\n",
      "Epoch 90: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.2566 - mae: 21.2566 - val_loss: 22.6806 - val_mae: 22.6806\n",
      "Epoch 91/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.2498 - mae: 21.2498\n",
      "Epoch 91: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.2498 - mae: 21.2498 - val_loss: 22.9493 - val_mae: 22.9493\n",
      "Epoch 92/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.2762 - mae: 21.2762\n",
      "Epoch 92: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.2762 - mae: 21.2762 - val_loss: 23.4206 - val_mae: 23.4206\n",
      "Epoch 93/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 21.2231 - mae: 21.2231\n",
      "Epoch 93: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 55s 32ms/step - loss: 21.2231 - mae: 21.2231 - val_loss: 22.6189 - val_mae: 22.6189\n",
      "Epoch 94/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.2480 - mae: 21.2480\n",
      "Epoch 94: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.2483 - mae: 21.2483 - val_loss: 22.4126 - val_mae: 22.4126\n",
      "Epoch 95/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.2755 - mae: 21.2755\n",
      "Epoch 95: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 55s 32ms/step - loss: 21.2755 - mae: 21.2755 - val_loss: 22.9037 - val_mae: 22.9037\n",
      "Epoch 96/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 25.1315 - mae: 25.1315\n",
      "Epoch 96: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 25.1309 - mae: 25.1309 - val_loss: 22.8240 - val_mae: 22.8240\n",
      "Epoch 97/100\n",
      "1705/1705 [==============================] - ETA: 0s - loss: 22.2517 - mae: 22.2517\n",
      "Epoch 97: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 22.2517 - mae: 22.2517 - val_loss: 22.5122 - val_mae: 22.5122\n",
      "Epoch 98/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 22.0013 - mae: 22.0013\n",
      "Epoch 98: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 22.0015 - mae: 22.0015 - val_loss: 23.1222 - val_mae: 23.1222\n",
      "Epoch 99/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.9047 - mae: 21.9047\n",
      "Epoch 99: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.9049 - mae: 21.9049 - val_loss: 23.4046 - val_mae: 23.4046\n",
      "Epoch 100/100\n",
      "1704/1705 [============================>.] - ETA: 0s - loss: 21.8537 - mae: 21.8537\n",
      "Epoch 100: val_mae did not improve from 22.15073\n",
      "1705/1705 [==============================] - 54s 32ms/step - loss: 21.8537 - mae: 21.8537 - val_loss: 22.6618 - val_mae: 22.6618\n"
     ]
    }
   ],
   "source": [
    "random_seed = 15\n",
    "tf.keras.utils.set_random_seed(random_seed)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "file_path = './RNN6_best_model.h5'\n",
    "checkpoint = ModelCheckpoint(file_path,\n",
    "                            monitor = 'val_mae',\n",
    "                            verbose=1,\n",
    "                            save_best_only=True,\n",
    "                            mode='auto')  \n",
    "\n",
    "hist = model.fit(x_train, y_train, validation_data=(x_test, y_test), \n",
    "                 epochs=100, batch_size=16, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df20b481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247/247 [==============================] - 2s 8ms/step - loss: 22.1507 - mae: 22.1507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[22.15072250366211, 22.15072250366211]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN6_model = tf.keras.models.load_model('./RNN6_best_model.h5')\n",
    "RNN6_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "80ddb16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264/264 [==============================] - 2s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "RNN6_pred = RNN6_model.predict(submission_x)\n",
    "pd.DataFrame(RNN6_pred).to_csv('RNN6_pred.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d723541e",
   "metadata": {},
   "source": [
    "## RNN7 / window size 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c6dabff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27367, 96, 1) (27367, 336) (7992, 96, 1) (7992, 336) (8425, 96, 1) (8425, 336)\n"
     ]
    }
   ],
   "source": [
    "pre_day = 28 # (31 - pre_month) * 24 = windowsize /27 : 96//28 : 72//29 : 48//30 : 24//\n",
    "x_train, y_train, x_test, y_test, submission_x, submission_y = DataProcessing.data_form_descision(train_df, test_df, pre_day)\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape, submission_x.shape, submission_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "85033b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_18 (SimpleRNN)   (None, 96, 32)            1088      \n",
      "                                                                 \n",
      " simple_rnn_19 (SimpleRNN)   (None, 96, 32)            2080      \n",
      "                                                                 \n",
      " simple_rnn_20 (SimpleRNN)   (None, 16)                784       \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 64)                1088      \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 336)               21840     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,880\n",
      "Trainable params: 26,880\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "initializer = tf.keras.initializers.GlorotNormal(seed=42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(32, activation='relu', input_shape=(x_train[0].shape), \n",
    "               return_sequences=True, kernel_initializer=initializer))\n",
    "model.add(SimpleRNN(32, activation='relu', return_sequences=True, kernel_initializer=initializer))\n",
    "model.add(SimpleRNN(16, activation='relu', kernel_initializer=initializer))\n",
    "model.add(Dense(64, activation='relu', kernel_initializer=initializer))\n",
    "model.add(Dense(336, activation='linear', kernel_initializer=initializer))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0007)\n",
    "model.compile(loss='mae', optimizer=optimizer, metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6843fd8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 27.3936 - mae: 27.3936\n",
      "Epoch 1: val_mae improved from inf to 24.27284, saving model to .\\RNN7_best_model.h5\n",
      "1711/1711 [==============================] - 28s 15ms/step - loss: 27.3926 - mae: 27.3926 - val_loss: 24.2728 - val_mae: 24.2728\n",
      "Epoch 2/80\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 23.0506 - mae: 23.0506\n",
      "Epoch 2: val_mae improved from 24.27284 to 23.20270, saving model to .\\RNN7_best_model.h5\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 23.0510 - mae: 23.0510 - val_loss: 23.2027 - val_mae: 23.2027\n",
      "Epoch 3/80\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 22.6988 - mae: 22.6988\n",
      "Epoch 3: val_mae improved from 23.20270 to 23.00675, saving model to .\\RNN7_best_model.h5\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 22.6988 - mae: 22.6988 - val_loss: 23.0067 - val_mae: 23.0067\n",
      "Epoch 4/80\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 1912.2610 - mae: 1912.2610\n",
      "Epoch 4: val_mae did not improve from 23.00675\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 1911.7898 - mae: 1911.7898 - val_loss: 72.5465 - val_mae: 72.5465\n",
      "Epoch 5/80\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 32.7719 - mae: 32.7719\n",
      "Epoch 5: val_mae did not improve from 23.00675\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 32.7704 - mae: 32.7704 - val_loss: 32.1289 - val_mae: 32.1289\n",
      "Epoch 6/80\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 28.8821 - mae: 28.8821\n",
      "Epoch 6: val_mae did not improve from 23.00675\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 28.8821 - mae: 28.8821 - val_loss: 28.3848 - val_mae: 28.3848\n",
      "Epoch 7/80\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 25.7514 - mae: 25.7514\n",
      "Epoch 7: val_mae did not improve from 23.00675\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 25.7507 - mae: 25.7507 - val_loss: 24.8820 - val_mae: 24.8820\n",
      "Epoch 8/80\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 23.9752 - mae: 23.9752\n",
      "Epoch 8: val_mae did not improve from 23.00675\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 23.9747 - mae: 23.9747 - val_loss: 23.9742 - val_mae: 23.9742\n",
      "Epoch 9/80\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 23.2875 - mae: 23.2875\n",
      "Epoch 9: val_mae did not improve from 23.00675\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 23.2875 - mae: 23.2875 - val_loss: 23.6027 - val_mae: 23.6027\n",
      "Epoch 10/80\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 22.9905 - mae: 22.9905\n",
      "Epoch 10: val_mae did not improve from 23.00675\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 22.9906 - mae: 22.9906 - val_loss: 23.1768 - val_mae: 23.1768\n",
      "Epoch 11/80\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 22.8500 - mae: 22.8500\n",
      "Epoch 11: val_mae did not improve from 23.00675\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 22.8503 - mae: 22.8503 - val_loss: 23.6220 - val_mae: 23.6220\n",
      "Epoch 12/80\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 22.7950 - mae: 22.7950\n",
      "Epoch 12: val_mae did not improve from 23.00675\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 22.7952 - mae: 22.7952 - val_loss: 23.1867 - val_mae: 23.1867\n",
      "Epoch 13/80\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 22.7835 - mae: 22.7835\n",
      "Epoch 13: val_mae did not improve from 23.00675\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 22.7829 - mae: 22.7829 - val_loss: 23.1295 - val_mae: 23.1295\n",
      "Epoch 14/80\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 22.7466 - mae: 22.7466\n",
      "Epoch 14: val_mae did not improve from 23.00675\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 22.7459 - mae: 22.7459 - val_loss: 23.2777 - val_mae: 23.2777\n",
      "Epoch 15/80\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 22.7459 - mae: 22.7459\n",
      "Epoch 15: val_mae improved from 23.00675 to 22.88352, saving model to .\\RNN7_best_model.h5\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 22.7465 - mae: 22.7465 - val_loss: 22.8835 - val_mae: 22.8835\n",
      "Epoch 16/80\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 22.7208 - mae: 22.7208\n",
      "Epoch 16: val_mae did not improve from 22.88352\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 22.7208 - mae: 22.7208 - val_loss: 23.0570 - val_mae: 23.0570\n",
      "Epoch 17/80\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 22.6618 - mae: 22.6618\n",
      "Epoch 17: val_mae did not improve from 22.88352\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 22.6618 - mae: 22.6618 - val_loss: 23.3979 - val_mae: 23.3979\n",
      "Epoch 18/80\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 22.5563 - mae: 22.5563\n",
      "Epoch 18: val_mae did not improve from 22.88352\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 22.5559 - mae: 22.5559 - val_loss: 22.9156 - val_mae: 22.9156\n",
      "Epoch 19/80\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 22.4792 - mae: 22.4792\n",
      "Epoch 19: val_mae improved from 22.88352 to 22.86283, saving model to .\\RNN7_best_model.h5\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 22.4784 - mae: 22.4784 - val_loss: 22.8628 - val_mae: 22.8628\n",
      "Epoch 20/80\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 22.3999 - mae: 22.3999\n",
      "Epoch 20: val_mae improved from 22.86283 to 22.63220, saving model to .\\RNN7_best_model.h5\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 22.3999 - mae: 22.3999 - val_loss: 22.6322 - val_mae: 22.6322\n",
      "Epoch 21/80\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 22.3064 - mae: 22.3064\n",
      "Epoch 21: val_mae did not improve from 22.63220\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 22.3059 - mae: 22.3059 - val_loss: 22.9184 - val_mae: 22.9184\n",
      "Epoch 22/80\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 22.2270 - mae: 22.2270\n",
      "Epoch 22: val_mae improved from 22.63220 to 22.48306, saving model to .\\RNN7_best_model.h5\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 22.2270 - mae: 22.2270 - val_loss: 22.4831 - val_mae: 22.4831\n",
      "Epoch 23/80\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 22.1525 - mae: 22.1525\n",
      "Epoch 23: val_mae did not improve from 22.48306\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 22.1524 - mae: 22.1524 - val_loss: 22.7566 - val_mae: 22.7566\n",
      "Epoch 24/80\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 22.0625 - mae: 22.0625\n",
      "Epoch 24: val_mae did not improve from 22.48306\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 22.0625 - mae: 22.0625 - val_loss: 22.4974 - val_mae: 22.4974\n",
      "Epoch 25/80\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 22.0655 - mae: 22.0655\n",
      "Epoch 25: val_mae did not improve from 22.48306\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 22.0656 - mae: 22.0656 - val_loss: 22.6715 - val_mae: 22.6715\n",
      "Epoch 26/80\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 22.0228 - mae: 22.0228\n",
      "Epoch 26: val_mae improved from 22.48306 to 22.43724, saving model to .\\RNN7_best_model.h5\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 22.0227 - mae: 22.0227 - val_loss: 22.4372 - val_mae: 22.4372\n",
      "Epoch 27/80\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 21.9939 - mae: 21.9939\n",
      "Epoch 27: val_mae did not improve from 22.43724\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.9939 - mae: 21.9939 - val_loss: 22.9813 - val_mae: 22.9813\n",
      "Epoch 28/80\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 21.9701 - mae: 21.9701\n",
      "Epoch 28: val_mae did not improve from 22.43724\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.9701 - mae: 21.9701 - val_loss: 22.6797 - val_mae: 22.6797\n",
      "Epoch 29/80\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 21.9526 - mae: 21.9526\n",
      "Epoch 29: val_mae did not improve from 22.43724\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.9526 - mae: 21.9526 - val_loss: 22.5143 - val_mae: 22.5143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/80\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 21.9186 - mae: 21.9186\n",
      "Epoch 30: val_mae did not improve from 22.43724\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.9186 - mae: 21.9186 - val_loss: 24.0267 - val_mae: 24.0267\n",
      "Epoch 31/80\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 21.9049 - mae: 21.9049\n",
      "Epoch 31: val_mae did not improve from 22.43724\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.9049 - mae: 21.9049 - val_loss: 22.5114 - val_mae: 22.5114\n",
      "Epoch 32/80\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 21.8769 - mae: 21.8769\n",
      "Epoch 32: val_mae did not improve from 22.43724\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.8767 - mae: 21.8767 - val_loss: 22.4830 - val_mae: 22.4830\n",
      "Epoch 33/80\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 21.8673 - mae: 21.8673\n",
      "Epoch 33: val_mae did not improve from 22.43724\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.8673 - mae: 21.8673 - val_loss: 22.5737 - val_mae: 22.5737\n",
      "Epoch 34/80\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 21.8460 - mae: 21.8460\n",
      "Epoch 34: val_mae did not improve from 22.43724\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.8456 - mae: 21.8456 - val_loss: 22.7684 - val_mae: 22.7684\n",
      "Epoch 35/80\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 21.8124 - mae: 21.8124\n",
      "Epoch 35: val_mae improved from 22.43724 to 22.37931, saving model to .\\RNN7_best_model.h5\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.8125 - mae: 21.8125 - val_loss: 22.3793 - val_mae: 22.3793\n",
      "Epoch 36/80\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 21.7984 - mae: 21.7984\n",
      "Epoch 36: val_mae did not improve from 22.37931\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.7984 - mae: 21.7984 - val_loss: 22.3939 - val_mae: 22.3939\n",
      "Epoch 37/80\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 21.7944 - mae: 21.7944\n",
      "Epoch 37: val_mae did not improve from 22.37931\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.7944 - mae: 21.7944 - val_loss: 22.6299 - val_mae: 22.6299\n",
      "Epoch 38/80\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 21.7768 - mae: 21.7768\n",
      "Epoch 38: val_mae improved from 22.37931 to 22.29875, saving model to .\\RNN7_best_model.h5\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.7768 - mae: 21.7768 - val_loss: 22.2987 - val_mae: 22.2987\n",
      "Epoch 39/80\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 21.7753 - mae: 21.7753\n",
      "Epoch 39: val_mae did not improve from 22.29875\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.7758 - mae: 21.7758 - val_loss: 22.3431 - val_mae: 22.3431\n",
      "Epoch 40/80\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 21.7377 - mae: 21.7377\n",
      "Epoch 40: val_mae did not improve from 22.29875\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.7379 - mae: 21.7379 - val_loss: 22.8513 - val_mae: 22.8513\n",
      "Epoch 41/80\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 21.7456 - mae: 21.7456\n",
      "Epoch 41: val_mae did not improve from 22.29875\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.7455 - mae: 21.7455 - val_loss: 22.5606 - val_mae: 22.5606\n",
      "Epoch 42/80\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 21.7233 - mae: 21.7233\n",
      "Epoch 42: val_mae did not improve from 22.29875\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.7233 - mae: 21.7233 - val_loss: 22.7585 - val_mae: 22.7585\n",
      "Epoch 43/80\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 21.7203 - mae: 21.7203\n",
      "Epoch 43: val_mae did not improve from 22.29875\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.7212 - mae: 21.7212 - val_loss: 22.7217 - val_mae: 22.7217\n",
      "Epoch 44/80\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 21.7100 - mae: 21.7100\n",
      "Epoch 44: val_mae did not improve from 22.29875\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.7099 - mae: 21.7099 - val_loss: 23.3275 - val_mae: 23.3275\n",
      "Epoch 45/80\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 21.6991 - mae: 21.6991\n",
      "Epoch 45: val_mae did not improve from 22.29875\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.6991 - mae: 21.6991 - val_loss: 23.5311 - val_mae: 23.5311\n",
      "Epoch 46/80\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 21.6851 - mae: 21.6851\n",
      "Epoch 46: val_mae did not improve from 22.29875\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.6852 - mae: 21.6852 - val_loss: 22.9393 - val_mae: 22.9393\n",
      "Epoch 47/80\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 21.6967 - mae: 21.6967\n",
      "Epoch 47: val_mae did not improve from 22.29875\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.6966 - mae: 21.6966 - val_loss: 22.7879 - val_mae: 22.7879\n",
      "Epoch 48/80\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 21.6649 - mae: 21.6649\n",
      "Epoch 48: val_mae did not improve from 22.29875\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.6651 - mae: 21.6651 - val_loss: 22.6096 - val_mae: 22.6096\n",
      "Epoch 49/80\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 21.6708 - mae: 21.6708\n",
      "Epoch 49: val_mae did not improve from 22.29875\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.6708 - mae: 21.6708 - val_loss: 22.7403 - val_mae: 22.7403\n",
      "Epoch 50/80\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 21.6552 - mae: 21.6552\n",
      "Epoch 50: val_mae did not improve from 22.29875\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.6551 - mae: 21.6551 - val_loss: 23.8035 - val_mae: 23.8035\n",
      "Epoch 51/80\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 21.6647 - mae: 21.6647\n",
      "Epoch 51: val_mae did not improve from 22.29875\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.6648 - mae: 21.6648 - val_loss: 24.4663 - val_mae: 24.4663\n",
      "Epoch 52/80\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 21.6350 - mae: 21.6350\n",
      "Epoch 52: val_mae did not improve from 22.29875\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.6355 - mae: 21.6355 - val_loss: 22.6074 - val_mae: 22.6074\n",
      "Epoch 53/80\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 21.6323 - mae: 21.6323\n",
      "Epoch 53: val_mae improved from 22.29875 to 22.27943, saving model to .\\RNN7_best_model.h5\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.6323 - mae: 21.6323 - val_loss: 22.2794 - val_mae: 22.2794\n",
      "Epoch 54/80\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 21.6185 - mae: 21.6185\n",
      "Epoch 54: val_mae did not improve from 22.27943\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.6186 - mae: 21.6186 - val_loss: 22.9457 - val_mae: 22.9457\n",
      "Epoch 55/80\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 21.6143 - mae: 21.6143\n",
      "Epoch 55: val_mae did not improve from 22.27943\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.6144 - mae: 21.6144 - val_loss: 22.6613 - val_mae: 22.6613\n",
      "Epoch 56/80\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 21.6090 - mae: 21.6090\n",
      "Epoch 56: val_mae did not improve from 22.27943\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.6091 - mae: 21.6091 - val_loss: 22.9175 - val_mae: 22.9175\n",
      "Epoch 57/80\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 21.6048 - mae: 21.6048\n",
      "Epoch 57: val_mae did not improve from 22.27943\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.6048 - mae: 21.6048 - val_loss: 23.3113 - val_mae: 23.3113\n",
      "Epoch 58/80\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 21.5941 - mae: 21.5941\n",
      "Epoch 58: val_mae did not improve from 22.27943\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.5942 - mae: 21.5942 - val_loss: 24.2693 - val_mae: 24.2693\n",
      "Epoch 59/80\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 21.6044 - mae: 21.6044\n",
      "Epoch 59: val_mae did not improve from 22.27943\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.6044 - mae: 21.6044 - val_loss: 22.4453 - val_mae: 22.4453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/80\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 21.5859 - mae: 21.5859\n",
      "Epoch 60: val_mae did not improve from 22.27943\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.5859 - mae: 21.5859 - val_loss: 22.8634 - val_mae: 22.8634\n",
      "Epoch 61/80\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 21.5796 - mae: 21.5796\n",
      "Epoch 61: val_mae did not improve from 22.27943\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.5791 - mae: 21.5791 - val_loss: 23.0879 - val_mae: 23.0879\n",
      "Epoch 62/80\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 21.5647 - mae: 21.5647\n",
      "Epoch 62: val_mae did not improve from 22.27943\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.5646 - mae: 21.5646 - val_loss: 22.6964 - val_mae: 22.6964\n",
      "Epoch 63/80\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 21.5743 - mae: 21.5743\n",
      "Epoch 63: val_mae did not improve from 22.27943\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.5744 - mae: 21.5744 - val_loss: 22.8103 - val_mae: 22.8103\n",
      "Epoch 64/80\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 21.5537 - mae: 21.5537\n",
      "Epoch 64: val_mae did not improve from 22.27943\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.5537 - mae: 21.5537 - val_loss: 22.5995 - val_mae: 22.5995\n",
      "Epoch 65/80\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 21.5524 - mae: 21.5524\n",
      "Epoch 65: val_mae did not improve from 22.27943\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.5524 - mae: 21.5524 - val_loss: 22.3641 - val_mae: 22.3641\n",
      "Epoch 66/80\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 21.5347 - mae: 21.5347\n",
      "Epoch 66: val_mae did not improve from 22.27943\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.5346 - mae: 21.5346 - val_loss: 22.7952 - val_mae: 22.7952\n",
      "Epoch 67/80\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 21.5358 - mae: 21.5358\n",
      "Epoch 67: val_mae did not improve from 22.27943\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.5357 - mae: 21.5357 - val_loss: 22.5081 - val_mae: 22.5081\n",
      "Epoch 68/80\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 21.5529 - mae: 21.5529\n",
      "Epoch 68: val_mae did not improve from 22.27943\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.5528 - mae: 21.5528 - val_loss: 23.4507 - val_mae: 23.4507\n",
      "Epoch 69/80\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 21.5298 - mae: 21.5298\n",
      "Epoch 69: val_mae did not improve from 22.27943\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.5300 - mae: 21.5300 - val_loss: 22.7108 - val_mae: 22.7108\n",
      "Epoch 70/80\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 21.5372 - mae: 21.5372\n",
      "Epoch 70: val_mae did not improve from 22.27943\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.5371 - mae: 21.5371 - val_loss: 22.7683 - val_mae: 22.7683\n",
      "Epoch 71/80\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 21.5101 - mae: 21.5101\n",
      "Epoch 71: val_mae did not improve from 22.27943\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.5106 - mae: 21.5106 - val_loss: 22.6642 - val_mae: 22.6642\n",
      "Epoch 72/80\n",
      "1709/1711 [============================>.] - ETA: 0s - loss: 21.5095 - mae: 21.5095\n",
      "Epoch 72: val_mae did not improve from 22.27943\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.5097 - mae: 21.5097 - val_loss: 22.9541 - val_mae: 22.9541\n",
      "Epoch 73/80\n",
      "1710/1711 [============================>.] - ETA: 0s - loss: 21.4901 - mae: 21.4901\n",
      "Epoch 73: val_mae did not improve from 22.27943\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.4902 - mae: 21.4902 - val_loss: 22.9260 - val_mae: 22.9260\n",
      "Epoch 74/80\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 21.4957 - mae: 21.4957\n",
      "Epoch 74: val_mae did not improve from 22.27943\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.4957 - mae: 21.4957 - val_loss: 23.1144 - val_mae: 23.1144\n",
      "Epoch 75/80\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 21.5147 - mae: 21.5147\n",
      "Epoch 75: val_mae did not improve from 22.27943\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.5147 - mae: 21.5147 - val_loss: 23.1517 - val_mae: 23.1517\n",
      "Epoch 76/80\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 21.4825 - mae: 21.4825\n",
      "Epoch 76: val_mae did not improve from 22.27943\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.4825 - mae: 21.4825 - val_loss: 24.0222 - val_mae: 24.0222\n",
      "Epoch 77/80\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 21.4862 - mae: 21.4862\n",
      "Epoch 77: val_mae did not improve from 22.27943\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.4870 - mae: 21.4870 - val_loss: 23.7283 - val_mae: 23.7283\n",
      "Epoch 78/80\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 21.4809 - mae: 21.4809\n",
      "Epoch 78: val_mae did not improve from 22.27943\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.4809 - mae: 21.4809 - val_loss: 22.4602 - val_mae: 22.4602\n",
      "Epoch 79/80\n",
      "1707/1711 [============================>.] - ETA: 0s - loss: 21.4719 - mae: 21.4719\n",
      "Epoch 79: val_mae did not improve from 22.27943\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.4727 - mae: 21.4727 - val_loss: 22.4053 - val_mae: 22.4053\n",
      "Epoch 80/80\n",
      "1711/1711 [==============================] - ETA: 0s - loss: 21.4643 - mae: 21.4643\n",
      "Epoch 80: val_mae did not improve from 22.27943\n",
      "1711/1711 [==============================] - 26s 15ms/step - loss: 21.4643 - mae: 21.4643 - val_loss: 23.4628 - val_mae: 23.4628\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "tf.keras.utils.set_random_seed(seed)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "checkpoint = ModelCheckpoint('./RNN7_best_model.h5',\n",
    "                        monitor = 'val_mae',\n",
    "                        verbose=1,\n",
    "                        save_best_only=True,\n",
    "                        mode='auto')  \n",
    "\n",
    "hist = model.fit(x_train, y_train, validation_data=(x_test, y_test), \n",
    "                 epochs=80, batch_size=16, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f2ca809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 4ms/step - loss: 22.2794 - mae: 22.2794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[22.279434204101562, 22.279434204101562]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN7_model = tf.keras.models.load_model('./RNN7_best_model.h5')\n",
    "RNN7_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ba6ae8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264/264 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "RNN7_pred = RNN7_model.predict(submission_x)\n",
    "pd.DataFrame(RNN7_pred).to_csv('RNN7_pred.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf977f39",
   "metadata": {},
   "source": [
    "## RNN8 / window size 216"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "03df965c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27247, 216, 1) (27247, 336) (7872, 216, 1) (7872, 336) (8425, 216, 1) (8425, 336)\n"
     ]
    }
   ],
   "source": [
    "pre_day = 23 # (31 - pre_month) * 24 = windowsize /27 : 96//28 : 72//29 : 48//30 : 24//\n",
    "x_train, y_train, x_test, y_test, submission_x, submission_y = DataProcessing.data_form_descision(train_df, test_df, pre_day)\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape, submission_x.shape, submission_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cb02e395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_21 (SimpleRNN)   (None, 216, 32)           1088      \n",
      "                                                                 \n",
      " simple_rnn_22 (SimpleRNN)   (None, 216, 32)           2080      \n",
      "                                                                 \n",
      " simple_rnn_23 (SimpleRNN)   (None, 16)                784       \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 64)                1088      \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 336)               11088     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,208\n",
      "Trainable params: 18,208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "initializer = tf.keras.initializers.GlorotNormal(seed=15)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(32, activation='relu', input_shape=(x_train[0].shape), \n",
    "               return_sequences=True, kernel_initializer=initializer))\n",
    "model.add(SimpleRNN(32, activation='relu',return_sequences=True, kernel_initializer=initializer))\n",
    "model.add(SimpleRNN(16, activation='relu', kernel_initializer=initializer))\n",
    "model.add(Dense(64, activation='relu', kernel_initializer=initializer))\n",
    "model.add(Dense(32, activation='relu', kernel_initializer=initializer))\n",
    "model.add(Dense(336, activation='linear', kernel_initializer=initializer))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0006)\n",
    "model.compile(loss='mae', optimizer=optimizer, metrics=['mae'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9a67067b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 32.8247 - mae: 32.8247\n",
      "Epoch 1: val_mae improved from inf to 25.79798, saving model to .\\RNN8_best_model.h5\n",
      "1703/1703 [==============================] - 67s 38ms/step - loss: 32.8207 - mae: 32.8207 - val_loss: 25.7980 - val_mae: 25.7980\n",
      "Epoch 2/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 23.5459 - mae: 23.5459\n",
      "Epoch 2: val_mae improved from 25.79798 to 23.54328, saving model to .\\RNN8_best_model.h5\n",
      "1703/1703 [==============================] - 67s 39ms/step - loss: 23.5459 - mae: 23.5459 - val_loss: 23.5433 - val_mae: 23.5433\n",
      "Epoch 3/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 22.8411 - mae: 22.8411\n",
      "Epoch 3: val_mae improved from 23.54328 to 23.21145, saving model to .\\RNN8_best_model.h5\n",
      "1703/1703 [==============================] - 68s 40ms/step - loss: 22.8411 - mae: 22.8411 - val_loss: 23.2114 - val_mae: 23.2114\n",
      "Epoch 4/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 22.4386 - mae: 22.4386\n",
      "Epoch 4: val_mae improved from 23.21145 to 22.75323, saving model to .\\RNN8_best_model.h5\n",
      "1703/1703 [==============================] - 69s 40ms/step - loss: 22.4384 - mae: 22.4384 - val_loss: 22.7532 - val_mae: 22.7532\n",
      "Epoch 5/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 22.4283 - mae: 22.4283\n",
      "Epoch 5: val_mae improved from 22.75323 to 22.61226, saving model to .\\RNN8_best_model.h5\n",
      "1703/1703 [==============================] - 72s 42ms/step - loss: 22.4283 - mae: 22.4283 - val_loss: 22.6123 - val_mae: 22.6123\n",
      "Epoch 6/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 22.3149 - mae: 22.3149\n",
      "Epoch 6: val_mae did not improve from 22.61226\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 22.3149 - mae: 22.3149 - val_loss: 22.7016 - val_mae: 22.7016\n",
      "Epoch 7/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 22.1666 - mae: 22.1666\n",
      "Epoch 7: val_mae did not improve from 22.61226\n",
      "1703/1703 [==============================] - 69s 41ms/step - loss: 22.1666 - mae: 22.1666 - val_loss: 22.8268 - val_mae: 22.8268\n",
      "Epoch 8/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 22.1052 - mae: 22.1052\n",
      "Epoch 8: val_mae improved from 22.61226 to 22.53022, saving model to .\\RNN8_best_model.h5\n",
      "1703/1703 [==============================] - 69s 41ms/step - loss: 22.1052 - mae: 22.1052 - val_loss: 22.5302 - val_mae: 22.5302\n",
      "Epoch 9/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 22.0340 - mae: 22.0340\n",
      "Epoch 9: val_mae did not improve from 22.53022\n",
      "1703/1703 [==============================] - 69s 41ms/step - loss: 22.0337 - mae: 22.0337 - val_loss: 22.8293 - val_mae: 22.8293\n",
      "Epoch 10/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.9800 - mae: 21.9800\n",
      "Epoch 10: val_mae did not improve from 22.53022\n",
      "1703/1703 [==============================] - 69s 41ms/step - loss: 21.9800 - mae: 21.9800 - val_loss: 22.8238 - val_mae: 22.8238\n",
      "Epoch 11/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.9648 - mae: 21.9648\n",
      "Epoch 11: val_mae improved from 22.53022 to 22.41911, saving model to .\\RNN8_best_model.h5\n",
      "1703/1703 [==============================] - 69s 41ms/step - loss: 21.9649 - mae: 21.9649 - val_loss: 22.4191 - val_mae: 22.4191\n",
      "Epoch 12/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.9224 - mae: 21.9224\n",
      "Epoch 12: val_mae did not improve from 22.41911\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.9230 - mae: 21.9230 - val_loss: 22.5103 - val_mae: 22.5103\n",
      "Epoch 13/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.8866 - mae: 21.8866\n",
      "Epoch 13: val_mae did not improve from 22.41911\n",
      "1703/1703 [==============================] - 71s 42ms/step - loss: 21.8866 - mae: 21.8866 - val_loss: 22.5376 - val_mae: 22.5376\n",
      "Epoch 14/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.8486 - mae: 21.8486\n",
      "Epoch 14: val_mae did not improve from 22.41911\n",
      "1703/1703 [==============================] - 69s 41ms/step - loss: 21.8487 - mae: 21.8487 - val_loss: 22.4327 - val_mae: 22.4327\n",
      "Epoch 15/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.8261 - mae: 21.8261\n",
      "Epoch 15: val_mae did not improve from 22.41911\n",
      "1703/1703 [==============================] - 69s 41ms/step - loss: 21.8256 - mae: 21.8256 - val_loss: 23.1313 - val_mae: 23.1313\n",
      "Epoch 16/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.8038 - mae: 21.8038\n",
      "Epoch 16: val_mae did not improve from 22.41911\n",
      "1703/1703 [==============================] - 69s 41ms/step - loss: 21.8039 - mae: 21.8039 - val_loss: 23.2698 - val_mae: 23.2698\n",
      "Epoch 17/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.7703 - mae: 21.7703\n",
      "Epoch 17: val_mae did not improve from 22.41911\n",
      "1703/1703 [==============================] - 69s 41ms/step - loss: 21.7703 - mae: 21.7703 - val_loss: 23.0545 - val_mae: 23.0545\n",
      "Epoch 18/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.7501 - mae: 21.7501\n",
      "Epoch 18: val_mae improved from 22.41911 to 22.23985, saving model to .\\RNN8_best_model.h5\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.7500 - mae: 21.7500 - val_loss: 22.2398 - val_mae: 22.2398\n",
      "Epoch 19/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.7568 - mae: 21.7568\n",
      "Epoch 19: val_mae improved from 22.23985 to 22.15297, saving model to .\\RNN8_best_model.h5\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.7568 - mae: 21.7568 - val_loss: 22.1530 - val_mae: 22.1530\n",
      "Epoch 20/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.7435 - mae: 21.7435\n",
      "Epoch 20: val_mae did not improve from 22.15297\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.7435 - mae: 21.7435 - val_loss: 22.5327 - val_mae: 22.5327\n",
      "Epoch 21/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.7107 - mae: 21.7107\n",
      "Epoch 21: val_mae improved from 22.15297 to 22.12921, saving model to .\\RNN8_best_model.h5\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.7107 - mae: 21.7107 - val_loss: 22.1292 - val_mae: 22.1292\n",
      "Epoch 22/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.7418 - mae: 21.7418\n",
      "Epoch 22: val_mae did not improve from 22.12921\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.7418 - mae: 21.7418 - val_loss: 22.7242 - val_mae: 22.7242\n",
      "Epoch 23/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.7044 - mae: 21.7044\n",
      "Epoch 23: val_mae did not improve from 22.12921\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.7043 - mae: 21.7043 - val_loss: 22.4311 - val_mae: 22.4311\n",
      "Epoch 24/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.6678 - mae: 21.6678\n",
      "Epoch 24: val_mae did not improve from 22.12921\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.6683 - mae: 21.6683 - val_loss: 22.2099 - val_mae: 22.2099\n",
      "Epoch 25/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.6737 - mae: 21.6737\n",
      "Epoch 25: val_mae did not improve from 22.12921\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.6737 - mae: 21.6737 - val_loss: 23.3249 - val_mae: 23.3249\n",
      "Epoch 26/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.6640 - mae: 21.6640\n",
      "Epoch 26: val_mae did not improve from 22.12921\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.6640 - mae: 21.6640 - val_loss: 22.4917 - val_mae: 22.4917\n",
      "Epoch 27/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.6514 - mae: 21.6514\n",
      "Epoch 27: val_mae did not improve from 22.12921\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.6514 - mae: 21.6514 - val_loss: 22.2076 - val_mae: 22.2076\n",
      "Epoch 28/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.6819 - mae: 21.6819\n",
      "Epoch 28: val_mae did not improve from 22.12921\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.6819 - mae: 21.6819 - val_loss: 22.4347 - val_mae: 22.4347\n",
      "Epoch 29/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.5991 - mae: 21.5991\n",
      "Epoch 29: val_mae did not improve from 22.12921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.5990 - mae: 21.5990 - val_loss: 22.2606 - val_mae: 22.2606\n",
      "Epoch 30/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.7357 - mae: 21.7357\n",
      "Epoch 30: val_mae did not improve from 22.12921\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.7355 - mae: 21.7355 - val_loss: 22.5015 - val_mae: 22.5015\n",
      "Epoch 31/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.6130 - mae: 21.6130\n",
      "Epoch 31: val_mae did not improve from 22.12921\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.6130 - mae: 21.6130 - val_loss: 22.2240 - val_mae: 22.2240\n",
      "Epoch 32/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.6120 - mae: 21.6120\n",
      "Epoch 32: val_mae did not improve from 22.12921\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.6119 - mae: 21.6119 - val_loss: 22.2137 - val_mae: 22.2137\n",
      "Epoch 33/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.6940 - mae: 21.6940\n",
      "Epoch 33: val_mae did not improve from 22.12921\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.6944 - mae: 21.6944 - val_loss: 23.1440 - val_mae: 23.1440\n",
      "Epoch 34/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.6120 - mae: 21.6120\n",
      "Epoch 34: val_mae did not improve from 22.12921\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.6118 - mae: 21.6118 - val_loss: 23.1091 - val_mae: 23.1091\n",
      "Epoch 35/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.5936 - mae: 21.5936\n",
      "Epoch 35: val_mae did not improve from 22.12921\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.5936 - mae: 21.5936 - val_loss: 22.9256 - val_mae: 22.9256\n",
      "Epoch 36/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.8212 - mae: 21.8212\n",
      "Epoch 36: val_mae did not improve from 22.12921\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.8212 - mae: 21.8212 - val_loss: 22.8832 - val_mae: 22.8832\n",
      "Epoch 37/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.5872 - mae: 21.5872\n",
      "Epoch 37: val_mae improved from 22.12921 to 22.04471, saving model to .\\RNN8_best_model.h5\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.5872 - mae: 21.5872 - val_loss: 22.0447 - val_mae: 22.0447\n",
      "Epoch 38/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.7022 - mae: 21.7022\n",
      "Epoch 38: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.7022 - mae: 21.7022 - val_loss: 22.2649 - val_mae: 22.2649\n",
      "Epoch 39/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.5866 - mae: 21.5866\n",
      "Epoch 39: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.5866 - mae: 21.5866 - val_loss: 22.3588 - val_mae: 22.3588\n",
      "Epoch 40/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.5636 - mae: 21.5636\n",
      "Epoch 40: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.5635 - mae: 21.5635 - val_loss: 22.5641 - val_mae: 22.5641\n",
      "Epoch 41/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.5792 - mae: 21.5792\n",
      "Epoch 41: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.5792 - mae: 21.5792 - val_loss: 22.3804 - val_mae: 22.3804\n",
      "Epoch 42/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.5158 - mae: 21.5158\n",
      "Epoch 42: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.5158 - mae: 21.5158 - val_loss: 22.7783 - val_mae: 22.7783\n",
      "Epoch 43/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.5475 - mae: 21.5475\n",
      "Epoch 43: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.5476 - mae: 21.5476 - val_loss: 22.2433 - val_mae: 22.2433\n",
      "Epoch 44/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.5348 - mae: 21.5348\n",
      "Epoch 44: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.5344 - mae: 21.5344 - val_loss: 22.9637 - val_mae: 22.9637\n",
      "Epoch 45/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.6654 - mae: 21.6654\n",
      "Epoch 45: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.6654 - mae: 21.6654 - val_loss: 23.3621 - val_mae: 23.3621\n",
      "Epoch 46/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.5632 - mae: 21.5632\n",
      "Epoch 46: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.5630 - mae: 21.5630 - val_loss: 23.8966 - val_mae: 23.8966\n",
      "Epoch 47/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.6559 - mae: 21.6559\n",
      "Epoch 47: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.6559 - mae: 21.6559 - val_loss: 22.2622 - val_mae: 22.2622\n",
      "Epoch 48/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.6760 - mae: 21.6760\n",
      "Epoch 48: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.6756 - mae: 21.6756 - val_loss: 22.4460 - val_mae: 22.4460\n",
      "Epoch 49/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.5326 - mae: 21.5326\n",
      "Epoch 49: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.5326 - mae: 21.5326 - val_loss: 22.2156 - val_mae: 22.2156\n",
      "Epoch 50/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.4561 - mae: 21.4561\n",
      "Epoch 50: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.4561 - mae: 21.4561 - val_loss: 22.7856 - val_mae: 22.7856\n",
      "Epoch 51/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.5438 - mae: 21.5438\n",
      "Epoch 51: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.5437 - mae: 21.5437 - val_loss: 22.5205 - val_mae: 22.5205\n",
      "Epoch 52/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.4554 - mae: 21.4554\n",
      "Epoch 52: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.4553 - mae: 21.4553 - val_loss: 22.8116 - val_mae: 22.8116\n",
      "Epoch 53/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.5287 - mae: 21.5287\n",
      "Epoch 53: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.5287 - mae: 21.5287 - val_loss: 23.2674 - val_mae: 23.2674\n",
      "Epoch 54/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.6473 - mae: 21.6473\n",
      "Epoch 54: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.6473 - mae: 21.6473 - val_loss: 23.8388 - val_mae: 23.8388\n",
      "Epoch 55/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.6670 - mae: 21.6670\n",
      "Epoch 55: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.6670 - mae: 21.6670 - val_loss: 23.0504 - val_mae: 23.0504\n",
      "Epoch 56/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.5478 - mae: 21.5478\n",
      "Epoch 56: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.5478 - mae: 21.5478 - val_loss: 22.5886 - val_mae: 22.5886\n",
      "Epoch 57/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.4804 - mae: 21.4804\n",
      "Epoch 57: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.4803 - mae: 21.4803 - val_loss: 22.1824 - val_mae: 22.1824\n",
      "Epoch 58/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.4987 - mae: 21.4987\n",
      "Epoch 58: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.4989 - mae: 21.4989 - val_loss: 22.1440 - val_mae: 22.1440\n",
      "Epoch 59/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.4434 - mae: 21.4434\n",
      "Epoch 59: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.4433 - mae: 21.4433 - val_loss: 22.4373 - val_mae: 22.4373\n",
      "Epoch 60/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.5069 - mae: 21.5069\n",
      "Epoch 60: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.5069 - mae: 21.5069 - val_loss: 22.6282 - val_mae: 22.6282\n",
      "Epoch 61/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.4187 - mae: 21.4187\n",
      "Epoch 61: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.4186 - mae: 21.4186 - val_loss: 22.5911 - val_mae: 22.5911\n",
      "Epoch 62/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.3955 - mae: 21.3955\n",
      "Epoch 62: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.3954 - mae: 21.3954 - val_loss: 22.7356 - val_mae: 22.7356\n",
      "Epoch 63/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.3977 - mae: 21.3977\n",
      "Epoch 63: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.3980 - mae: 21.3980 - val_loss: 23.4914 - val_mae: 23.4914\n",
      "Epoch 64/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.3621 - mae: 21.3621\n",
      "Epoch 64: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.3623 - mae: 21.3623 - val_loss: 22.1641 - val_mae: 22.1641\n",
      "Epoch 65/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.4143 - mae: 21.4143\n",
      "Epoch 65: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.4143 - mae: 21.4143 - val_loss: 22.5866 - val_mae: 22.5866\n",
      "Epoch 66/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.5692 - mae: 21.5692\n",
      "Epoch 66: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.5692 - mae: 21.5692 - val_loss: 23.2619 - val_mae: 23.2619\n",
      "Epoch 67/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.4025 - mae: 21.4025\n",
      "Epoch 67: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.4024 - mae: 21.4024 - val_loss: 22.2263 - val_mae: 22.2263\n",
      "Epoch 68/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.3863 - mae: 21.3863\n",
      "Epoch 68: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.3862 - mae: 21.3862 - val_loss: 22.7638 - val_mae: 22.7638\n",
      "Epoch 69/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.4655 - mae: 21.4655\n",
      "Epoch 69: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.4655 - mae: 21.4655 - val_loss: 22.3584 - val_mae: 22.3584\n",
      "Epoch 70/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.4242 - mae: 21.4242\n",
      "Epoch 70: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.4242 - mae: 21.4242 - val_loss: 23.0111 - val_mae: 23.0111\n",
      "Epoch 71/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.3559 - mae: 21.3559\n",
      "Epoch 71: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.3558 - mae: 21.3558 - val_loss: 22.6761 - val_mae: 22.6761\n",
      "Epoch 72/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.3406 - mae: 21.3406\n",
      "Epoch 72: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.3406 - mae: 21.3406 - val_loss: 22.4466 - val_mae: 22.4466\n",
      "Epoch 73/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.3709 - mae: 21.3709\n",
      "Epoch 73: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.3709 - mae: 21.3709 - val_loss: 22.7734 - val_mae: 22.7734\n",
      "Epoch 74/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.3157 - mae: 21.3157\n",
      "Epoch 74: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.3157 - mae: 21.3157 - val_loss: 22.5547 - val_mae: 22.5547\n",
      "Epoch 75/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.3128 - mae: 21.3128\n",
      "Epoch 75: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.3130 - mae: 21.3130 - val_loss: 23.1563 - val_mae: 23.1563\n",
      "Epoch 76/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.4264 - mae: 21.4264\n",
      "Epoch 76: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.4264 - mae: 21.4264 - val_loss: 22.9530 - val_mae: 22.9530\n",
      "Epoch 77/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.7310 - mae: 21.7310\n",
      "Epoch 77: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.7347 - mae: 21.7347 - val_loss: 29.5049 - val_mae: 29.5049\n",
      "Epoch 78/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 22.8013 - mae: 22.8013\n",
      "Epoch 78: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 22.8013 - mae: 22.8013 - val_loss: 22.5982 - val_mae: 22.5982\n",
      "Epoch 79/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 22.2251 - mae: 22.2251\n",
      "Epoch 79: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 22.2251 - mae: 22.2251 - val_loss: 22.6202 - val_mae: 22.6202\n",
      "Epoch 80/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 22.6252 - mae: 22.6252\n",
      "Epoch 80: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 22.6279 - mae: 22.6279 - val_loss: 27.6000 - val_mae: 27.6000\n",
      "Epoch 81/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 24.5346 - mae: 24.5346\n",
      "Epoch 81: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 24.5346 - mae: 24.5346 - val_loss: 23.0796 - val_mae: 23.0796\n",
      "Epoch 82/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 22.4196 - mae: 22.4196\n",
      "Epoch 82: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 22.4196 - mae: 22.4196 - val_loss: 22.9566 - val_mae: 22.9566\n",
      "Epoch 83/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 22.2247 - mae: 22.2247\n",
      "Epoch 83: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 22.2247 - mae: 22.2247 - val_loss: 22.5102 - val_mae: 22.5102\n",
      "Epoch 84/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 22.2738 - mae: 22.2738\n",
      "Epoch 84: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 22.2736 - mae: 22.2736 - val_loss: 23.0483 - val_mae: 23.0483\n",
      "Epoch 85/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 26.4615 - mae: 26.4615\n",
      "Epoch 85: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 26.4630 - mae: 26.4630 - val_loss: 30.2982 - val_mae: 30.2982\n",
      "Epoch 86/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 24.9085 - mae: 24.9085\n",
      "Epoch 86: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 24.9080 - mae: 24.9080 - val_loss: 23.8102 - val_mae: 23.8102\n",
      "Epoch 87/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 22.8428 - mae: 22.8428\n",
      "Epoch 87: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 22.8428 - mae: 22.8428 - val_loss: 23.2277 - val_mae: 23.2277\n",
      "Epoch 88/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 22.4299 - mae: 22.4299\n",
      "Epoch 88: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 22.4299 - mae: 22.4299 - val_loss: 23.5655 - val_mae: 23.5655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 22.2081 - mae: 22.2081\n",
      "Epoch 89: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 22.2079 - mae: 22.2079 - val_loss: 23.0292 - val_mae: 23.0292\n",
      "Epoch 90/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 22.0612 - mae: 22.0612\n",
      "Epoch 90: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 22.0611 - mae: 22.0611 - val_loss: 23.1479 - val_mae: 23.1479\n",
      "Epoch 91/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.9690 - mae: 21.9690\n",
      "Epoch 91: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.9690 - mae: 21.9690 - val_loss: 22.6303 - val_mae: 22.6303\n",
      "Epoch 92/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.9059 - mae: 21.9059\n",
      "Epoch 92: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.9059 - mae: 21.9059 - val_loss: 22.7378 - val_mae: 22.7378\n",
      "Epoch 93/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.8261 - mae: 21.8261\n",
      "Epoch 93: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.8260 - mae: 21.8260 - val_loss: 22.4192 - val_mae: 22.4192\n",
      "Epoch 94/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.7840 - mae: 21.7840\n",
      "Epoch 94: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.7840 - mae: 21.7840 - val_loss: 22.5698 - val_mae: 22.5698\n",
      "Epoch 95/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.7513 - mae: 21.7513\n",
      "Epoch 95: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.7513 - mae: 21.7513 - val_loss: 22.4520 - val_mae: 22.4520\n",
      "Epoch 96/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.7200 - mae: 21.7200\n",
      "Epoch 96: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.7200 - mae: 21.7200 - val_loss: 22.3387 - val_mae: 22.3387\n",
      "Epoch 97/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.6956 - mae: 21.6956\n",
      "Epoch 97: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.6956 - mae: 21.6956 - val_loss: 22.3038 - val_mae: 22.3038\n",
      "Epoch 98/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.6747 - mae: 21.6747\n",
      "Epoch 98: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.6747 - mae: 21.6747 - val_loss: 24.1709 - val_mae: 24.1709\n",
      "Epoch 99/100\n",
      "1702/1703 [============================>.] - ETA: 0s - loss: 21.6593 - mae: 21.6593\n",
      "Epoch 99: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.6592 - mae: 21.6592 - val_loss: 22.3365 - val_mae: 22.3365\n",
      "Epoch 100/100\n",
      "1703/1703 [==============================] - ETA: 0s - loss: 21.6408 - mae: 21.6408\n",
      "Epoch 100: val_mae did not improve from 22.04471\n",
      "1703/1703 [==============================] - 70s 41ms/step - loss: 21.6408 - mae: 21.6408 - val_loss: 22.7164 - val_mae: 22.7164\n"
     ]
    }
   ],
   "source": [
    "random_seed = 15\n",
    "tf.keras.utils.set_random_seed(random_seed)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "file_path = './RNN8_best_model.h5'\n",
    "checkpoint = ModelCheckpoint(file_path,\n",
    "                            monitor = 'val_mae',\n",
    "                            verbose=1,\n",
    "                            save_best_only=True,\n",
    "                            mode='auto')  \n",
    "\n",
    "hist = model.fit(x_train, y_train, validation_data=(x_test, y_test), \n",
    "                 epochs=100, batch_size=16, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e6c6ec3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 [==============================] - 3s 10ms/step - loss: 22.0447 - mae: 22.0447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[22.04470443725586, 22.04470443725586]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN8_model = tf.keras.models.load_model('./RNN8_best_model.h5')\n",
    "RNN8_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "725cc38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264/264 [==============================] - 3s 10ms/step\n"
     ]
    }
   ],
   "source": [
    "RNN8_pred = RNN8_model.predict(submission_x)\n",
    "pd.DataFrame(RNN8_pred).to_csv('RNN8_pred.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ab62f5",
   "metadata": {},
   "source": [
    "## RNN9 / window size 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "899bdca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27343, 120, 1) (27343, 336) (7968, 120, 1) (7968, 336) (8425, 120, 1) (8425, 336)\n"
     ]
    }
   ],
   "source": [
    "pre_day = 27 # (31 - pre_month) * 24 = windowsize /27 : 96//28 : 72//29 : 48//30 : 24//\n",
    "x_train, y_train, x_test, y_test, submission_x, submission_y = DataProcessing.data_form_descision(train_df, test_df, pre_day)\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape, submission_x.shape, submission_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "28eb0169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_24 (SimpleRNN)   (None, 120, 32)           1088      \n",
      "                                                                 \n",
      " simple_rnn_25 (SimpleRNN)   (None, 120, 32)           2080      \n",
      "                                                                 \n",
      " simple_rnn_26 (SimpleRNN)   (None, 16)                784       \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 64)                1088      \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 336)               11088     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,208\n",
      "Trainable params: 18,208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "initializer = tf.keras.initializers.GlorotNormal(seed=42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(32, activation='relu', input_shape=(x_train[0].shape), \n",
    "               return_sequences=True, kernel_initializer=initializer))\n",
    "model.add(SimpleRNN(32, activation='relu', return_sequences=True, kernel_initializer=initializer))\n",
    "model.add(SimpleRNN(16, activation='relu', kernel_initializer=initializer))\n",
    "model.add(Dense(64, activation='relu', kernel_initializer=initializer))\n",
    "model.add(Dense(32, activation='relu', kernel_initializer=initializer))\n",
    "model.add(Dense(336, activation='linear', kernel_initializer=initializer))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0004)\n",
    "model.compile(loss='mae', optimizer=optimizer, metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d6f4f9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 34.7666 - mae: 34.7666\n",
      "Epoch 1: val_mae improved from inf to 32.28339, saving model to .\\RNN9_best_model.h5\n",
      "1709/1709 [==============================] - 38s 22ms/step - loss: 34.7622 - mae: 34.7622 - val_loss: 32.2834 - val_mae: 32.2834\n",
      "Epoch 2/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 24.7536 - mae: 24.7536\n",
      "Epoch 2: val_mae improved from 32.28339 to 23.97766, saving model to .\\RNN9_best_model.h5\n",
      "1709/1709 [==============================] - 37s 21ms/step - loss: 24.7521 - mae: 24.7521 - val_loss: 23.9777 - val_mae: 23.9777\n",
      "Epoch 3/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 23.2920 - mae: 23.2920\n",
      "Epoch 3: val_mae improved from 23.97766 to 23.65331, saving model to .\\RNN9_best_model.h5\n",
      "1709/1709 [==============================] - 37s 21ms/step - loss: 23.2920 - mae: 23.2920 - val_loss: 23.6533 - val_mae: 23.6533\n",
      "Epoch 4/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 22.8354 - mae: 22.8354\n",
      "Epoch 4: val_mae improved from 23.65331 to 23.11870, saving model to .\\RNN9_best_model.h5\n",
      "1709/1709 [==============================] - 37s 21ms/step - loss: 22.8348 - mae: 22.8348 - val_loss: 23.1187 - val_mae: 23.1187\n",
      "Epoch 5/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 22.6313 - mae: 22.6313\n",
      "Epoch 5: val_mae improved from 23.11870 to 23.08495, saving model to .\\RNN9_best_model.h5\n",
      "1709/1709 [==============================] - 37s 21ms/step - loss: 22.6313 - mae: 22.6313 - val_loss: 23.0850 - val_mae: 23.0850\n",
      "Epoch 6/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 22.4867 - mae: 22.4867\n",
      "Epoch 6: val_mae did not improve from 23.08495\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 22.4865 - mae: 22.4865 - val_loss: 23.1644 - val_mae: 23.1644\n",
      "Epoch 7/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 22.4198 - mae: 22.4198\n",
      "Epoch 7: val_mae improved from 23.08495 to 22.66665, saving model to .\\RNN9_best_model.h5\n",
      "1709/1709 [==============================] - 36s 21ms/step - loss: 22.4198 - mae: 22.4198 - val_loss: 22.6666 - val_mae: 22.6666\n",
      "Epoch 8/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 22.3401 - mae: 22.3401\n",
      "Epoch 8: val_mae did not improve from 22.66665\n",
      "1709/1709 [==============================] - 38s 22ms/step - loss: 22.3399 - mae: 22.3399 - val_loss: 23.6626 - val_mae: 23.6626\n",
      "Epoch 9/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 22.2943 - mae: 22.2943\n",
      "Epoch 9: val_mae improved from 22.66665 to 22.65401, saving model to .\\RNN9_best_model.h5\n",
      "1709/1709 [==============================] - 38s 22ms/step - loss: 22.2943 - mae: 22.2943 - val_loss: 22.6540 - val_mae: 22.6540\n",
      "Epoch 10/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 22.2086 - mae: 22.2086\n",
      "Epoch 10: val_mae improved from 22.65401 to 22.53191, saving model to .\\RNN9_best_model.h5\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 22.2086 - mae: 22.2086 - val_loss: 22.5319 - val_mae: 22.5319\n",
      "Epoch 11/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 22.1740 - mae: 22.1740\n",
      "Epoch 11: val_mae did not improve from 22.53191\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 22.1740 - mae: 22.1740 - val_loss: 22.7759 - val_mae: 22.7759\n",
      "Epoch 12/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 22.1418 - mae: 22.1418\n",
      "Epoch 12: val_mae did not improve from 22.53191\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 22.1419 - mae: 22.1419 - val_loss: 22.7845 - val_mae: 22.7845\n",
      "Epoch 13/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 22.1037 - mae: 22.1037\n",
      "Epoch 13: val_mae did not improve from 22.53191\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 22.1033 - mae: 22.1033 - val_loss: 22.6990 - val_mae: 22.6990\n",
      "Epoch 14/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 22.0750 - mae: 22.0750\n",
      "Epoch 14: val_mae improved from 22.53191 to 22.49282, saving model to .\\RNN9_best_model.h5\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 22.0750 - mae: 22.0750 - val_loss: 22.4928 - val_mae: 22.4928\n",
      "Epoch 15/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 22.0256 - mae: 22.0256\n",
      "Epoch 15: val_mae improved from 22.49282 to 22.42600, saving model to .\\RNN9_best_model.h5\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 22.0256 - mae: 22.0256 - val_loss: 22.4260 - val_mae: 22.4260\n",
      "Epoch 16/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 22.0258 - mae: 22.0258\n",
      "Epoch 16: val_mae did not improve from 22.42600\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 22.0258 - mae: 22.0258 - val_loss: 22.6089 - val_mae: 22.6089\n",
      "Epoch 17/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 22.0027 - mae: 22.0027\n",
      "Epoch 17: val_mae improved from 22.42600 to 22.38442, saving model to .\\RNN9_best_model.h5\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 22.0027 - mae: 22.0027 - val_loss: 22.3844 - val_mae: 22.3844\n",
      "Epoch 18/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.9694 - mae: 21.9694\n",
      "Epoch 18: val_mae did not improve from 22.38442\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.9694 - mae: 21.9694 - val_loss: 22.5991 - val_mae: 22.5991\n",
      "Epoch 19/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.9423 - mae: 21.9423\n",
      "Epoch 19: val_mae did not improve from 22.38442\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.9425 - mae: 21.9425 - val_loss: 23.2342 - val_mae: 23.2342\n",
      "Epoch 20/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.9372 - mae: 21.9372\n",
      "Epoch 20: val_mae did not improve from 22.38442\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.9372 - mae: 21.9372 - val_loss: 22.4958 - val_mae: 22.4958\n",
      "Epoch 21/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.9343 - mae: 21.9343\n",
      "Epoch 21: val_mae improved from 22.38442 to 22.32685, saving model to .\\RNN9_best_model.h5\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.9343 - mae: 21.9343 - val_loss: 22.3269 - val_mae: 22.3269\n",
      "Epoch 22/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.9198 - mae: 21.9198\n",
      "Epoch 22: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.9196 - mae: 21.9196 - val_loss: 22.7854 - val_mae: 22.7854\n",
      "Epoch 23/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.8943 - mae: 21.8943\n",
      "Epoch 23: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.8948 - mae: 21.8948 - val_loss: 22.4408 - val_mae: 22.4408\n",
      "Epoch 24/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.8762 - mae: 21.8762\n",
      "Epoch 24: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.8762 - mae: 21.8762 - val_loss: 22.4513 - val_mae: 22.4513\n",
      "Epoch 25/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.8628 - mae: 21.8628\n",
      "Epoch 25: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.8624 - mae: 21.8624 - val_loss: 22.8886 - val_mae: 22.8886\n",
      "Epoch 26/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.8641 - mae: 21.8641\n",
      "Epoch 26: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.8640 - mae: 21.8640 - val_loss: 22.4082 - val_mae: 22.4082\n",
      "Epoch 27/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.8192 - mae: 21.8192\n",
      "Epoch 27: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.8190 - mae: 21.8190 - val_loss: 22.4681 - val_mae: 22.4681\n",
      "Epoch 28/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.8241 - mae: 21.8241\n",
      "Epoch 28: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.8241 - mae: 21.8241 - val_loss: 22.6735 - val_mae: 22.6735\n",
      "Epoch 29/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.8158 - mae: 21.8158\n",
      "Epoch 29: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.8157 - mae: 21.8157 - val_loss: 22.6019 - val_mae: 22.6019\n",
      "Epoch 30/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.7902 - mae: 21.7902\n",
      "Epoch 30: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.7902 - mae: 21.7902 - val_loss: 22.5252 - val_mae: 22.5252\n",
      "Epoch 31/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.7840 - mae: 21.7840\n",
      "Epoch 31: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.7841 - mae: 21.7841 - val_loss: 23.1734 - val_mae: 23.1734\n",
      "Epoch 32/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 22.2936 - mae: 22.2936\n",
      "Epoch 32: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 22.2936 - mae: 22.2936 - val_loss: 22.9186 - val_mae: 22.9186\n",
      "Epoch 33/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.9627 - mae: 21.9627\n",
      "Epoch 33: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.9625 - mae: 21.9625 - val_loss: 22.8580 - val_mae: 22.8580\n",
      "Epoch 34/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.8984 - mae: 21.8984\n",
      "Epoch 34: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.8984 - mae: 21.8984 - val_loss: 22.5472 - val_mae: 22.5472\n",
      "Epoch 35/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.8674 - mae: 21.8674\n",
      "Epoch 35: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.8675 - mae: 21.8675 - val_loss: 22.9743 - val_mae: 22.9743\n",
      "Epoch 36/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.8466 - mae: 21.8466\n",
      "Epoch 36: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.8471 - mae: 21.8471 - val_loss: 22.4575 - val_mae: 22.4575\n",
      "Epoch 37/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.8171 - mae: 21.8171\n",
      "Epoch 37: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.8173 - mae: 21.8173 - val_loss: 23.6098 - val_mae: 23.6098\n",
      "Epoch 38/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.8203 - mae: 21.8203\n",
      "Epoch 38: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.8205 - mae: 21.8205 - val_loss: 22.6621 - val_mae: 22.6621\n",
      "Epoch 39/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.7856 - mae: 21.7856\n",
      "Epoch 39: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.7856 - mae: 21.7856 - val_loss: 22.3480 - val_mae: 22.3480\n",
      "Epoch 40/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.7752 - mae: 21.7752\n",
      "Epoch 40: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.7753 - mae: 21.7753 - val_loss: 22.4830 - val_mae: 22.4830\n",
      "Epoch 41/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.7619 - mae: 21.7619\n",
      "Epoch 41: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.7619 - mae: 21.7619 - val_loss: 22.9232 - val_mae: 22.9232\n",
      "Epoch 42/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.7581 - mae: 21.7581\n",
      "Epoch 42: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.7582 - mae: 21.7582 - val_loss: 22.5080 - val_mae: 22.5080\n",
      "Epoch 43/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.7466 - mae: 21.7466\n",
      "Epoch 43: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.7472 - mae: 21.7472 - val_loss: 22.6378 - val_mae: 22.6378\n",
      "Epoch 44/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.7317 - mae: 21.7317\n",
      "Epoch 44: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.7317 - mae: 21.7317 - val_loss: 22.8089 - val_mae: 22.8089\n",
      "Epoch 45/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.7333 - mae: 21.7333\n",
      "Epoch 45: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.7330 - mae: 21.7330 - val_loss: 22.4743 - val_mae: 22.4743\n",
      "Epoch 46/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.7214 - mae: 21.7214\n",
      "Epoch 46: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.7214 - mae: 21.7214 - val_loss: 22.6186 - val_mae: 22.6186\n",
      "Epoch 47/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.7068 - mae: 21.7068\n",
      "Epoch 47: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.7068 - mae: 21.7068 - val_loss: 22.6705 - val_mae: 22.6705\n",
      "Epoch 48/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.7200 - mae: 21.7200\n",
      "Epoch 48: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.7197 - mae: 21.7197 - val_loss: 23.0822 - val_mae: 23.0822\n",
      "Epoch 49/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.7027 - mae: 21.7027\n",
      "Epoch 49: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.7026 - mae: 21.7026 - val_loss: 22.4903 - val_mae: 22.4903\n",
      "Epoch 50/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.6989 - mae: 21.6989\n",
      "Epoch 50: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.6988 - mae: 21.6988 - val_loss: 22.4483 - val_mae: 22.4483\n",
      "Epoch 51/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.6974 - mae: 21.6974\n",
      "Epoch 51: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.6975 - mae: 21.6975 - val_loss: 22.4667 - val_mae: 22.4667\n",
      "Epoch 52/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.7037 - mae: 21.7037\n",
      "Epoch 52: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.7033 - mae: 21.7033 - val_loss: 22.6504 - val_mae: 22.6504\n",
      "Epoch 53/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.6902 - mae: 21.6902\n",
      "Epoch 53: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.6901 - mae: 21.6901 - val_loss: 23.0391 - val_mae: 23.0391\n",
      "Epoch 54/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.6779 - mae: 21.6779\n",
      "Epoch 54: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.6778 - mae: 21.6778 - val_loss: 22.3887 - val_mae: 22.3887\n",
      "Epoch 55/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.6713 - mae: 21.6713\n",
      "Epoch 55: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.6712 - mae: 21.6712 - val_loss: 22.6770 - val_mae: 22.6770\n",
      "Epoch 56/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.6691 - mae: 21.6691\n",
      "Epoch 56: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.6693 - mae: 21.6693 - val_loss: 22.3477 - val_mae: 22.3477\n",
      "Epoch 57/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.6592 - mae: 21.6592\n",
      "Epoch 57: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.6592 - mae: 21.6592 - val_loss: 23.0478 - val_mae: 23.0478\n",
      "Epoch 58/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.6615 - mae: 21.6615\n",
      "Epoch 58: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.6612 - mae: 21.6612 - val_loss: 22.4000 - val_mae: 22.4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.6538 - mae: 21.6538\n",
      "Epoch 59: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 21ms/step - loss: 21.6539 - mae: 21.6539 - val_loss: 23.4598 - val_mae: 23.4598\n",
      "Epoch 60/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.6495 - mae: 21.6495\n",
      "Epoch 60: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.6494 - mae: 21.6494 - val_loss: 23.4834 - val_mae: 23.4834\n",
      "Epoch 61/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.6353 - mae: 21.6353\n",
      "Epoch 61: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.6354 - mae: 21.6354 - val_loss: 22.5132 - val_mae: 22.5132\n",
      "Epoch 62/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.6284 - mae: 21.6284\n",
      "Epoch 62: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.6284 - mae: 21.6284 - val_loss: 22.4212 - val_mae: 22.4212\n",
      "Epoch 63/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.6315 - mae: 21.6315\n",
      "Epoch 63: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.6316 - mae: 21.6316 - val_loss: 22.7296 - val_mae: 22.7296\n",
      "Epoch 64/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.6366 - mae: 21.6366\n",
      "Epoch 64: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.6370 - mae: 21.6370 - val_loss: 22.5194 - val_mae: 22.5194\n",
      "Epoch 65/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.6124 - mae: 21.6124\n",
      "Epoch 65: val_mae did not improve from 22.32685\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.6126 - mae: 21.6126 - val_loss: 22.6820 - val_mae: 22.6820\n",
      "Epoch 66/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.6042 - mae: 21.6042\n",
      "Epoch 66: val_mae improved from 22.32685 to 22.24091, saving model to .\\RNN9_best_model.h5\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.6042 - mae: 21.6042 - val_loss: 22.2409 - val_mae: 22.2409\n",
      "Epoch 67/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.6431 - mae: 21.6431\n",
      "Epoch 67: val_mae did not improve from 22.24091\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.6431 - mae: 21.6431 - val_loss: 22.6795 - val_mae: 22.6795\n",
      "Epoch 68/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.5936 - mae: 21.5936\n",
      "Epoch 68: val_mae improved from 22.24091 to 22.20263, saving model to .\\RNN9_best_model.h5\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.5938 - mae: 21.5938 - val_loss: 22.2026 - val_mae: 22.2026\n",
      "Epoch 69/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.6173 - mae: 21.6173\n",
      "Epoch 69: val_mae did not improve from 22.20263\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.6174 - mae: 21.6174 - val_loss: 22.4611 - val_mae: 22.4611\n",
      "Epoch 70/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.6123 - mae: 21.6123\n",
      "Epoch 70: val_mae did not improve from 22.20263\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.6123 - mae: 21.6123 - val_loss: 22.6644 - val_mae: 22.6644\n",
      "Epoch 71/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.6073 - mae: 21.6073\n",
      "Epoch 71: val_mae did not improve from 22.20263\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.6069 - mae: 21.6069 - val_loss: 22.7100 - val_mae: 22.7100\n",
      "Epoch 72/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.5966 - mae: 21.5966\n",
      "Epoch 72: val_mae did not improve from 22.20263\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.5962 - mae: 21.5962 - val_loss: 23.0636 - val_mae: 23.0636\n",
      "Epoch 73/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.6005 - mae: 21.6005\n",
      "Epoch 73: val_mae did not improve from 22.20263\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.6005 - mae: 21.6005 - val_loss: 22.6435 - val_mae: 22.6435\n",
      "Epoch 74/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.6075 - mae: 21.6075\n",
      "Epoch 74: val_mae did not improve from 22.20263\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.6075 - mae: 21.6075 - val_loss: 22.2243 - val_mae: 22.2243\n",
      "Epoch 75/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.5808 - mae: 21.5808\n",
      "Epoch 75: val_mae did not improve from 22.20263\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.5808 - mae: 21.5808 - val_loss: 22.5291 - val_mae: 22.5291\n",
      "Epoch 76/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.5907 - mae: 21.5907\n",
      "Epoch 76: val_mae did not improve from 22.20263\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.5907 - mae: 21.5907 - val_loss: 23.8900 - val_mae: 23.8900\n",
      "Epoch 77/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.5694 - mae: 21.5694\n",
      "Epoch 77: val_mae did not improve from 22.20263\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.5694 - mae: 21.5694 - val_loss: 22.7492 - val_mae: 22.7492\n",
      "Epoch 78/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.5808 - mae: 21.5808\n",
      "Epoch 78: val_mae did not improve from 22.20263\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.5808 - mae: 21.5808 - val_loss: 22.9468 - val_mae: 22.9468\n",
      "Epoch 79/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.5628 - mae: 21.5628\n",
      "Epoch 79: val_mae did not improve from 22.20263\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.5628 - mae: 21.5628 - val_loss: 23.8371 - val_mae: 23.8371\n",
      "Epoch 80/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.5597 - mae: 21.5597\n",
      "Epoch 80: val_mae did not improve from 22.20263\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.5597 - mae: 21.5597 - val_loss: 22.5698 - val_mae: 22.5698\n",
      "Epoch 81/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.5500 - mae: 21.5500\n",
      "Epoch 81: val_mae did not improve from 22.20263\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.5502 - mae: 21.5502 - val_loss: 22.2169 - val_mae: 22.2169\n",
      "Epoch 82/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.5662 - mae: 21.5662\n",
      "Epoch 82: val_mae did not improve from 22.20263\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.5663 - mae: 21.5663 - val_loss: 22.2829 - val_mae: 22.2829\n",
      "Epoch 83/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.5516 - mae: 21.5516\n",
      "Epoch 83: val_mae did not improve from 22.20263\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.5516 - mae: 21.5516 - val_loss: 22.2491 - val_mae: 22.2491\n",
      "Epoch 84/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.5534 - mae: 21.5534\n",
      "Epoch 84: val_mae did not improve from 22.20263\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.5531 - mae: 21.5531 - val_loss: 22.5647 - val_mae: 22.5647\n",
      "Epoch 85/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.5450 - mae: 21.5450\n",
      "Epoch 85: val_mae did not improve from 22.20263\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.5450 - mae: 21.5450 - val_loss: 22.3658 - val_mae: 22.3658\n",
      "Epoch 86/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.5440 - mae: 21.5440\n",
      "Epoch 86: val_mae did not improve from 22.20263\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.5440 - mae: 21.5440 - val_loss: 22.3116 - val_mae: 22.3116\n",
      "Epoch 87/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.5310 - mae: 21.5310\n",
      "Epoch 87: val_mae did not improve from 22.20263\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.5310 - mae: 21.5310 - val_loss: 23.1097 - val_mae: 23.1097\n",
      "Epoch 88/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.5327 - mae: 21.5327\n",
      "Epoch 88: val_mae did not improve from 22.20263\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.5327 - mae: 21.5327 - val_loss: 22.7179 - val_mae: 22.7179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.5274 - mae: 21.5274\n",
      "Epoch 89: val_mae did not improve from 22.20263\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.5275 - mae: 21.5275 - val_loss: 22.4418 - val_mae: 22.4418\n",
      "Epoch 90/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.5189 - mae: 21.5189\n",
      "Epoch 90: val_mae did not improve from 22.20263\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.5189 - mae: 21.5189 - val_loss: 23.7808 - val_mae: 23.7808\n",
      "Epoch 91/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.5329 - mae: 21.5329\n",
      "Epoch 91: val_mae did not improve from 22.20263\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.5331 - mae: 21.5331 - val_loss: 22.2892 - val_mae: 22.2892\n",
      "Epoch 92/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.5155 - mae: 21.5155\n",
      "Epoch 92: val_mae did not improve from 22.20263\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.5155 - mae: 21.5155 - val_loss: 22.3718 - val_mae: 22.3718\n",
      "Epoch 93/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.5131 - mae: 21.5131\n",
      "Epoch 93: val_mae did not improve from 22.20263\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.5131 - mae: 21.5131 - val_loss: 22.7900 - val_mae: 22.7900\n",
      "Epoch 94/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.5200 - mae: 21.5200\n",
      "Epoch 94: val_mae did not improve from 22.20263\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.5201 - mae: 21.5201 - val_loss: 23.4697 - val_mae: 23.4697\n",
      "Epoch 95/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.5142 - mae: 21.5142\n",
      "Epoch 95: val_mae did not improve from 22.20263\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.5143 - mae: 21.5143 - val_loss: 22.7776 - val_mae: 22.7776\n",
      "Epoch 96/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.5089 - mae: 21.5089\n",
      "Epoch 96: val_mae did not improve from 22.20263\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.5088 - mae: 21.5088 - val_loss: 23.0095 - val_mae: 23.0095\n",
      "Epoch 97/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.4991 - mae: 21.4991\n",
      "Epoch 97: val_mae did not improve from 22.20263\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.4995 - mae: 21.4995 - val_loss: 23.4527 - val_mae: 23.4527\n",
      "Epoch 98/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.5028 - mae: 21.5028\n",
      "Epoch 98: val_mae did not improve from 22.20263\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.5028 - mae: 21.5028 - val_loss: 22.4711 - val_mae: 22.4711\n",
      "Epoch 99/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.4897 - mae: 21.4897\n",
      "Epoch 99: val_mae did not improve from 22.20263\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.4896 - mae: 21.4896 - val_loss: 23.5993 - val_mae: 23.5993\n",
      "Epoch 100/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4842 - mae: 21.4842\n",
      "Epoch 100: val_mae did not improve from 22.20263\n",
      "1709/1709 [==============================] - 37s 22ms/step - loss: 21.4848 - mae: 21.4848 - val_loss: 22.8842 - val_mae: 22.8842\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "tf.keras.utils.set_random_seed(seed)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "checkpoint = ModelCheckpoint('./RNN9_best_model.h5',\n",
    "                        monitor = 'val_mae',\n",
    "                        verbose=1,\n",
    "                        save_best_only=True,\n",
    "                        mode='auto')  \n",
    "\n",
    "hist = model.fit(x_train, y_train, validation_data=(x_test, y_test), \n",
    "                 epochs=100, batch_size=16, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e571cdb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249/249 [==============================] - 2s 6ms/step - loss: 22.2026 - mae: 22.2026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[22.20262908935547, 22.20262908935547]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN9_model = tf.keras.models.load_model('./RNN9_best_model.h5')\n",
    "RNN9_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c23e0e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264/264 [==============================] - 2s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "RNN9_pred = RNN9_model.predict(submission_x)\n",
    "pd.DataFrame(RNN9_pred).to_csv('RNN9_pred.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47b7c73",
   "metadata": {},
   "source": [
    "## RNN10 / window size 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4c6d3411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27391, 72, 1) (27391, 336) (8016, 72, 1) (8016, 336) (8425, 72, 1) (8425, 336)\n"
     ]
    }
   ],
   "source": [
    "pre_day = 29 # (31 - pre_month) * 24 = windowsize /27 : 96//28 : 72//29 : 48//30 : 24//\n",
    "x_train, y_train, x_test, y_test, submission_x, submission_y = DataProcessing.data_form_descision(train_df, test_df, pre_day)\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape, submission_x.shape, submission_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "77d7c5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_27 (SimpleRNN)   (None, 72, 32)            1088      \n",
      "                                                                 \n",
      " simple_rnn_28 (SimpleRNN)   (None, 72, 32)            2080      \n",
      "                                                                 \n",
      " simple_rnn_29 (SimpleRNN)   (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 336)               11088     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,528\n",
      "Trainable params: 20,528\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "initializer = tf.keras.initializers.GlorotNormal(seed=15)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(32, activation='relu', input_shape=(x_train[0].shape), \n",
    "               return_sequences=True, kernel_initializer=initializer))\n",
    "model.add(SimpleRNN(32, activation='relu',return_sequences=True, kernel_initializer=initializer))\n",
    "model.add(SimpleRNN(32, activation='relu', kernel_initializer=initializer))\n",
    "model.add(Dense(64, activation='relu', kernel_initializer=initializer))\n",
    "model.add(Dense(32, activation='relu', kernel_initializer=initializer))\n",
    "model.add(Dense(336, activation='linear', kernel_initializer=initializer))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.00006)\n",
    "model.compile(loss='mae', optimizer=optimizer, metrics=['mae'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dd0700b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1707/1712 [============================>.] - ETA: 0s - loss: 42.0992 - mae: 42.0992\n",
      "Epoch 1: val_mae improved from inf to 35.61140, saving model to .\\RNN10_best_model.h5\n",
      "1712/1712 [==============================] - 21s 12ms/step - loss: 42.0772 - mae: 42.0772 - val_loss: 35.6114 - val_mae: 35.6114\n",
      "Epoch 2/200\n",
      "1706/1712 [============================>.] - ETA: 0s - loss: 33.9098 - mae: 33.9098\n",
      "Epoch 2: val_mae improved from 35.61140 to 34.63104, saving model to .\\RNN10_best_model.h5\n",
      "1712/1712 [==============================] - 20s 12ms/step - loss: 33.9082 - mae: 33.9082 - val_loss: 34.6310 - val_mae: 34.6310\n",
      "Epoch 3/200\n",
      "1709/1712 [============================>.] - ETA: 0s - loss: 30.0513 - mae: 30.0513\n",
      "Epoch 3: val_mae improved from 34.63104 to 28.24335, saving model to .\\RNN10_best_model.h5\n",
      "1712/1712 [==============================] - 20s 12ms/step - loss: 30.0470 - mae: 30.0470 - val_loss: 28.2433 - val_mae: 28.2433\n",
      "Epoch 4/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 26.0206 - mae: 26.0206\n",
      "Epoch 4: val_mae improved from 28.24335 to 25.60419, saving model to .\\RNN10_best_model.h5\n",
      "1712/1712 [==============================] - 20s 12ms/step - loss: 26.0206 - mae: 26.0206 - val_loss: 25.6042 - val_mae: 25.6042\n",
      "Epoch 5/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 23.9909 - mae: 23.9909\n",
      "Epoch 5: val_mae improved from 25.60419 to 24.14633, saving model to .\\RNN10_best_model.h5\n",
      "1712/1712 [==============================] - 20s 12ms/step - loss: 23.9909 - mae: 23.9909 - val_loss: 24.1463 - val_mae: 24.1463\n",
      "Epoch 6/200\n",
      "1711/1712 [============================>.] - ETA: 0s - loss: 23.1496 - mae: 23.1496\n",
      "Epoch 6: val_mae improved from 24.14633 to 23.73919, saving model to .\\RNN10_best_model.h5\n",
      "1712/1712 [==============================] - 20s 12ms/step - loss: 23.1496 - mae: 23.1496 - val_loss: 23.7392 - val_mae: 23.7392\n",
      "Epoch 7/200\n",
      "1709/1712 [============================>.] - ETA: 0s - loss: 22.9579 - mae: 22.9579\n",
      "Epoch 7: val_mae improved from 23.73919 to 23.62394, saving model to .\\RNN10_best_model.h5\n",
      "1712/1712 [==============================] - 20s 12ms/step - loss: 22.9571 - mae: 22.9571 - val_loss: 23.6239 - val_mae: 23.6239\n",
      "Epoch 8/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 22.9009 - mae: 22.9009\n",
      "Epoch 8: val_mae did not improve from 23.62394\n",
      "1712/1712 [==============================] - 20s 11ms/step - loss: 22.9009 - mae: 22.9009 - val_loss: 23.6264 - val_mae: 23.6264\n",
      "Epoch 9/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 22.8529 - mae: 22.8529\n",
      "Epoch 9: val_mae improved from 23.62394 to 23.53769, saving model to .\\RNN10_best_model.h5\n",
      "1712/1712 [==============================] - 20s 12ms/step - loss: 22.8529 - mae: 22.8529 - val_loss: 23.5377 - val_mae: 23.5377\n",
      "Epoch 10/200\n",
      "1709/1712 [============================>.] - ETA: 0s - loss: 22.8097 - mae: 22.8097\n",
      "Epoch 10: val_mae did not improve from 23.53769\n",
      "1712/1712 [==============================] - 20s 12ms/step - loss: 22.8096 - mae: 22.8096 - val_loss: 23.5584 - val_mae: 23.5584\n",
      "Epoch 11/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 22.7599 - mae: 22.7599\n",
      "Epoch 11: val_mae improved from 23.53769 to 23.48195, saving model to .\\RNN10_best_model.h5\n",
      "1712/1712 [==============================] - 20s 12ms/step - loss: 22.7599 - mae: 22.7599 - val_loss: 23.4819 - val_mae: 23.4819\n",
      "Epoch 12/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 22.7065 - mae: 22.7065\n",
      "Epoch 12: val_mae improved from 23.48195 to 23.39994, saving model to .\\RNN10_best_model.h5\n",
      "1712/1712 [==============================] - 20s 12ms/step - loss: 22.7069 - mae: 22.7069 - val_loss: 23.3999 - val_mae: 23.3999\n",
      "Epoch 13/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 22.6567 - mae: 22.6567\n",
      "Epoch 13: val_mae did not improve from 23.39994\n",
      "1712/1712 [==============================] - 20s 12ms/step - loss: 22.6563 - mae: 22.6563 - val_loss: 23.4266 - val_mae: 23.4266\n",
      "Epoch 14/200\n",
      "1709/1712 [============================>.] - ETA: 0s - loss: 22.5971 - mae: 22.5971\n",
      "Epoch 14: val_mae did not improve from 23.39994\n",
      "1712/1712 [==============================] - 20s 12ms/step - loss: 22.5970 - mae: 22.5970 - val_loss: 23.4556 - val_mae: 23.4556\n",
      "Epoch 15/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 22.5391 - mae: 22.5391\n",
      "Epoch 15: val_mae did not improve from 23.39994\n",
      "1712/1712 [==============================] - 20s 12ms/step - loss: 22.5391 - mae: 22.5391 - val_loss: 23.4876 - val_mae: 23.4876\n",
      "Epoch 16/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 22.4782 - mae: 22.4782\n",
      "Epoch 16: val_mae improved from 23.39994 to 23.25412, saving model to .\\RNN10_best_model.h5\n",
      "1712/1712 [==============================] - 20s 12ms/step - loss: 22.4781 - mae: 22.4781 - val_loss: 23.2541 - val_mae: 23.2541\n",
      "Epoch 17/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 22.4352 - mae: 22.4352\n",
      "Epoch 17: val_mae improved from 23.25412 to 23.23566, saving model to .\\RNN10_best_model.h5\n",
      "1712/1712 [==============================] - 20s 12ms/step - loss: 22.4346 - mae: 22.4346 - val_loss: 23.2357 - val_mae: 23.2357\n",
      "Epoch 18/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 22.3664 - mae: 22.3664\n",
      "Epoch 18: val_mae improved from 23.23566 to 23.13223, saving model to .\\RNN10_best_model.h5\n",
      "1712/1712 [==============================] - 20s 11ms/step - loss: 22.3665 - mae: 22.3665 - val_loss: 23.1322 - val_mae: 23.1322\n",
      "Epoch 19/200\n",
      "1708/1712 [============================>.] - ETA: 0s - loss: 22.3003 - mae: 22.3003\n",
      "Epoch 19: val_mae did not improve from 23.13223\n",
      "1712/1712 [==============================] - 20s 11ms/step - loss: 22.3004 - mae: 22.3004 - val_loss: 23.2713 - val_mae: 23.2713\n",
      "Epoch 20/200\n",
      "1711/1712 [============================>.] - ETA: 0s - loss: 22.2425 - mae: 22.2425\n",
      "Epoch 20: val_mae improved from 23.13223 to 23.06797, saving model to .\\RNN10_best_model.h5\n",
      "1712/1712 [==============================] - 20s 11ms/step - loss: 22.2426 - mae: 22.2426 - val_loss: 23.0680 - val_mae: 23.0680\n",
      "Epoch 21/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 22.1843 - mae: 22.1843\n",
      "Epoch 21: val_mae did not improve from 23.06797\n",
      "1712/1712 [==============================] - 20s 11ms/step - loss: 22.1843 - mae: 22.1843 - val_loss: 23.1084 - val_mae: 23.1084\n",
      "Epoch 22/200\n",
      "1708/1712 [============================>.] - ETA: 0s - loss: 22.1384 - mae: 22.1384\n",
      "Epoch 22: val_mae did not improve from 23.06797\n",
      "1712/1712 [==============================] - 20s 11ms/step - loss: 22.1381 - mae: 22.1381 - val_loss: 23.0951 - val_mae: 23.0951\n",
      "Epoch 23/200\n",
      "1708/1712 [============================>.] - ETA: 0s - loss: 22.1013 - mae: 22.1013\n",
      "Epoch 23: val_mae did not improve from 23.06797\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 22.1014 - mae: 22.1014 - val_loss: 23.2099 - val_mae: 23.2099\n",
      "Epoch 24/200\n",
      "1707/1712 [============================>.] - ETA: 0s - loss: 22.0728 - mae: 22.0728\n",
      "Epoch 24: val_mae improved from 23.06797 to 22.81046, saving model to .\\RNN10_best_model.h5\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 22.0734 - mae: 22.0734 - val_loss: 22.8105 - val_mae: 22.8105\n",
      "Epoch 25/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 22.0616 - mae: 22.0616\n",
      "Epoch 25: val_mae improved from 22.81046 to 22.80033, saving model to .\\RNN10_best_model.h5\n",
      "1712/1712 [==============================] - 20s 11ms/step - loss: 22.0616 - mae: 22.0616 - val_loss: 22.8003 - val_mae: 22.8003\n",
      "Epoch 26/200\n",
      "1707/1712 [============================>.] - ETA: 0s - loss: 22.0308 - mae: 22.0308\n",
      "Epoch 26: val_mae did not improve from 22.80033\n",
      "1712/1712 [==============================] - 20s 11ms/step - loss: 22.0312 - mae: 22.0312 - val_loss: 22.8682 - val_mae: 22.8682\n",
      "Epoch 27/200\n",
      "1711/1712 [============================>.] - ETA: 0s - loss: 22.0117 - mae: 22.0117\n",
      "Epoch 27: val_mae did not improve from 22.80033\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 22.0117 - mae: 22.0117 - val_loss: 22.8135 - val_mae: 22.8135\n",
      "Epoch 28/200\n",
      "1708/1712 [============================>.] - ETA: 0s - loss: 21.9943 - mae: 21.9943\n",
      "Epoch 28: val_mae improved from 22.80033 to 22.78726, saving model to .\\RNN10_best_model.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.9953 - mae: 21.9953 - val_loss: 22.7873 - val_mae: 22.7873\n",
      "Epoch 29/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 21.9821 - mae: 21.9821\n",
      "Epoch 29: val_mae improved from 22.78726 to 22.76823, saving model to .\\RNN10_best_model.h5\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.9821 - mae: 21.9821 - val_loss: 22.7682 - val_mae: 22.7682\n",
      "Epoch 30/200\n",
      "1711/1712 [============================>.] - ETA: 0s - loss: 21.9757 - mae: 21.9757\n",
      "Epoch 30: val_mae improved from 22.76823 to 22.71494, saving model to .\\RNN10_best_model.h5\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.9756 - mae: 21.9756 - val_loss: 22.7149 - val_mae: 22.7149\n",
      "Epoch 31/200\n",
      "1711/1712 [============================>.] - ETA: 0s - loss: 21.9589 - mae: 21.9589\n",
      "Epoch 31: val_mae did not improve from 22.71494\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.9592 - mae: 21.9592 - val_loss: 22.9306 - val_mae: 22.9306\n",
      "Epoch 32/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.9520 - mae: 21.9520\n",
      "Epoch 32: val_mae did not improve from 22.71494\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.9519 - mae: 21.9519 - val_loss: 22.7740 - val_mae: 22.7740\n",
      "Epoch 33/200\n",
      "1711/1712 [============================>.] - ETA: 0s - loss: 21.9419 - mae: 21.9419\n",
      "Epoch 33: val_mae improved from 22.71494 to 22.67289, saving model to .\\RNN10_best_model.h5\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.9415 - mae: 21.9415 - val_loss: 22.6729 - val_mae: 22.6729\n",
      "Epoch 34/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.9336 - mae: 21.9336\n",
      "Epoch 34: val_mae did not improve from 22.67289\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.9340 - mae: 21.9340 - val_loss: 22.9667 - val_mae: 22.9667\n",
      "Epoch 35/200\n",
      "1707/1712 [============================>.] - ETA: 0s - loss: 21.9264 - mae: 21.9264\n",
      "Epoch 35: val_mae did not improve from 22.67289\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.9265 - mae: 21.9265 - val_loss: 23.1096 - val_mae: 23.1096\n",
      "Epoch 36/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.9146 - mae: 21.9146\n",
      "Epoch 36: val_mae did not improve from 22.67289\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.9150 - mae: 21.9150 - val_loss: 22.7171 - val_mae: 22.7171\n",
      "Epoch 37/200\n",
      "1708/1712 [============================>.] - ETA: 0s - loss: 21.9074 - mae: 21.9074\n",
      "Epoch 37: val_mae did not improve from 22.67289\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.9083 - mae: 21.9083 - val_loss: 23.1185 - val_mae: 23.1185\n",
      "Epoch 38/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.8941 - mae: 21.8941\n",
      "Epoch 38: val_mae did not improve from 22.67289\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.8935 - mae: 21.8935 - val_loss: 22.7246 - val_mae: 22.7246\n",
      "Epoch 39/200\n",
      "1708/1712 [============================>.] - ETA: 0s - loss: 21.8865 - mae: 21.8865\n",
      "Epoch 39: val_mae did not improve from 22.67289\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.8864 - mae: 21.8864 - val_loss: 23.0875 - val_mae: 23.0875\n",
      "Epoch 40/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.8901 - mae: 21.8901\n",
      "Epoch 40: val_mae did not improve from 22.67289\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.8903 - mae: 21.8903 - val_loss: 23.1429 - val_mae: 23.1429\n",
      "Epoch 41/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 21.8742 - mae: 21.8742\n",
      "Epoch 41: val_mae improved from 22.67289 to 22.66606, saving model to .\\RNN10_best_model.h5\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.8742 - mae: 21.8742 - val_loss: 22.6661 - val_mae: 22.6661\n",
      "Epoch 42/200\n",
      "1711/1712 [============================>.] - ETA: 0s - loss: 21.8694 - mae: 21.8694\n",
      "Epoch 42: val_mae did not improve from 22.66606\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.8696 - mae: 21.8696 - val_loss: 22.9408 - val_mae: 22.9408\n",
      "Epoch 43/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 21.8603 - mae: 21.8603\n",
      "Epoch 43: val_mae did not improve from 22.66606\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.8603 - mae: 21.8603 - val_loss: 22.9652 - val_mae: 22.9652\n",
      "Epoch 44/200\n",
      "1709/1712 [============================>.] - ETA: 0s - loss: 21.8544 - mae: 21.8544\n",
      "Epoch 44: val_mae did not improve from 22.66606\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.8546 - mae: 21.8546 - val_loss: 22.9475 - val_mae: 22.9475\n",
      "Epoch 45/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 21.8448 - mae: 21.8448\n",
      "Epoch 45: val_mae did not improve from 22.66606\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.8448 - mae: 21.8448 - val_loss: 22.7202 - val_mae: 22.7202\n",
      "Epoch 46/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 21.8428 - mae: 21.8428\n",
      "Epoch 46: val_mae did not improve from 22.66606\n",
      "1712/1712 [==============================] - 20s 11ms/step - loss: 21.8428 - mae: 21.8428 - val_loss: 22.9063 - val_mae: 22.9063\n",
      "Epoch 47/200\n",
      "1708/1712 [============================>.] - ETA: 0s - loss: 21.8336 - mae: 21.8336\n",
      "Epoch 47: val_mae did not improve from 22.66606\n",
      "1712/1712 [==============================] - 20s 11ms/step - loss: 21.8331 - mae: 21.8331 - val_loss: 23.3834 - val_mae: 23.3834\n",
      "Epoch 48/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 21.8262 - mae: 21.8262\n",
      "Epoch 48: val_mae improved from 22.66606 to 22.61146, saving model to .\\RNN10_best_model.h5\n",
      "1712/1712 [==============================] - 20s 11ms/step - loss: 21.8262 - mae: 21.8262 - val_loss: 22.6115 - val_mae: 22.6115\n",
      "Epoch 49/200\n",
      "1708/1712 [============================>.] - ETA: 0s - loss: 21.8142 - mae: 21.8142\n",
      "Epoch 49: val_mae did not improve from 22.61146\n",
      "1712/1712 [==============================] - 20s 11ms/step - loss: 21.8147 - mae: 21.8147 - val_loss: 22.6649 - val_mae: 22.6649\n",
      "Epoch 50/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 21.8129 - mae: 21.8129\n",
      "Epoch 50: val_mae did not improve from 22.61146\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.8129 - mae: 21.8129 - val_loss: 22.7833 - val_mae: 22.7833\n",
      "Epoch 51/200\n",
      "1708/1712 [============================>.] - ETA: 0s - loss: 21.8081 - mae: 21.8081\n",
      "Epoch 51: val_mae improved from 22.61146 to 22.55501, saving model to .\\RNN10_best_model.h5\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.8085 - mae: 21.8085 - val_loss: 22.5550 - val_mae: 22.5550\n",
      "Epoch 52/200\n",
      "1709/1712 [============================>.] - ETA: 0s - loss: 21.8008 - mae: 21.8008\n",
      "Epoch 52: val_mae did not improve from 22.55501\n",
      "1712/1712 [==============================] - 20s 11ms/step - loss: 21.8009 - mae: 21.8009 - val_loss: 23.0018 - val_mae: 23.0018\n",
      "Epoch 53/200\n",
      "1709/1712 [============================>.] - ETA: 0s - loss: 21.7913 - mae: 21.7913\n",
      "Epoch 53: val_mae did not improve from 22.55501\n",
      "1712/1712 [==============================] - 20s 12ms/step - loss: 21.7915 - mae: 21.7915 - val_loss: 22.5662 - val_mae: 22.5662\n",
      "Epoch 54/200\n",
      "1708/1712 [============================>.] - ETA: 0s - loss: 21.7838 - mae: 21.7838\n",
      "Epoch 54: val_mae did not improve from 22.55501\n",
      "1712/1712 [==============================] - 20s 12ms/step - loss: 21.7837 - mae: 21.7837 - val_loss: 22.5964 - val_mae: 22.5964\n",
      "Epoch 55/200\n",
      "1709/1712 [============================>.] - ETA: 0s - loss: 21.7780 - mae: 21.7780\n",
      "Epoch 55: val_mae improved from 22.55501 to 22.50306, saving model to .\\RNN10_best_model.h5\n",
      "1712/1712 [==============================] - 20s 12ms/step - loss: 21.7781 - mae: 21.7781 - val_loss: 22.5031 - val_mae: 22.5031\n",
      "Epoch 56/200\n",
      "1708/1712 [============================>.] - ETA: 0s - loss: 21.7756 - mae: 21.7756\n",
      "Epoch 56: val_mae did not improve from 22.50306\n",
      "1712/1712 [==============================] - 20s 12ms/step - loss: 21.7751 - mae: 21.7751 - val_loss: 23.1948 - val_mae: 23.1948\n",
      "Epoch 57/200\n",
      "1711/1712 [============================>.] - ETA: 0s - loss: 21.7692 - mae: 21.7692\n",
      "Epoch 57: val_mae did not improve from 22.50306\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.7689 - mae: 21.7689 - val_loss: 22.7996 - val_mae: 22.7996\n",
      "Epoch 58/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 21.7535 - mae: 21.7535\n",
      "Epoch 58: val_mae did not improve from 22.50306\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.7535 - mae: 21.7535 - val_loss: 22.7800 - val_mae: 22.7800\n",
      "Epoch 59/200\n",
      "1711/1712 [============================>.] - ETA: 0s - loss: 21.7529 - mae: 21.7529\n",
      "Epoch 59: val_mae did not improve from 22.50306\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.7529 - mae: 21.7529 - val_loss: 22.7370 - val_mae: 22.7370\n",
      "Epoch 60/200\n",
      "1708/1712 [============================>.] - ETA: 0s - loss: 21.7437 - mae: 21.7437\n",
      "Epoch 60: val_mae did not improve from 22.50306\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.7437 - mae: 21.7437 - val_loss: 22.7203 - val_mae: 22.7203\n",
      "Epoch 61/200\n",
      "1711/1712 [============================>.] - ETA: 0s - loss: 21.7355 - mae: 21.7355\n",
      "Epoch 61: val_mae did not improve from 22.50306\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.7353 - mae: 21.7353 - val_loss: 22.9415 - val_mae: 22.9415\n",
      "Epoch 62/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.7355 - mae: 21.7355\n",
      "Epoch 62: val_mae did not improve from 22.50306\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.7359 - mae: 21.7359 - val_loss: 22.5331 - val_mae: 22.5331\n",
      "Epoch 63/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 21.7215 - mae: 21.7215\n",
      "Epoch 63: val_mae did not improve from 22.50306\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.7215 - mae: 21.7215 - val_loss: 22.6023 - val_mae: 22.6023\n",
      "Epoch 64/200\n",
      "1709/1712 [============================>.] - ETA: 0s - loss: 21.7203 - mae: 21.7203\n",
      "Epoch 64: val_mae did not improve from 22.50306\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.7208 - mae: 21.7208 - val_loss: 22.5614 - val_mae: 22.5614\n",
      "Epoch 65/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 21.7155 - mae: 21.7155\n",
      "Epoch 65: val_mae improved from 22.50306 to 22.44304, saving model to .\\RNN10_best_model.h5\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.7155 - mae: 21.7155 - val_loss: 22.4430 - val_mae: 22.4430\n",
      "Epoch 66/200\n",
      "1708/1712 [============================>.] - ETA: 0s - loss: 21.6998 - mae: 21.6998\n",
      "Epoch 66: val_mae did not improve from 22.44304\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.6998 - mae: 21.6998 - val_loss: 22.7054 - val_mae: 22.7054\n",
      "Epoch 67/200\n",
      "1709/1712 [============================>.] - ETA: 0s - loss: 21.7018 - mae: 21.7018\n",
      "Epoch 67: val_mae did not improve from 22.44304\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.7022 - mae: 21.7022 - val_loss: 22.4696 - val_mae: 22.4696\n",
      "Epoch 68/200\n",
      "1709/1712 [============================>.] - ETA: 0s - loss: 21.6956 - mae: 21.6956\n",
      "Epoch 68: val_mae did not improve from 22.44304\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.6953 - mae: 21.6953 - val_loss: 22.5088 - val_mae: 22.5088\n",
      "Epoch 69/200\n",
      "1711/1712 [============================>.] - ETA: 0s - loss: 21.6888 - mae: 21.6888\n",
      "Epoch 69: val_mae did not improve from 22.44304\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.6887 - mae: 21.6887 - val_loss: 22.5965 - val_mae: 22.5965\n",
      "Epoch 70/200\n",
      "1711/1712 [============================>.] - ETA: 0s - loss: 21.6768 - mae: 21.6768\n",
      "Epoch 70: val_mae did not improve from 22.44304\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.6771 - mae: 21.6771 - val_loss: 22.6090 - val_mae: 22.6090\n",
      "Epoch 71/200\n",
      "1709/1712 [============================>.] - ETA: 0s - loss: 21.6763 - mae: 21.6763\n",
      "Epoch 71: val_mae did not improve from 22.44304\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.6760 - mae: 21.6760 - val_loss: 22.5389 - val_mae: 22.5389\n",
      "Epoch 72/200\n",
      "1709/1712 [============================>.] - ETA: 0s - loss: 21.6659 - mae: 21.6659\n",
      "Epoch 72: val_mae improved from 22.44304 to 22.38150, saving model to .\\RNN10_best_model.h5\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.6664 - mae: 21.6664 - val_loss: 22.3815 - val_mae: 22.3815\n",
      "Epoch 73/200\n",
      "1711/1712 [============================>.] - ETA: 0s - loss: 21.6652 - mae: 21.6652\n",
      "Epoch 73: val_mae did not improve from 22.38150\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.6655 - mae: 21.6655 - val_loss: 22.5789 - val_mae: 22.5789\n",
      "Epoch 74/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 21.6520 - mae: 21.6520\n",
      "Epoch 74: val_mae improved from 22.38150 to 22.35736, saving model to .\\RNN10_best_model.h5\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.6520 - mae: 21.6520 - val_loss: 22.3574 - val_mae: 22.3574\n",
      "Epoch 75/200\n",
      "1711/1712 [============================>.] - ETA: 0s - loss: 21.6526 - mae: 21.6526\n",
      "Epoch 75: val_mae did not improve from 22.35736\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.6526 - mae: 21.6526 - val_loss: 22.5881 - val_mae: 22.5881\n",
      "Epoch 76/200\n",
      "1706/1712 [============================>.] - ETA: 0s - loss: 21.6452 - mae: 21.6452\n",
      "Epoch 76: val_mae did not improve from 22.35736\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.6444 - mae: 21.6444 - val_loss: 22.8621 - val_mae: 22.8621\n",
      "Epoch 77/200\n",
      "1709/1712 [============================>.] - ETA: 0s - loss: 21.6368 - mae: 21.6368\n",
      "Epoch 77: val_mae did not improve from 22.35736\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.6377 - mae: 21.6377 - val_loss: 22.5741 - val_mae: 22.5741\n",
      "Epoch 78/200\n",
      "1706/1712 [============================>.] - ETA: 0s - loss: 21.6271 - mae: 21.6271\n",
      "Epoch 78: val_mae did not improve from 22.35736\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.6273 - mae: 21.6273 - val_loss: 22.6611 - val_mae: 22.6611\n",
      "Epoch 79/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 21.6245 - mae: 21.6245\n",
      "Epoch 79: val_mae did not improve from 22.35736\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.6245 - mae: 21.6245 - val_loss: 22.4579 - val_mae: 22.4579\n",
      "Epoch 80/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.6189 - mae: 21.6189\n",
      "Epoch 80: val_mae improved from 22.35736 to 22.35382, saving model to .\\RNN10_best_model.h5\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.6185 - mae: 21.6185 - val_loss: 22.3538 - val_mae: 22.3538\n",
      "Epoch 81/200\n",
      "1707/1712 [============================>.] - ETA: 0s - loss: 21.6112 - mae: 21.6112\n",
      "Epoch 81: val_mae did not improve from 22.35382\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.6114 - mae: 21.6114 - val_loss: 22.6123 - val_mae: 22.6123\n",
      "Epoch 82/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.6063 - mae: 21.6063\n",
      "Epoch 82: val_mae did not improve from 22.35382\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.6058 - mae: 21.6058 - val_loss: 22.5025 - val_mae: 22.5025\n",
      "Epoch 83/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 21.6069 - mae: 21.6069\n",
      "Epoch 83: val_mae improved from 22.35382 to 22.35184, saving model to .\\RNN10_best_model.h5\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.6069 - mae: 21.6069 - val_loss: 22.3518 - val_mae: 22.3518\n",
      "Epoch 84/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 21.5997 - mae: 21.5997\n",
      "Epoch 84: val_mae did not improve from 22.35184\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.5997 - mae: 21.5997 - val_loss: 22.5240 - val_mae: 22.5240\n",
      "Epoch 85/200\n",
      "1711/1712 [============================>.] - ETA: 0s - loss: 21.5933 - mae: 21.5933\n",
      "Epoch 85: val_mae did not improve from 22.35184\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.5936 - mae: 21.5936 - val_loss: 22.7319 - val_mae: 22.7319\n",
      "Epoch 86/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.5848 - mae: 21.5848\n",
      "Epoch 86: val_mae improved from 22.35184 to 22.30812, saving model to .\\RNN10_best_model.h5\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.5852 - mae: 21.5852 - val_loss: 22.3081 - val_mae: 22.3081\n",
      "Epoch 87/200\n",
      "1711/1712 [============================>.] - ETA: 0s - loss: 21.5829 - mae: 21.5829\n",
      "Epoch 87: val_mae did not improve from 22.30812\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.5828 - mae: 21.5828 - val_loss: 22.4134 - val_mae: 22.4134\n",
      "Epoch 88/200\n",
      "1711/1712 [============================>.] - ETA: 0s - loss: 21.5730 - mae: 21.5730\n",
      "Epoch 88: val_mae did not improve from 22.30812\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.5733 - mae: 21.5733 - val_loss: 22.5056 - val_mae: 22.5056\n",
      "Epoch 89/200\n",
      "1707/1712 [============================>.] - ETA: 0s - loss: 21.5821 - mae: 21.5821\n",
      "Epoch 89: val_mae did not improve from 22.30812\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.5818 - mae: 21.5818 - val_loss: 22.3511 - val_mae: 22.3511\n",
      "Epoch 90/200\n",
      "1709/1712 [============================>.] - ETA: 0s - loss: 21.5674 - mae: 21.5674\n",
      "Epoch 90: val_mae did not improve from 22.30812\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.5674 - mae: 21.5674 - val_loss: 22.4754 - val_mae: 22.4754\n",
      "Epoch 91/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.5688 - mae: 21.5688\n",
      "Epoch 91: val_mae did not improve from 22.30812\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.5683 - mae: 21.5683 - val_loss: 22.4932 - val_mae: 22.4932\n",
      "Epoch 92/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.5598 - mae: 21.5598\n",
      "Epoch 92: val_mae did not improve from 22.30812\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.5595 - mae: 21.5595 - val_loss: 22.5549 - val_mae: 22.5549\n",
      "Epoch 93/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 21.5583 - mae: 21.5583\n",
      "Epoch 93: val_mae did not improve from 22.30812\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.5583 - mae: 21.5583 - val_loss: 23.0409 - val_mae: 23.0409\n",
      "Epoch 94/200\n",
      "1711/1712 [============================>.] - ETA: 0s - loss: 21.5512 - mae: 21.5512\n",
      "Epoch 94: val_mae did not improve from 22.30812\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.5514 - mae: 21.5514 - val_loss: 22.9073 - val_mae: 22.9073\n",
      "Epoch 95/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.5520 - mae: 21.5520\n",
      "Epoch 95: val_mae did not improve from 22.30812\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.5517 - mae: 21.5517 - val_loss: 22.3962 - val_mae: 22.3962\n",
      "Epoch 96/200\n",
      "1708/1712 [============================>.] - ETA: 0s - loss: 21.5492 - mae: 21.5492\n",
      "Epoch 96: val_mae did not improve from 22.30812\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.5497 - mae: 21.5497 - val_loss: 22.5697 - val_mae: 22.5697\n",
      "Epoch 97/200\n",
      "1709/1712 [============================>.] - ETA: 0s - loss: 21.5458 - mae: 21.5458\n",
      "Epoch 97: val_mae did not improve from 22.30812\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.5462 - mae: 21.5462 - val_loss: 22.7689 - val_mae: 22.7689\n",
      "Epoch 98/200\n",
      "1711/1712 [============================>.] - ETA: 0s - loss: 21.5434 - mae: 21.5434\n",
      "Epoch 98: val_mae did not improve from 22.30812\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.5434 - mae: 21.5434 - val_loss: 22.6747 - val_mae: 22.6747\n",
      "Epoch 99/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 21.5422 - mae: 21.5422\n",
      "Epoch 99: val_mae improved from 22.30812 to 22.24192, saving model to .\\RNN10_best_model.h5\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.5422 - mae: 21.5422 - val_loss: 22.2419 - val_mae: 22.2419\n",
      "Epoch 100/200\n",
      "1709/1712 [============================>.] - ETA: 0s - loss: 21.5419 - mae: 21.5419\n",
      "Epoch 100: val_mae did not improve from 22.24192\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.5415 - mae: 21.5415 - val_loss: 22.3344 - val_mae: 22.3344\n",
      "Epoch 101/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 21.5325 - mae: 21.5325\n",
      "Epoch 101: val_mae did not improve from 22.24192\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.5325 - mae: 21.5325 - val_loss: 22.4753 - val_mae: 22.4753\n",
      "Epoch 102/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.5324 - mae: 21.5324\n",
      "Epoch 102: val_mae did not improve from 22.24192\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.5329 - mae: 21.5329 - val_loss: 22.5084 - val_mae: 22.5084\n",
      "Epoch 103/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.5265 - mae: 21.5265\n",
      "Epoch 103: val_mae did not improve from 22.24192\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.5263 - mae: 21.5263 - val_loss: 22.6416 - val_mae: 22.6416\n",
      "Epoch 104/200\n",
      "1707/1712 [============================>.] - ETA: 0s - loss: 21.5255 - mae: 21.5255\n",
      "Epoch 104: val_mae did not improve from 22.24192\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.5254 - mae: 21.5254 - val_loss: 22.8705 - val_mae: 22.8705\n",
      "Epoch 105/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 21.5221 - mae: 21.5221\n",
      "Epoch 105: val_mae did not improve from 22.24192\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.5221 - mae: 21.5221 - val_loss: 22.3855 - val_mae: 22.3855\n",
      "Epoch 106/200\n",
      "1709/1712 [============================>.] - ETA: 0s - loss: 21.5190 - mae: 21.5190\n",
      "Epoch 106: val_mae did not improve from 22.24192\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.5186 - mae: 21.5186 - val_loss: 22.5327 - val_mae: 22.5327\n",
      "Epoch 107/200\n",
      "1711/1712 [============================>.] - ETA: 0s - loss: 21.5193 - mae: 21.5193\n",
      "Epoch 107: val_mae did not improve from 22.24192\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.5197 - mae: 21.5197 - val_loss: 22.3082 - val_mae: 22.3082\n",
      "Epoch 108/200\n",
      "1708/1712 [============================>.] - ETA: 0s - loss: 21.5164 - mae: 21.5164\n",
      "Epoch 108: val_mae did not improve from 22.24192\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.5166 - mae: 21.5166 - val_loss: 22.2992 - val_mae: 22.2992\n",
      "Epoch 109/200\n",
      "1707/1712 [============================>.] - ETA: 0s - loss: 21.5158 - mae: 21.5158\n",
      "Epoch 109: val_mae did not improve from 22.24192\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.5165 - mae: 21.5165 - val_loss: 22.4938 - val_mae: 22.4938\n",
      "Epoch 110/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 21.5134 - mae: 21.5134\n",
      "Epoch 110: val_mae did not improve from 22.24192\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.5134 - mae: 21.5134 - val_loss: 22.3609 - val_mae: 22.3609\n",
      "Epoch 111/200\n",
      "1708/1712 [============================>.] - ETA: 0s - loss: 21.5087 - mae: 21.5087\n",
      "Epoch 111: val_mae did not improve from 22.24192\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.5089 - mae: 21.5089 - val_loss: 22.4615 - val_mae: 22.4615\n",
      "Epoch 112/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 21.5089 - mae: 21.5089\n",
      "Epoch 112: val_mae did not improve from 22.24192\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.5089 - mae: 21.5089 - val_loss: 22.3755 - val_mae: 22.3755\n",
      "Epoch 113/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 21.5059 - mae: 21.5059\n",
      "Epoch 113: val_mae did not improve from 22.24192\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.5059 - mae: 21.5059 - val_loss: 22.7297 - val_mae: 22.7297\n",
      "Epoch 114/200\n",
      "1709/1712 [============================>.] - ETA: 0s - loss: 21.4989 - mae: 21.4989\n",
      "Epoch 114: val_mae did not improve from 22.24192\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4990 - mae: 21.4990 - val_loss: 22.4633 - val_mae: 22.4633\n",
      "Epoch 115/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.4971 - mae: 21.4971\n",
      "Epoch 115: val_mae did not improve from 22.24192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4971 - mae: 21.4971 - val_loss: 22.5140 - val_mae: 22.5140\n",
      "Epoch 116/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 21.5031 - mae: 21.5031\n",
      "Epoch 116: val_mae did not improve from 22.24192\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.5031 - mae: 21.5031 - val_loss: 22.4712 - val_mae: 22.4712\n",
      "Epoch 117/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.5008 - mae: 21.5008\n",
      "Epoch 117: val_mae did not improve from 22.24192\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.5004 - mae: 21.5004 - val_loss: 22.4523 - val_mae: 22.4523\n",
      "Epoch 118/200\n",
      "1709/1712 [============================>.] - ETA: 0s - loss: 21.4976 - mae: 21.4976\n",
      "Epoch 118: val_mae did not improve from 22.24192\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4969 - mae: 21.4969 - val_loss: 22.4804 - val_mae: 22.4804\n",
      "Epoch 119/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 21.4961 - mae: 21.4961\n",
      "Epoch 119: val_mae did not improve from 22.24192\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4961 - mae: 21.4961 - val_loss: 22.6658 - val_mae: 22.6658\n",
      "Epoch 120/200\n",
      "1711/1712 [============================>.] - ETA: 0s - loss: 21.4964 - mae: 21.4964\n",
      "Epoch 120: val_mae did not improve from 22.24192\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4963 - mae: 21.4963 - val_loss: 22.6393 - val_mae: 22.6393\n",
      "Epoch 121/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.4913 - mae: 21.4913\n",
      "Epoch 121: val_mae did not improve from 22.24192\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4911 - mae: 21.4911 - val_loss: 22.5958 - val_mae: 22.5958\n",
      "Epoch 122/200\n",
      "1711/1712 [============================>.] - ETA: 0s - loss: 21.4902 - mae: 21.4902\n",
      "Epoch 122: val_mae did not improve from 22.24192\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4899 - mae: 21.4899 - val_loss: 22.6193 - val_mae: 22.6193\n",
      "Epoch 123/200\n",
      "1709/1712 [============================>.] - ETA: 0s - loss: 21.4873 - mae: 21.4873\n",
      "Epoch 123: val_mae did not improve from 22.24192\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4872 - mae: 21.4872 - val_loss: 22.3854 - val_mae: 22.3854\n",
      "Epoch 124/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 21.4865 - mae: 21.4865\n",
      "Epoch 124: val_mae did not improve from 22.24192\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4865 - mae: 21.4865 - val_loss: 22.4154 - val_mae: 22.4154\n",
      "Epoch 125/200\n",
      "1711/1712 [============================>.] - ETA: 0s - loss: 21.4831 - mae: 21.4831\n",
      "Epoch 125: val_mae improved from 22.24192 to 22.20549, saving model to .\\RNN10_best_model.h5\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4832 - mae: 21.4832 - val_loss: 22.2055 - val_mae: 22.2055\n",
      "Epoch 126/200\n",
      "1709/1712 [============================>.] - ETA: 0s - loss: 21.4856 - mae: 21.4856\n",
      "Epoch 126: val_mae did not improve from 22.20549\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4858 - mae: 21.4858 - val_loss: 22.4900 - val_mae: 22.4900\n",
      "Epoch 127/200\n",
      "1711/1712 [============================>.] - ETA: 0s - loss: 21.4801 - mae: 21.4801\n",
      "Epoch 127: val_mae did not improve from 22.20549\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4798 - mae: 21.4798 - val_loss: 22.5012 - val_mae: 22.5012\n",
      "Epoch 128/200\n",
      "1706/1712 [============================>.] - ETA: 0s - loss: 21.4821 - mae: 21.4821\n",
      "Epoch 128: val_mae did not improve from 22.20549\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4821 - mae: 21.4821 - val_loss: 22.5640 - val_mae: 22.5640\n",
      "Epoch 129/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.4787 - mae: 21.4787\n",
      "Epoch 129: val_mae did not improve from 22.20549\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4788 - mae: 21.4788 - val_loss: 22.4358 - val_mae: 22.4358\n",
      "Epoch 130/200\n",
      "1711/1712 [============================>.] - ETA: 0s - loss: 21.4760 - mae: 21.4760\n",
      "Epoch 130: val_mae did not improve from 22.20549\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4764 - mae: 21.4764 - val_loss: 22.4659 - val_mae: 22.4659\n",
      "Epoch 131/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 21.4749 - mae: 21.4749\n",
      "Epoch 131: val_mae did not improve from 22.20549\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4749 - mae: 21.4749 - val_loss: 22.2898 - val_mae: 22.2898\n",
      "Epoch 132/200\n",
      "1709/1712 [============================>.] - ETA: 0s - loss: 21.4721 - mae: 21.4721\n",
      "Epoch 132: val_mae did not improve from 22.20549\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4721 - mae: 21.4721 - val_loss: 22.7131 - val_mae: 22.7131\n",
      "Epoch 133/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 21.4708 - mae: 21.4708\n",
      "Epoch 133: val_mae did not improve from 22.20549\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4708 - mae: 21.4708 - val_loss: 22.6055 - val_mae: 22.6055\n",
      "Epoch 134/200\n",
      "1709/1712 [============================>.] - ETA: 0s - loss: 21.4660 - mae: 21.4660\n",
      "Epoch 134: val_mae did not improve from 22.20549\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4656 - mae: 21.4656 - val_loss: 22.9160 - val_mae: 22.9160\n",
      "Epoch 135/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.4688 - mae: 21.4688\n",
      "Epoch 135: val_mae did not improve from 22.20549\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4687 - mae: 21.4687 - val_loss: 23.3454 - val_mae: 23.3454\n",
      "Epoch 136/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.4687 - mae: 21.4687\n",
      "Epoch 136: val_mae did not improve from 22.20549\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4681 - mae: 21.4681 - val_loss: 22.4053 - val_mae: 22.4053\n",
      "Epoch 137/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.4688 - mae: 21.4688\n",
      "Epoch 137: val_mae did not improve from 22.20549\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4689 - mae: 21.4689 - val_loss: 22.2394 - val_mae: 22.2394\n",
      "Epoch 138/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.4693 - mae: 21.4693\n",
      "Epoch 138: val_mae did not improve from 22.20549\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4690 - mae: 21.4690 - val_loss: 22.7549 - val_mae: 22.7549\n",
      "Epoch 139/200\n",
      "1708/1712 [============================>.] - ETA: 0s - loss: 21.4653 - mae: 21.4653\n",
      "Epoch 139: val_mae did not improve from 22.20549\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4649 - mae: 21.4649 - val_loss: 22.9634 - val_mae: 22.9634\n",
      "Epoch 140/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 21.4571 - mae: 21.4571\n",
      "Epoch 140: val_mae did not improve from 22.20549\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4571 - mae: 21.4571 - val_loss: 22.5536 - val_mae: 22.5536\n",
      "Epoch 141/200\n",
      "1708/1712 [============================>.] - ETA: 0s - loss: 21.4577 - mae: 21.4577\n",
      "Epoch 141: val_mae did not improve from 22.20549\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4574 - mae: 21.4574 - val_loss: 22.5736 - val_mae: 22.5736\n",
      "Epoch 142/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 21.4547 - mae: 21.4547\n",
      "Epoch 142: val_mae improved from 22.20549 to 22.19605, saving model to .\\RNN10_best_model.h5\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4547 - mae: 21.4547 - val_loss: 22.1961 - val_mae: 22.1961\n",
      "Epoch 143/200\n",
      "1711/1712 [============================>.] - ETA: 0s - loss: 21.4588 - mae: 21.4588\n",
      "Epoch 143: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4591 - mae: 21.4591 - val_loss: 22.5098 - val_mae: 22.5098\n",
      "Epoch 144/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.4530 - mae: 21.4530\n",
      "Epoch 144: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4535 - mae: 21.4535 - val_loss: 22.4233 - val_mae: 22.4233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.4560 - mae: 21.4560\n",
      "Epoch 145: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4560 - mae: 21.4560 - val_loss: 22.4771 - val_mae: 22.4771\n",
      "Epoch 146/200\n",
      "1708/1712 [============================>.] - ETA: 0s - loss: 21.4527 - mae: 21.4527\n",
      "Epoch 146: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4526 - mae: 21.4526 - val_loss: 22.7964 - val_mae: 22.7964\n",
      "Epoch 147/200\n",
      "1711/1712 [============================>.] - ETA: 0s - loss: 21.4473 - mae: 21.4473\n",
      "Epoch 147: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4473 - mae: 21.4473 - val_loss: 22.3279 - val_mae: 22.3279\n",
      "Epoch 148/200\n",
      "1711/1712 [============================>.] - ETA: 0s - loss: 21.4537 - mae: 21.4537\n",
      "Epoch 148: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4537 - mae: 21.4537 - val_loss: 22.7144 - val_mae: 22.7144\n",
      "Epoch 149/200\n",
      "1709/1712 [============================>.] - ETA: 0s - loss: 21.4453 - mae: 21.4453\n",
      "Epoch 149: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4452 - mae: 21.4452 - val_loss: 22.2143 - val_mae: 22.2143\n",
      "Epoch 150/200\n",
      "1706/1712 [============================>.] - ETA: 0s - loss: 21.4407 - mae: 21.4407\n",
      "Epoch 150: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4407 - mae: 21.4407 - val_loss: 22.3033 - val_mae: 22.3033\n",
      "Epoch 151/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.4419 - mae: 21.4419\n",
      "Epoch 151: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4420 - mae: 21.4420 - val_loss: 22.2112 - val_mae: 22.2112\n",
      "Epoch 152/200\n",
      "1709/1712 [============================>.] - ETA: 0s - loss: 21.4429 - mae: 21.4429\n",
      "Epoch 152: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4427 - mae: 21.4427 - val_loss: 22.4649 - val_mae: 22.4649\n",
      "Epoch 153/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.4452 - mae: 21.4452\n",
      "Epoch 153: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4450 - mae: 21.4450 - val_loss: 22.6432 - val_mae: 22.6432\n",
      "Epoch 154/200\n",
      "1708/1712 [============================>.] - ETA: 0s - loss: 21.4483 - mae: 21.4483\n",
      "Epoch 154: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4480 - mae: 21.4480 - val_loss: 22.5409 - val_mae: 22.5409\n",
      "Epoch 155/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.4329 - mae: 21.4329\n",
      "Epoch 155: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4329 - mae: 21.4329 - val_loss: 22.4101 - val_mae: 22.4101\n",
      "Epoch 156/200\n",
      "1709/1712 [============================>.] - ETA: 0s - loss: 21.4350 - mae: 21.4350\n",
      "Epoch 156: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4345 - mae: 21.4345 - val_loss: 22.3291 - val_mae: 22.3291\n",
      "Epoch 157/200\n",
      "1708/1712 [============================>.] - ETA: 0s - loss: 21.4390 - mae: 21.4390\n",
      "Epoch 157: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4387 - mae: 21.4387 - val_loss: 22.6804 - val_mae: 22.6804\n",
      "Epoch 158/200\n",
      "1711/1712 [============================>.] - ETA: 0s - loss: 21.4317 - mae: 21.4317\n",
      "Epoch 158: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4313 - mae: 21.4313 - val_loss: 22.4069 - val_mae: 22.4069\n",
      "Epoch 159/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 21.4360 - mae: 21.4360\n",
      "Epoch 159: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4360 - mae: 21.4360 - val_loss: 22.4279 - val_mae: 22.4279\n",
      "Epoch 160/200\n",
      "1711/1712 [============================>.] - ETA: 0s - loss: 21.4377 - mae: 21.4377\n",
      "Epoch 160: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4380 - mae: 21.4380 - val_loss: 22.4676 - val_mae: 22.4676\n",
      "Epoch 161/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.4233 - mae: 21.4233\n",
      "Epoch 161: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4232 - mae: 21.4232 - val_loss: 22.6023 - val_mae: 22.6023\n",
      "Epoch 162/200\n",
      "1711/1712 [============================>.] - ETA: 0s - loss: 21.4386 - mae: 21.4386\n",
      "Epoch 162: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4385 - mae: 21.4385 - val_loss: 22.4047 - val_mae: 22.4047\n",
      "Epoch 163/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.4281 - mae: 21.4281\n",
      "Epoch 163: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4280 - mae: 21.4280 - val_loss: 22.4492 - val_mae: 22.4492\n",
      "Epoch 164/200\n",
      "1709/1712 [============================>.] - ETA: 0s - loss: 21.4259 - mae: 21.4259\n",
      "Epoch 164: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4257 - mae: 21.4257 - val_loss: 22.8615 - val_mae: 22.8615\n",
      "Epoch 165/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.4290 - mae: 21.4290\n",
      "Epoch 165: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4288 - mae: 21.4288 - val_loss: 22.6125 - val_mae: 22.6125\n",
      "Epoch 166/200\n",
      "1711/1712 [============================>.] - ETA: 0s - loss: 21.4279 - mae: 21.4279\n",
      "Epoch 166: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4282 - mae: 21.4282 - val_loss: 22.3176 - val_mae: 22.3176\n",
      "Epoch 167/200\n",
      "1709/1712 [============================>.] - ETA: 0s - loss: 21.4250 - mae: 21.4250\n",
      "Epoch 167: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4250 - mae: 21.4250 - val_loss: 22.3065 - val_mae: 22.3065\n",
      "Epoch 168/200\n",
      "1709/1712 [============================>.] - ETA: 0s - loss: 21.4222 - mae: 21.4222\n",
      "Epoch 168: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4213 - mae: 21.4213 - val_loss: 22.3643 - val_mae: 22.3643\n",
      "Epoch 169/200\n",
      "1709/1712 [============================>.] - ETA: 0s - loss: 21.4213 - mae: 21.4213\n",
      "Epoch 169: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4218 - mae: 21.4218 - val_loss: 22.2732 - val_mae: 22.2732\n",
      "Epoch 170/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.4194 - mae: 21.4194\n",
      "Epoch 170: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4193 - mae: 21.4193 - val_loss: 22.6226 - val_mae: 22.6226\n",
      "Epoch 171/200\n",
      "1707/1712 [============================>.] - ETA: 0s - loss: 21.4180 - mae: 21.4180\n",
      "Epoch 171: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4183 - mae: 21.4183 - val_loss: 22.9061 - val_mae: 22.9061\n",
      "Epoch 172/200\n",
      "1708/1712 [============================>.] - ETA: 0s - loss: 21.4174 - mae: 21.4174\n",
      "Epoch 172: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4167 - mae: 21.4167 - val_loss: 22.7311 - val_mae: 22.7311\n",
      "Epoch 173/200\n",
      "1711/1712 [============================>.] - ETA: 0s - loss: 21.4138 - mae: 21.4138\n",
      "Epoch 173: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4142 - mae: 21.4142 - val_loss: 22.3120 - val_mae: 22.3120\n",
      "Epoch 174/200\n",
      "1707/1712 [============================>.] - ETA: 0s - loss: 21.4139 - mae: 21.4139\n",
      "Epoch 174: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4136 - mae: 21.4136 - val_loss: 22.5182 - val_mae: 22.5182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "1706/1712 [============================>.] - ETA: 0s - loss: 21.4096 - mae: 21.4096\n",
      "Epoch 175: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4103 - mae: 21.4103 - val_loss: 22.3870 - val_mae: 22.3870\n",
      "Epoch 176/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.4127 - mae: 21.4127\n",
      "Epoch 176: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4130 - mae: 21.4130 - val_loss: 22.4429 - val_mae: 22.4429\n",
      "Epoch 177/200\n",
      "1706/1712 [============================>.] - ETA: 0s - loss: 21.4116 - mae: 21.4116\n",
      "Epoch 177: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4112 - mae: 21.4112 - val_loss: 22.8502 - val_mae: 22.8502\n",
      "Epoch 178/200\n",
      "1708/1712 [============================>.] - ETA: 0s - loss: 21.4067 - mae: 21.4067\n",
      "Epoch 178: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4074 - mae: 21.4074 - val_loss: 22.4853 - val_mae: 22.4853\n",
      "Epoch 179/200\n",
      "1708/1712 [============================>.] - ETA: 0s - loss: 21.4084 - mae: 21.4084\n",
      "Epoch 179: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4086 - mae: 21.4086 - val_loss: 22.5009 - val_mae: 22.5009\n",
      "Epoch 180/200\n",
      "1708/1712 [============================>.] - ETA: 0s - loss: 21.4055 - mae: 21.4055\n",
      "Epoch 180: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4056 - mae: 21.4056 - val_loss: 22.4240 - val_mae: 22.4240\n",
      "Epoch 181/200\n",
      "1711/1712 [============================>.] - ETA: 0s - loss: 21.4068 - mae: 21.4068\n",
      "Epoch 181: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4070 - mae: 21.4070 - val_loss: 22.3093 - val_mae: 22.3093\n",
      "Epoch 182/200\n",
      "1709/1712 [============================>.] - ETA: 0s - loss: 21.4043 - mae: 21.4043\n",
      "Epoch 182: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4045 - mae: 21.4045 - val_loss: 23.1310 - val_mae: 23.1310\n",
      "Epoch 183/200\n",
      "1706/1712 [============================>.] - ETA: 0s - loss: 21.4028 - mae: 21.4028\n",
      "Epoch 183: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4033 - mae: 21.4033 - val_loss: 22.3258 - val_mae: 22.3258\n",
      "Epoch 184/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.4030 - mae: 21.4030\n",
      "Epoch 184: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4029 - mae: 21.4029 - val_loss: 22.2492 - val_mae: 22.2492\n",
      "Epoch 185/200\n",
      "1708/1712 [============================>.] - ETA: 0s - loss: 21.4009 - mae: 21.4009\n",
      "Epoch 185: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.4006 - mae: 21.4006 - val_loss: 22.7496 - val_mae: 22.7496\n",
      "Epoch 186/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.3986 - mae: 21.3986\n",
      "Epoch 186: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.3985 - mae: 21.3985 - val_loss: 22.4889 - val_mae: 22.4889\n",
      "Epoch 187/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 21.3984 - mae: 21.3984\n",
      "Epoch 187: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.3984 - mae: 21.3984 - val_loss: 22.7147 - val_mae: 22.7147\n",
      "Epoch 188/200\n",
      "1709/1712 [============================>.] - ETA: 0s - loss: 21.3960 - mae: 21.3960\n",
      "Epoch 188: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.3962 - mae: 21.3962 - val_loss: 22.4307 - val_mae: 22.4307\n",
      "Epoch 189/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.3904 - mae: 21.3904\n",
      "Epoch 189: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.3908 - mae: 21.3908 - val_loss: 22.3742 - val_mae: 22.3742\n",
      "Epoch 190/200\n",
      "1709/1712 [============================>.] - ETA: 0s - loss: 21.3934 - mae: 21.3934\n",
      "Epoch 190: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.3934 - mae: 21.3934 - val_loss: 22.3676 - val_mae: 22.3676\n",
      "Epoch 191/200\n",
      "1709/1712 [============================>.] - ETA: 0s - loss: 21.3928 - mae: 21.3928\n",
      "Epoch 191: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.3928 - mae: 21.3928 - val_loss: 22.2751 - val_mae: 22.2751\n",
      "Epoch 192/200\n",
      "1711/1712 [============================>.] - ETA: 0s - loss: 21.3892 - mae: 21.3892\n",
      "Epoch 192: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.3891 - mae: 21.3891 - val_loss: 23.0748 - val_mae: 23.0748\n",
      "Epoch 193/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.3905 - mae: 21.3905\n",
      "Epoch 193: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.3904 - mae: 21.3904 - val_loss: 22.7803 - val_mae: 22.7803\n",
      "Epoch 194/200\n",
      "1712/1712 [==============================] - ETA: 0s - loss: 21.3900 - mae: 21.3900\n",
      "Epoch 194: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.3900 - mae: 21.3900 - val_loss: 22.9966 - val_mae: 22.9966\n",
      "Epoch 195/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.3848 - mae: 21.3848\n",
      "Epoch 195: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.3842 - mae: 21.3842 - val_loss: 22.8217 - val_mae: 22.8217\n",
      "Epoch 196/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.3826 - mae: 21.3826\n",
      "Epoch 196: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.3829 - mae: 21.3829 - val_loss: 22.5038 - val_mae: 22.5038\n",
      "Epoch 197/200\n",
      "1711/1712 [============================>.] - ETA: 0s - loss: 21.3841 - mae: 21.3841\n",
      "Epoch 197: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.3845 - mae: 21.3845 - val_loss: 22.7607 - val_mae: 22.7607\n",
      "Epoch 198/200\n",
      "1711/1712 [============================>.] - ETA: 0s - loss: 21.3843 - mae: 21.3843\n",
      "Epoch 198: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.3844 - mae: 21.3844 - val_loss: 23.0389 - val_mae: 23.0389\n",
      "Epoch 199/200\n",
      "1710/1712 [============================>.] - ETA: 0s - loss: 21.3822 - mae: 21.3822\n",
      "Epoch 199: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.3824 - mae: 21.3824 - val_loss: 22.5982 - val_mae: 22.5982\n",
      "Epoch 200/200\n",
      "1709/1712 [============================>.] - ETA: 0s - loss: 21.3821 - mae: 21.3821\n",
      "Epoch 200: val_mae did not improve from 22.19605\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 21.3819 - mae: 21.3819 - val_loss: 22.3869 - val_mae: 22.3869\n"
     ]
    }
   ],
   "source": [
    "random_seed = 15\n",
    "tf.keras.utils.set_random_seed(random_seed)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "file_path = './RNN10_best_model.h5'\n",
    "checkpoint = ModelCheckpoint(file_path,\n",
    "                            monitor = 'val_mae',\n",
    "                            verbose=1,\n",
    "                            save_best_only=True,\n",
    "                            mode='auto')  \n",
    "\n",
    "hist = model.fit(x_train, y_train, validation_data=(x_test, y_test), \n",
    "                 epochs=200, batch_size=16, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "46806a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 1s 3ms/step - loss: 22.1961 - mae: 22.1961\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[22.19605827331543, 22.19605827331543]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN10_model = tf.keras.models.load_model('./RNN10_best_model.h5')\n",
    "RNN10_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ab9dce09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264/264 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "RNN10_pred = RNN10_model.predict(submission_x)\n",
    "pd.DataFrame(RNN10_pred).to_csv('RNN10_pred.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbb2a39",
   "metadata": {},
   "source": [
    "## RNN11 / window size 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d99f2b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27343, 120, 1) (27343, 336) (7968, 120, 1) (7968, 336) (8425, 120, 1) (8425, 336)\n"
     ]
    }
   ],
   "source": [
    "pre_day = 27 # (31 - pre_month) * 24 = windowsize /27 : 96//28 : 72//29 : 48//30 : 24//\n",
    "x_train, y_train, x_test, y_test, submission_x, submission_y = DataProcessing.data_form_descision(train_df, test_df, pre_day)\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape, submission_x.shape, submission_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "872527f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_30 (SimpleRNN)   (None, 120, 32)           1088      \n",
      "                                                                 \n",
      " simple_rnn_31 (SimpleRNN)   (None, 120, 64)           6208      \n",
      "                                                                 \n",
      " simple_rnn_32 (SimpleRNN)   (None, 16)                1296      \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 64)                1088      \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 336)               11088     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,848\n",
      "Trainable params: 22,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "initializer = tf.keras.initializers.GlorotNormal(seed=11)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(32, activation='relu', input_shape=(x_train[0].shape), \n",
    "               return_sequences=True, kernel_initializer=initializer))\n",
    "model.add(SimpleRNN(64, activation='relu', return_sequences=True, kernel_initializer=initializer))\n",
    "model.add(SimpleRNN(16, activation='relu', kernel_initializer=initializer))\n",
    "model.add(Dense(64, activation='relu', kernel_initializer=initializer))\n",
    "model.add(Dense(32, activation='relu', kernel_initializer=initializer))\n",
    "model.add(Dense(336, activation='linear', kernel_initializer=initializer))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.00009)\n",
    "model.compile(loss='mae', optimizer=optimizer, metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "029fc657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 39.6454 - mae: 39.6454\n",
      "Epoch 1: val_mae improved from inf to 35.66589, saving model to .\\RNN11_best_model.h5\n",
      "1709/1709 [==============================] - 35s 20ms/step - loss: 39.6397 - mae: 39.6397 - val_loss: 35.6659 - val_mae: 35.6659\n",
      "Epoch 2/100\n",
      "1706/1709 [============================>.] - ETA: 0s - loss: 34.2708 - mae: 34.2708\n",
      "Epoch 2: val_mae improved from 35.66589 to 35.62386, saving model to .\\RNN11_best_model.h5\n",
      "1709/1709 [==============================] - 34s 20ms/step - loss: 34.2702 - mae: 34.2702 - val_loss: 35.6239 - val_mae: 35.6239\n",
      "Epoch 3/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 33.9799 - mae: 33.9799\n",
      "Epoch 3: val_mae improved from 35.62386 to 34.77349, saving model to .\\RNN11_best_model.h5\n",
      "1709/1709 [==============================] - 34s 20ms/step - loss: 33.9797 - mae: 33.9797 - val_loss: 34.7735 - val_mae: 34.7735\n",
      "Epoch 4/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 30.3865 - mae: 30.3865\n",
      "Epoch 4: val_mae improved from 34.77349 to 28.75238, saving model to .\\RNN11_best_model.h5\n",
      "1709/1709 [==============================] - 34s 20ms/step - loss: 30.3865 - mae: 30.3865 - val_loss: 28.7524 - val_mae: 28.7524\n",
      "Epoch 5/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 26.0903 - mae: 26.0903\n",
      "Epoch 5: val_mae improved from 28.75238 to 25.24716, saving model to .\\RNN11_best_model.h5\n",
      "1709/1709 [==============================] - 34s 20ms/step - loss: 26.0903 - mae: 26.0903 - val_loss: 25.2472 - val_mae: 25.2472\n",
      "Epoch 6/100\n",
      "1706/1709 [============================>.] - ETA: 0s - loss: 23.6821 - mae: 23.6821\n",
      "Epoch 6: val_mae improved from 25.24716 to 23.81949, saving model to .\\RNN11_best_model.h5\n",
      "1709/1709 [==============================] - 34s 20ms/step - loss: 23.6812 - mae: 23.6812 - val_loss: 23.8195 - val_mae: 23.8195\n",
      "Epoch 7/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 23.0746 - mae: 23.0746\n",
      "Epoch 7: val_mae improved from 23.81949 to 23.53091, saving model to .\\RNN11_best_model.h5\n",
      "1709/1709 [==============================] - 34s 20ms/step - loss: 23.0746 - mae: 23.0746 - val_loss: 23.5309 - val_mae: 23.5309\n",
      "Epoch 8/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 23.0181 - mae: 23.0181\n",
      "Epoch 8: val_mae did not improve from 23.53091\n",
      "1709/1709 [==============================] - 34s 20ms/step - loss: 23.0187 - mae: 23.0187 - val_loss: 23.6748 - val_mae: 23.6748\n",
      "Epoch 9/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 22.9710 - mae: 22.9710\n",
      "Epoch 9: val_mae improved from 23.53091 to 23.49364, saving model to .\\RNN11_best_model.h5\n",
      "1709/1709 [==============================] - 35s 20ms/step - loss: 22.9710 - mae: 22.9710 - val_loss: 23.4936 - val_mae: 23.4936\n",
      "Epoch 10/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 22.9580 - mae: 22.9580\n",
      "Epoch 10: val_mae did not improve from 23.49364\n",
      "1709/1709 [==============================] - 34s 20ms/step - loss: 22.9578 - mae: 22.9578 - val_loss: 23.5065 - val_mae: 23.5065\n",
      "Epoch 11/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 22.9276 - mae: 22.9276\n",
      "Epoch 11: val_mae did not improve from 23.49364\n",
      "1709/1709 [==============================] - 33s 20ms/step - loss: 22.9276 - mae: 22.9276 - val_loss: 23.8995 - val_mae: 23.8995\n",
      "Epoch 12/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 22.9086 - mae: 22.9086\n",
      "Epoch 12: val_mae did not improve from 23.49364\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 22.9084 - mae: 22.9084 - val_loss: 23.8759 - val_mae: 23.8759\n",
      "Epoch 13/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 22.8907 - mae: 22.8907\n",
      "Epoch 13: val_mae improved from 23.49364 to 23.45797, saving model to .\\RNN11_best_model.h5\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 22.8908 - mae: 22.8908 - val_loss: 23.4580 - val_mae: 23.4580\n",
      "Epoch 14/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 22.8634 - mae: 22.8634\n",
      "Epoch 14: val_mae did not improve from 23.45797\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 22.8633 - mae: 22.8633 - val_loss: 23.6414 - val_mae: 23.6414\n",
      "Epoch 15/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 22.8362 - mae: 22.8362\n",
      "Epoch 15: val_mae improved from 23.45797 to 23.39492, saving model to .\\RNN11_best_model.h5\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 22.8361 - mae: 22.8361 - val_loss: 23.3949 - val_mae: 23.3949\n",
      "Epoch 16/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 22.7998 - mae: 22.7998\n",
      "Epoch 16: val_mae improved from 23.39492 to 23.34222, saving model to .\\RNN11_best_model.h5\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 22.7998 - mae: 22.7998 - val_loss: 23.3422 - val_mae: 23.3422\n",
      "Epoch 17/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 22.7572 - mae: 22.7572\n",
      "Epoch 17: val_mae improved from 23.34222 to 23.28991, saving model to .\\RNN11_best_model.h5\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 22.7572 - mae: 22.7572 - val_loss: 23.2899 - val_mae: 23.2899\n",
      "Epoch 18/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 22.7196 - mae: 22.7196\n",
      "Epoch 18: val_mae improved from 23.28991 to 23.24488, saving model to .\\RNN11_best_model.h5\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 22.7200 - mae: 22.7200 - val_loss: 23.2449 - val_mae: 23.2449\n",
      "Epoch 19/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 22.6614 - mae: 22.6614\n",
      "Epoch 19: val_mae improved from 23.24488 to 23.20132, saving model to .\\RNN11_best_model.h5\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 22.6617 - mae: 22.6617 - val_loss: 23.2013 - val_mae: 23.2013\n",
      "Epoch 20/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 22.5989 - mae: 22.5989\n",
      "Epoch 20: val_mae improved from 23.20132 to 23.10677, saving model to .\\RNN11_best_model.h5\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 22.5989 - mae: 22.5989 - val_loss: 23.1068 - val_mae: 23.1068\n",
      "Epoch 21/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 22.5236 - mae: 22.5236\n",
      "Epoch 21: val_mae did not improve from 23.10677\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 22.5236 - mae: 22.5236 - val_loss: 23.2792 - val_mae: 23.2792\n",
      "Epoch 22/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 22.4413 - mae: 22.4413\n",
      "Epoch 22: val_mae improved from 23.10677 to 22.96604, saving model to .\\RNN11_best_model.h5\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 22.4417 - mae: 22.4417 - val_loss: 22.9660 - val_mae: 22.9660\n",
      "Epoch 23/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 22.3539 - mae: 22.3539\n",
      "Epoch 23: val_mae did not improve from 22.96604\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 22.3536 - mae: 22.3536 - val_loss: 23.0633 - val_mae: 23.0633\n",
      "Epoch 24/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 22.2680 - mae: 22.2680\n",
      "Epoch 24: val_mae improved from 22.96604 to 22.77688, saving model to .\\RNN11_best_model.h5\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 22.2683 - mae: 22.2683 - val_loss: 22.7769 - val_mae: 22.7769\n",
      "Epoch 25/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 22.1893 - mae: 22.1893\n",
      "Epoch 25: val_mae did not improve from 22.77688\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 22.1894 - mae: 22.1894 - val_loss: 22.9809 - val_mae: 22.9809\n",
      "Epoch 26/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 22.1167 - mae: 22.1167\n",
      "Epoch 26: val_mae improved from 22.77688 to 22.63437, saving model to .\\RNN11_best_model.h5\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 22.1169 - mae: 22.1169 - val_loss: 22.6344 - val_mae: 22.6344\n",
      "Epoch 27/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 22.0658 - mae: 22.0658\n",
      "Epoch 27: val_mae did not improve from 22.63437\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 22.0658 - mae: 22.0658 - val_loss: 22.7011 - val_mae: 22.7011\n",
      "Epoch 28/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 22.0272 - mae: 22.0272\n",
      "Epoch 28: val_mae did not improve from 22.63437\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 22.0272 - mae: 22.0272 - val_loss: 23.0988 - val_mae: 23.0988\n",
      "Epoch 29/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 22.0057 - mae: 22.0057\n",
      "Epoch 29: val_mae did not improve from 22.63437\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 22.0057 - mae: 22.0057 - val_loss: 22.6878 - val_mae: 22.6878\n",
      "Epoch 30/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.9794 - mae: 21.9794\n",
      "Epoch 30: val_mae did not improve from 22.63437\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.9792 - mae: 21.9792 - val_loss: 22.7448 - val_mae: 22.7448\n",
      "Epoch 31/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.9489 - mae: 21.9489\n",
      "Epoch 31: val_mae improved from 22.63437 to 22.46365, saving model to .\\RNN11_best_model.h5\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.9489 - mae: 21.9489 - val_loss: 22.4637 - val_mae: 22.4637\n",
      "Epoch 32/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.9337 - mae: 21.9337\n",
      "Epoch 32: val_mae improved from 22.46365 to 22.44674, saving model to .\\RNN11_best_model.h5\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.9341 - mae: 21.9341 - val_loss: 22.4467 - val_mae: 22.4467\n",
      "Epoch 33/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.9272 - mae: 21.9272\n",
      "Epoch 33: val_mae did not improve from 22.44674\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.9271 - mae: 21.9271 - val_loss: 22.6602 - val_mae: 22.6602\n",
      "Epoch 34/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.9104 - mae: 21.9104\n",
      "Epoch 34: val_mae did not improve from 22.44674\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.9106 - mae: 21.9106 - val_loss: 22.9270 - val_mae: 22.9270\n",
      "Epoch 35/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.8981 - mae: 21.8981\n",
      "Epoch 35: val_mae improved from 22.44674 to 22.39497, saving model to .\\RNN11_best_model.h5\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.8982 - mae: 21.8982 - val_loss: 22.3950 - val_mae: 22.3950\n",
      "Epoch 36/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.8883 - mae: 21.8883\n",
      "Epoch 36: val_mae did not improve from 22.39497\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.8883 - mae: 21.8883 - val_loss: 22.4769 - val_mae: 22.4769\n",
      "Epoch 37/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.8716 - mae: 21.8716\n",
      "Epoch 37: val_mae did not improve from 22.39497\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.8716 - mae: 21.8716 - val_loss: 22.4028 - val_mae: 22.4028\n",
      "Epoch 38/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.8599 - mae: 21.8599\n",
      "Epoch 38: val_mae did not improve from 22.39497\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.8598 - mae: 21.8598 - val_loss: 22.5163 - val_mae: 22.5163\n",
      "Epoch 39/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.8516 - mae: 21.8516\n",
      "Epoch 39: val_mae improved from 22.39497 to 22.39421, saving model to .\\RNN11_best_model.h5\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.8514 - mae: 21.8514 - val_loss: 22.3942 - val_mae: 22.3942\n",
      "Epoch 40/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.8408 - mae: 21.8408\n",
      "Epoch 40: val_mae improved from 22.39421 to 22.31830, saving model to .\\RNN11_best_model.h5\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.8408 - mae: 21.8408 - val_loss: 22.3183 - val_mae: 22.3183\n",
      "Epoch 41/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.8233 - mae: 21.8233\n",
      "Epoch 41: val_mae did not improve from 22.31830\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.8233 - mae: 21.8233 - val_loss: 22.4339 - val_mae: 22.4339\n",
      "Epoch 42/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.8166 - mae: 21.8166\n",
      "Epoch 42: val_mae did not improve from 22.31830\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.8165 - mae: 21.8165 - val_loss: 22.3203 - val_mae: 22.3203\n",
      "Epoch 43/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.8021 - mae: 21.8021\n",
      "Epoch 43: val_mae did not improve from 22.31830\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.8021 - mae: 21.8021 - val_loss: 22.4096 - val_mae: 22.4096\n",
      "Epoch 44/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.7913 - mae: 21.7913\n",
      "Epoch 44: val_mae did not improve from 22.31830\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.7912 - mae: 21.7912 - val_loss: 22.6116 - val_mae: 22.6116\n",
      "Epoch 45/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.7753 - mae: 21.7753\n",
      "Epoch 45: val_mae did not improve from 22.31830\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.7753 - mae: 21.7753 - val_loss: 22.3414 - val_mae: 22.3414\n",
      "Epoch 46/100\n",
      "1706/1709 [============================>.] - ETA: 0s - loss: 21.7643 - mae: 21.7643\n",
      "Epoch 46: val_mae did not improve from 22.31830\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.7643 - mae: 21.7643 - val_loss: 23.0857 - val_mae: 23.0857\n",
      "Epoch 47/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.7565 - mae: 21.7565\n",
      "Epoch 47: val_mae improved from 22.31830 to 22.25453, saving model to .\\RNN11_best_model.h5\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.7566 - mae: 21.7566 - val_loss: 22.2545 - val_mae: 22.2545\n",
      "Epoch 48/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.7393 - mae: 21.7393\n",
      "Epoch 48: val_mae did not improve from 22.25453\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.7400 - mae: 21.7400 - val_loss: 22.3815 - val_mae: 22.3815\n",
      "Epoch 49/100\n",
      "1706/1709 [============================>.] - ETA: 0s - loss: 21.7299 - mae: 21.7299\n",
      "Epoch 49: val_mae improved from 22.25453 to 22.23822, saving model to .\\RNN11_best_model.h5\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.7298 - mae: 21.7298 - val_loss: 22.2382 - val_mae: 22.2382\n",
      "Epoch 50/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.7198 - mae: 21.7198\n",
      "Epoch 50: val_mae did not improve from 22.23822\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.7194 - mae: 21.7194 - val_loss: 22.2508 - val_mae: 22.2508\n",
      "Epoch 51/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.7021 - mae: 21.7021\n",
      "Epoch 51: val_mae did not improve from 22.23822\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.7021 - mae: 21.7021 - val_loss: 22.6128 - val_mae: 22.6128\n",
      "Epoch 52/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.6933 - mae: 21.6933\n",
      "Epoch 52: val_mae did not improve from 22.23822\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.6933 - mae: 21.6933 - val_loss: 22.2811 - val_mae: 22.2811\n",
      "Epoch 53/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.6783 - mae: 21.6783\n",
      "Epoch 53: val_mae improved from 22.23822 to 22.19933, saving model to .\\RNN11_best_model.h5\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.6783 - mae: 21.6783 - val_loss: 22.1993 - val_mae: 22.1993\n",
      "Epoch 54/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.6735 - mae: 21.6735\n",
      "Epoch 54: val_mae did not improve from 22.19933\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.6734 - mae: 21.6734 - val_loss: 22.3347 - val_mae: 22.3347\n",
      "Epoch 55/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.6491 - mae: 21.6491\n",
      "Epoch 55: val_mae did not improve from 22.19933\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.6491 - mae: 21.6491 - val_loss: 22.2620 - val_mae: 22.2620\n",
      "Epoch 56/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.6424 - mae: 21.6424\n",
      "Epoch 56: val_mae did not improve from 22.19933\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.6423 - mae: 21.6423 - val_loss: 22.3232 - val_mae: 22.3232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.6284 - mae: 21.6284\n",
      "Epoch 57: val_mae did not improve from 22.19933\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.6284 - mae: 21.6284 - val_loss: 22.4056 - val_mae: 22.4056\n",
      "Epoch 58/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.6210 - mae: 21.6210\n",
      "Epoch 58: val_mae did not improve from 22.19933\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.6210 - mae: 21.6210 - val_loss: 22.5197 - val_mae: 22.5197\n",
      "Epoch 59/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.6180 - mae: 21.6180\n",
      "Epoch 59: val_mae improved from 22.19933 to 22.16570, saving model to .\\RNN11_best_model.h5\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.6180 - mae: 21.6180 - val_loss: 22.1657 - val_mae: 22.1657\n",
      "Epoch 60/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.5993 - mae: 21.5993\n",
      "Epoch 60: val_mae improved from 22.16570 to 22.13850, saving model to .\\RNN11_best_model.h5\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.5990 - mae: 21.5990 - val_loss: 22.1385 - val_mae: 22.1385\n",
      "Epoch 61/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.5980 - mae: 21.5980\n",
      "Epoch 61: val_mae did not improve from 22.13850\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.5982 - mae: 21.5982 - val_loss: 22.5712 - val_mae: 22.5712\n",
      "Epoch 62/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.5823 - mae: 21.5823\n",
      "Epoch 62: val_mae did not improve from 22.13850\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.5820 - mae: 21.5820 - val_loss: 22.2112 - val_mae: 22.2112\n",
      "Epoch 63/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.5788 - mae: 21.5788\n",
      "Epoch 63: val_mae did not improve from 22.13850\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.5787 - mae: 21.5787 - val_loss: 22.6884 - val_mae: 22.6884\n",
      "Epoch 64/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.5697 - mae: 21.5697\n",
      "Epoch 64: val_mae improved from 22.13850 to 22.13302, saving model to .\\RNN11_best_model.h5\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.5695 - mae: 21.5695 - val_loss: 22.1330 - val_mae: 22.1330\n",
      "Epoch 65/100\n",
      "1706/1709 [============================>.] - ETA: 0s - loss: 21.5673 - mae: 21.5673\n",
      "Epoch 65: val_mae did not improve from 22.13302\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.5674 - mae: 21.5674 - val_loss: 22.1981 - val_mae: 22.1981\n",
      "Epoch 66/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.5588 - mae: 21.5588\n",
      "Epoch 66: val_mae did not improve from 22.13302\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.5589 - mae: 21.5589 - val_loss: 22.1633 - val_mae: 22.1633\n",
      "Epoch 67/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.5540 - mae: 21.5540\n",
      "Epoch 67: val_mae improved from 22.13302 to 22.08874, saving model to .\\RNN11_best_model.h5\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.5538 - mae: 21.5538 - val_loss: 22.0887 - val_mae: 22.0887\n",
      "Epoch 68/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.5525 - mae: 21.5525\n",
      "Epoch 68: val_mae did not improve from 22.08874\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.5524 - mae: 21.5524 - val_loss: 22.7186 - val_mae: 22.7186\n",
      "Epoch 69/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.5398 - mae: 21.5398\n",
      "Epoch 69: val_mae improved from 22.08874 to 22.08851, saving model to .\\RNN11_best_model.h5\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.5399 - mae: 21.5399 - val_loss: 22.0885 - val_mae: 22.0885\n",
      "Epoch 70/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.5319 - mae: 21.5319\n",
      "Epoch 70: val_mae did not improve from 22.08851\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.5317 - mae: 21.5317 - val_loss: 22.2988 - val_mae: 22.2988\n",
      "Epoch 71/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.5186 - mae: 21.5186\n",
      "Epoch 71: val_mae did not improve from 22.08851\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.5187 - mae: 21.5187 - val_loss: 22.1440 - val_mae: 22.1440\n",
      "Epoch 72/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.5219 - mae: 21.5219\n",
      "Epoch 72: val_mae improved from 22.08851 to 22.07275, saving model to .\\RNN11_best_model.h5\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.5219 - mae: 21.5219 - val_loss: 22.0728 - val_mae: 22.0728\n",
      "Epoch 73/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.5162 - mae: 21.5162\n",
      "Epoch 73: val_mae did not improve from 22.07275\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.5160 - mae: 21.5160 - val_loss: 22.1322 - val_mae: 22.1322\n",
      "Epoch 74/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.5174 - mae: 21.5174\n",
      "Epoch 74: val_mae did not improve from 22.07275\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.5174 - mae: 21.5174 - val_loss: 22.0984 - val_mae: 22.0984\n",
      "Epoch 75/100\n",
      "1706/1709 [============================>.] - ETA: 0s - loss: 21.5024 - mae: 21.5024\n",
      "Epoch 75: val_mae did not improve from 22.07275\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.5026 - mae: 21.5026 - val_loss: 22.5100 - val_mae: 22.5100\n",
      "Epoch 76/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.5046 - mae: 21.5046\n",
      "Epoch 76: val_mae did not improve from 22.07275\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.5045 - mae: 21.5045 - val_loss: 22.4562 - val_mae: 22.4562\n",
      "Epoch 77/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.4970 - mae: 21.4970\n",
      "Epoch 77: val_mae did not improve from 22.07275\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.4970 - mae: 21.4970 - val_loss: 23.0029 - val_mae: 23.0029\n",
      "Epoch 78/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.4995 - mae: 21.4995\n",
      "Epoch 78: val_mae did not improve from 22.07275\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.5002 - mae: 21.5002 - val_loss: 22.6536 - val_mae: 22.6536\n",
      "Epoch 79/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.4940 - mae: 21.4940\n",
      "Epoch 79: val_mae improved from 22.07275 to 22.06633, saving model to .\\RNN11_best_model.h5\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.4940 - mae: 21.4940 - val_loss: 22.0663 - val_mae: 22.0663\n",
      "Epoch 80/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4772 - mae: 21.4772\n",
      "Epoch 80: val_mae did not improve from 22.06633\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.4773 - mae: 21.4773 - val_loss: 22.1401 - val_mae: 22.1401\n",
      "Epoch 81/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.4872 - mae: 21.4872\n",
      "Epoch 81: val_mae did not improve from 22.06633\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.4872 - mae: 21.4872 - val_loss: 22.2133 - val_mae: 22.2133\n",
      "Epoch 82/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4758 - mae: 21.4758\n",
      "Epoch 82: val_mae did not improve from 22.06633\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.4760 - mae: 21.4760 - val_loss: 22.3555 - val_mae: 22.3555\n",
      "Epoch 83/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.4838 - mae: 21.4838\n",
      "Epoch 83: val_mae did not improve from 22.06633\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.4838 - mae: 21.4838 - val_loss: 22.0955 - val_mae: 22.0955\n",
      "Epoch 84/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.4616 - mae: 21.4616\n",
      "Epoch 84: val_mae did not improve from 22.06633\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.4616 - mae: 21.4616 - val_loss: 22.1474 - val_mae: 22.1474\n",
      "Epoch 85/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.4667 - mae: 21.4667\n",
      "Epoch 85: val_mae did not improve from 22.06633\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.4667 - mae: 21.4667 - val_loss: 22.3856 - val_mae: 22.3856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4678 - mae: 21.4678\n",
      "Epoch 86: val_mae did not improve from 22.06633\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.4677 - mae: 21.4677 - val_loss: 22.3753 - val_mae: 22.3753\n",
      "Epoch 87/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4656 - mae: 21.4656\n",
      "Epoch 87: val_mae improved from 22.06633 to 22.06200, saving model to .\\RNN11_best_model.h5\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.4655 - mae: 21.4655 - val_loss: 22.0620 - val_mae: 22.0620\n",
      "Epoch 88/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4662 - mae: 21.4662\n",
      "Epoch 88: val_mae did not improve from 22.06200\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.4662 - mae: 21.4662 - val_loss: 22.1719 - val_mae: 22.1719\n",
      "Epoch 89/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.4508 - mae: 21.4508\n",
      "Epoch 89: val_mae did not improve from 22.06200\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.4503 - mae: 21.4503 - val_loss: 22.2581 - val_mae: 22.2581\n",
      "Epoch 90/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4511 - mae: 21.4511\n",
      "Epoch 90: val_mae did not improve from 22.06200\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.4511 - mae: 21.4511 - val_loss: 22.0790 - val_mae: 22.0790\n",
      "Epoch 91/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.4456 - mae: 21.4456\n",
      "Epoch 91: val_mae did not improve from 22.06200\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.4456 - mae: 21.4456 - val_loss: 22.7857 - val_mae: 22.7857\n",
      "Epoch 92/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4392 - mae: 21.4392\n",
      "Epoch 92: val_mae did not improve from 22.06200\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.4391 - mae: 21.4391 - val_loss: 22.1791 - val_mae: 22.1791\n",
      "Epoch 93/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.4418 - mae: 21.4418\n",
      "Epoch 93: val_mae did not improve from 22.06200\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.4417 - mae: 21.4417 - val_loss: 22.1864 - val_mae: 22.1864\n",
      "Epoch 94/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.4377 - mae: 21.4377\n",
      "Epoch 94: val_mae did not improve from 22.06200\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.4377 - mae: 21.4377 - val_loss: 22.0655 - val_mae: 22.0655\n",
      "Epoch 95/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.4392 - mae: 21.4392\n",
      "Epoch 95: val_mae did not improve from 22.06200\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.4392 - mae: 21.4392 - val_loss: 22.9191 - val_mae: 22.9191\n",
      "Epoch 96/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4394 - mae: 21.4394\n",
      "Epoch 96: val_mae did not improve from 22.06200\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.4398 - mae: 21.4398 - val_loss: 22.1679 - val_mae: 22.1679\n",
      "Epoch 97/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.4190 - mae: 21.4190\n",
      "Epoch 97: val_mae did not improve from 22.06200\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.4189 - mae: 21.4189 - val_loss: 22.0990 - val_mae: 22.0990\n",
      "Epoch 98/100\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4236 - mae: 21.4236\n",
      "Epoch 98: val_mae did not improve from 22.06200\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.4236 - mae: 21.4236 - val_loss: 22.4204 - val_mae: 22.4204\n",
      "Epoch 99/100\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.4192 - mae: 21.4192\n",
      "Epoch 99: val_mae did not improve from 22.06200\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.4192 - mae: 21.4192 - val_loss: 22.2836 - val_mae: 22.2836\n",
      "Epoch 100/100\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.4226 - mae: 21.4226\n",
      "Epoch 100: val_mae did not improve from 22.06200\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 21.4230 - mae: 21.4230 - val_loss: 22.3403 - val_mae: 22.3403\n"
     ]
    }
   ],
   "source": [
    "seed = 11\n",
    "tf.keras.utils.set_random_seed(seed)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "checkpoint = ModelCheckpoint('./RNN11_best_model.h5',\n",
    "                        monitor = 'val_mae',\n",
    "                        verbose=1,\n",
    "                        save_best_only=True,\n",
    "                        mode='auto')  \n",
    "\n",
    "hist = model.fit(x_train, y_train, validation_data=(x_test, y_test), \n",
    "                 epochs=100, batch_size=16, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7885df35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249/249 [==============================] - 2s 6ms/step - loss: 22.0620 - mae: 22.0620\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[22.062002182006836, 22.062002182006836]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN11_model = tf.keras.models.load_model('./RNN11_best_model.h5')\n",
    "RNN11_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d6c78200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264/264 [==============================] - 2s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "RNN11_pred = RNN11_model.predict(submission_x)\n",
    "pd.DataFrame(RNN11_pred).to_csv('RNN11_pred.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76ac7f6",
   "metadata": {},
   "source": [
    "## RNN12 / window size 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4affee8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27343, 120, 1) (27343, 336) (7968, 120, 1) (7968, 336) (8425, 120, 1) (8425, 336)\n"
     ]
    }
   ],
   "source": [
    "pre_day = 27 # (31 - pre_month) * 24 = windowsize /27 : 96//28 : 72//29 : 48//30 : 24//\n",
    "x_train, y_train, x_test, y_test, submission_x, submission_y = DataProcessing.data_form_descision(train_df, test_df, pre_day)\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape, submission_x.shape, submission_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "70d0216c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_33 (SimpleRNN)   (None, 120, 32)           1088      \n",
      "                                                                 \n",
      " simple_rnn_34 (SimpleRNN)   (None, 120, 32)           2080      \n",
      "                                                                 \n",
      " simple_rnn_35 (SimpleRNN)   (None, 16)                784       \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 64)                1088      \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 336)               11088     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,208\n",
      "Trainable params: 18,208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "initializer = tf.keras.initializers.GlorotNormal(seed=60)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(32, activation='relu', input_shape=(x_train[0].shape), \n",
    "               return_sequences=True, kernel_initializer=initializer))\n",
    "model.add(SimpleRNN(32, activation='relu', return_sequences=True, kernel_initializer=initializer))\n",
    "model.add(SimpleRNN(16, activation='relu', kernel_initializer=initializer))\n",
    "model.add(Dense(64, activation='relu', kernel_initializer=initializer))\n",
    "model.add(Dense(32, activation='relu', kernel_initializer=initializer))\n",
    "model.add(Dense(336, activation='linear', kernel_initializer=initializer))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.00005)\n",
    "model.compile(loss='mae', optimizer=optimizer, metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "55e16010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 45.7575 - mae: 45.7575\n",
      "Epoch 1: val_mae improved from inf to 35.73738, saving model to .\\RNN12_best_model.h5\n",
      "1709/1709 [==============================] - 35s 19ms/step - loss: 45.7575 - mae: 45.7575 - val_loss: 35.7374 - val_mae: 35.7374\n",
      "Epoch 2/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 34.2891 - mae: 34.2891\n",
      "Epoch 2: val_mae improved from 35.73738 to 35.67515, saving model to .\\RNN12_best_model.h5\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 34.2891 - mae: 34.2891 - val_loss: 35.6751 - val_mae: 35.6751\n",
      "Epoch 3/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 34.2314 - mae: 34.2314\n",
      "Epoch 3: val_mae did not improve from 35.67515\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 34.2314 - mae: 34.2314 - val_loss: 35.7462 - val_mae: 35.7462\n",
      "Epoch 4/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 34.1825 - mae: 34.1825\n",
      "Epoch 4: val_mae improved from 35.67515 to 35.57500, saving model to .\\RNN12_best_model.h5\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 34.1825 - mae: 34.1825 - val_loss: 35.5750 - val_mae: 35.5750\n",
      "Epoch 5/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 34.0324 - mae: 34.0324\n",
      "Epoch 5: val_mae improved from 35.57500 to 35.27984, saving model to .\\RNN12_best_model.h5\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 34.0324 - mae: 34.0324 - val_loss: 35.2798 - val_mae: 35.2798\n",
      "Epoch 6/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 33.1707 - mae: 33.1707\n",
      "Epoch 6: val_mae improved from 35.27984 to 33.61366, saving model to .\\RNN12_best_model.h5\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 33.1691 - mae: 33.1691 - val_loss: 33.6137 - val_mae: 33.6137\n",
      "Epoch 7/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 31.5820 - mae: 31.5820\n",
      "Epoch 7: val_mae improved from 33.61366 to 32.14668, saving model to .\\RNN12_best_model.h5\n",
      "1709/1709 [==============================] - 33s 19ms/step - loss: 31.5826 - mae: 31.5826 - val_loss: 32.1467 - val_mae: 32.1467\n",
      "Epoch 8/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 29.5789 - mae: 29.5789\n",
      "Epoch 8: val_mae improved from 32.14668 to 29.38397, saving model to .\\RNN12_best_model.h5\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 29.5786 - mae: 29.5786 - val_loss: 29.3840 - val_mae: 29.3840\n",
      "Epoch 9/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 27.5825 - mae: 27.5825\n",
      "Epoch 9: val_mae improved from 29.38397 to 27.64761, saving model to .\\RNN12_best_model.h5\n",
      "1709/1709 [==============================] - 34s 20ms/step - loss: 27.5819 - mae: 27.5819 - val_loss: 27.6476 - val_mae: 27.6476\n",
      "Epoch 10/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 25.7430 - mae: 25.7430\n",
      "Epoch 10: val_mae improved from 27.64761 to 25.72789, saving model to .\\RNN12_best_model.h5\n",
      "1709/1709 [==============================] - 34s 20ms/step - loss: 25.7430 - mae: 25.7430 - val_loss: 25.7279 - val_mae: 25.7279\n",
      "Epoch 11/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 24.2345 - mae: 24.2345\n",
      "Epoch 11: val_mae improved from 25.72789 to 24.66669, saving model to .\\RNN12_best_model.h5\n",
      "1709/1709 [==============================] - 34s 20ms/step - loss: 24.2338 - mae: 24.2338 - val_loss: 24.6667 - val_mae: 24.6667\n",
      "Epoch 12/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 23.4670 - mae: 23.4670\n",
      "Epoch 12: val_mae improved from 24.66669 to 23.96367, saving model to .\\RNN12_best_model.h5\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 23.4670 - mae: 23.4670 - val_loss: 23.9637 - val_mae: 23.9637\n",
      "Epoch 13/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 23.1754 - mae: 23.1754\n",
      "Epoch 13: val_mae improved from 23.96367 to 23.82541, saving model to .\\RNN12_best_model.h5\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 23.1751 - mae: 23.1751 - val_loss: 23.8254 - val_mae: 23.8254\n",
      "Epoch 14/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 23.0395 - mae: 23.0395\n",
      "Epoch 14: val_mae did not improve from 23.82541\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 23.0398 - mae: 23.0398 - val_loss: 23.8683 - val_mae: 23.8683\n",
      "Epoch 15/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 22.9626 - mae: 22.9626\n",
      "Epoch 15: val_mae did not improve from 23.82541\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 22.9620 - mae: 22.9620 - val_loss: 23.9365 - val_mae: 23.9365\n",
      "Epoch 16/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 22.9069 - mae: 22.9069\n",
      "Epoch 16: val_mae improved from 23.82541 to 23.61740, saving model to .\\RNN12_best_model.h5\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 22.9069 - mae: 22.9069 - val_loss: 23.6174 - val_mae: 23.6174\n",
      "Epoch 17/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 22.8611 - mae: 22.8611\n",
      "Epoch 17: val_mae did not improve from 23.61740\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 22.8611 - mae: 22.8611 - val_loss: 23.6560 - val_mae: 23.6560\n",
      "Epoch 18/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 22.8014 - mae: 22.8014\n",
      "Epoch 18: val_mae did not improve from 23.61740\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 22.8008 - mae: 22.8008 - val_loss: 23.7513 - val_mae: 23.7513\n",
      "Epoch 19/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 22.7622 - mae: 22.7622\n",
      "Epoch 19: val_mae improved from 23.61740 to 23.59826, saving model to .\\RNN12_best_model.h5\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 22.7624 - mae: 22.7624 - val_loss: 23.5983 - val_mae: 23.5983\n",
      "Epoch 20/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 22.7172 - mae: 22.7172\n",
      "Epoch 20: val_mae improved from 23.59826 to 23.47022, saving model to .\\RNN12_best_model.h5\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 22.7171 - mae: 22.7171 - val_loss: 23.4702 - val_mae: 23.4702\n",
      "Epoch 21/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 22.6648 - mae: 22.6648\n",
      "Epoch 21: val_mae improved from 23.47022 to 23.29584, saving model to .\\RNN12_best_model.h5\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 22.6649 - mae: 22.6649 - val_loss: 23.2958 - val_mae: 23.2958\n",
      "Epoch 22/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 22.6217 - mae: 22.6217\n",
      "Epoch 22: val_mae improved from 23.29584 to 23.24230, saving model to .\\RNN12_best_model.h5\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 22.6217 - mae: 22.6217 - val_loss: 23.2423 - val_mae: 23.2423\n",
      "Epoch 23/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 22.5705 - mae: 22.5705\n",
      "Epoch 23: val_mae did not improve from 23.24230\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 22.5705 - mae: 22.5705 - val_loss: 23.3572 - val_mae: 23.3572\n",
      "Epoch 24/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 22.5286 - mae: 22.5286\n",
      "Epoch 24: val_mae improved from 23.24230 to 23.21444, saving model to .\\RNN12_best_model.h5\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 22.5288 - mae: 22.5288 - val_loss: 23.2144 - val_mae: 23.2144\n",
      "Epoch 25/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 22.4777 - mae: 22.4777\n",
      "Epoch 25: val_mae did not improve from 23.21444\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 22.4777 - mae: 22.4777 - val_loss: 23.4998 - val_mae: 23.4998\n",
      "Epoch 26/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 22.4343 - mae: 22.4343\n",
      "Epoch 26: val_mae did not improve from 23.21444\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 22.4345 - mae: 22.4345 - val_loss: 23.2615 - val_mae: 23.2615\n",
      "Epoch 27/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 22.3931 - mae: 22.3931\n",
      "Epoch 27: val_mae improved from 23.21444 to 23.02106, saving model to .\\RNN12_best_model.h5\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 22.3931 - mae: 22.3931 - val_loss: 23.0211 - val_mae: 23.0211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 22.3504 - mae: 22.3504\n",
      "Epoch 28: val_mae improved from 23.02106 to 22.96385, saving model to .\\RNN12_best_model.h5\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 22.3504 - mae: 22.3504 - val_loss: 22.9638 - val_mae: 22.9638\n",
      "Epoch 29/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 22.3145 - mae: 22.3145\n",
      "Epoch 29: val_mae did not improve from 22.96385\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 22.3142 - mae: 22.3142 - val_loss: 23.0409 - val_mae: 23.0409\n",
      "Epoch 30/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 22.2697 - mae: 22.2697\n",
      "Epoch 30: val_mae did not improve from 22.96385\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 22.2697 - mae: 22.2697 - val_loss: 23.0251 - val_mae: 23.0251\n",
      "Epoch 31/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 22.2347 - mae: 22.2347\n",
      "Epoch 31: val_mae did not improve from 22.96385\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 22.2347 - mae: 22.2347 - val_loss: 23.1227 - val_mae: 23.1227\n",
      "Epoch 32/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 22.2015 - mae: 22.2015\n",
      "Epoch 32: val_mae improved from 22.96385 to 22.81278, saving model to .\\RNN12_best_model.h5\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 22.2015 - mae: 22.2015 - val_loss: 22.8128 - val_mae: 22.8128\n",
      "Epoch 33/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 22.1704 - mae: 22.1704\n",
      "Epoch 33: val_mae did not improve from 22.81278\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 22.1706 - mae: 22.1706 - val_loss: 22.9522 - val_mae: 22.9522\n",
      "Epoch 34/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 22.1393 - mae: 22.1393\n",
      "Epoch 34: val_mae did not improve from 22.81278\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 22.1393 - mae: 22.1393 - val_loss: 22.8130 - val_mae: 22.8130\n",
      "Epoch 35/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 22.1098 - mae: 22.1098\n",
      "Epoch 35: val_mae did not improve from 22.81278\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 22.1098 - mae: 22.1098 - val_loss: 22.8358 - val_mae: 22.8358\n",
      "Epoch 36/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 22.0895 - mae: 22.0895\n",
      "Epoch 36: val_mae improved from 22.81278 to 22.70242, saving model to .\\RNN12_best_model.h5\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 22.0896 - mae: 22.0896 - val_loss: 22.7024 - val_mae: 22.7024\n",
      "Epoch 37/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 22.0656 - mae: 22.0656\n",
      "Epoch 37: val_mae did not improve from 22.70242\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 22.0660 - mae: 22.0660 - val_loss: 22.9657 - val_mae: 22.9657\n",
      "Epoch 38/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 22.0433 - mae: 22.0433\n",
      "Epoch 38: val_mae did not improve from 22.70242\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 22.0431 - mae: 22.0431 - val_loss: 22.7750 - val_mae: 22.7750\n",
      "Epoch 39/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 22.0287 - mae: 22.0287\n",
      "Epoch 39: val_mae did not improve from 22.70242\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 22.0289 - mae: 22.0289 - val_loss: 22.7975 - val_mae: 22.7975\n",
      "Epoch 40/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 22.0150 - mae: 22.0150\n",
      "Epoch 40: val_mae did not improve from 22.70242\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 22.0150 - mae: 22.0150 - val_loss: 22.7922 - val_mae: 22.7922\n",
      "Epoch 41/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 22.0041 - mae: 22.0041\n",
      "Epoch 41: val_mae did not improve from 22.70242\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 22.0041 - mae: 22.0041 - val_loss: 22.7949 - val_mae: 22.7949\n",
      "Epoch 42/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.9915 - mae: 21.9915\n",
      "Epoch 42: val_mae improved from 22.70242 to 22.67760, saving model to .\\RNN12_best_model.h5\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.9914 - mae: 21.9914 - val_loss: 22.6776 - val_mae: 22.6776\n",
      "Epoch 43/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.9823 - mae: 21.9823\n",
      "Epoch 43: val_mae did not improve from 22.67760\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.9822 - mae: 21.9822 - val_loss: 22.9516 - val_mae: 22.9516\n",
      "Epoch 44/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.9775 - mae: 21.9775\n",
      "Epoch 44: val_mae did not improve from 22.67760\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.9775 - mae: 21.9775 - val_loss: 22.7302 - val_mae: 22.7302\n",
      "Epoch 45/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.9595 - mae: 21.9595\n",
      "Epoch 45: val_mae did not improve from 22.67760\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.9591 - mae: 21.9591 - val_loss: 23.0084 - val_mae: 23.0084\n",
      "Epoch 46/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.9466 - mae: 21.9466\n",
      "Epoch 46: val_mae did not improve from 22.67760\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.9467 - mae: 21.9467 - val_loss: 23.1082 - val_mae: 23.1082\n",
      "Epoch 47/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.9391 - mae: 21.9391\n",
      "Epoch 47: val_mae did not improve from 22.67760\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.9390 - mae: 21.9390 - val_loss: 22.9351 - val_mae: 22.9351\n",
      "Epoch 48/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.9356 - mae: 21.9356\n",
      "Epoch 48: val_mae did not improve from 22.67760\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.9351 - mae: 21.9351 - val_loss: 22.8777 - val_mae: 22.8777\n",
      "Epoch 49/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.9211 - mae: 21.9211\n",
      "Epoch 49: val_mae did not improve from 22.67760\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.9211 - mae: 21.9211 - val_loss: 22.7388 - val_mae: 22.7388\n",
      "Epoch 50/250\n",
      "1706/1709 [============================>.] - ETA: 0s - loss: 21.9144 - mae: 21.9144\n",
      "Epoch 50: val_mae did not improve from 22.67760\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.9144 - mae: 21.9144 - val_loss: 22.9031 - val_mae: 22.9031\n",
      "Epoch 51/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.9074 - mae: 21.9074\n",
      "Epoch 51: val_mae did not improve from 22.67760\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.9074 - mae: 21.9074 - val_loss: 22.9968 - val_mae: 22.9968\n",
      "Epoch 52/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.9046 - mae: 21.9046\n",
      "Epoch 52: val_mae did not improve from 22.67760\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.9045 - mae: 21.9045 - val_loss: 22.7701 - val_mae: 22.7701\n",
      "Epoch 53/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.8921 - mae: 21.8921\n",
      "Epoch 53: val_mae improved from 22.67760 to 22.63676, saving model to .\\RNN12_best_model.h5\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.8923 - mae: 21.8923 - val_loss: 22.6368 - val_mae: 22.6368\n",
      "Epoch 54/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.8853 - mae: 21.8853\n",
      "Epoch 54: val_mae did not improve from 22.63676\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.8853 - mae: 21.8853 - val_loss: 22.7522 - val_mae: 22.7522\n",
      "Epoch 55/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.8783 - mae: 21.8783\n",
      "Epoch 55: val_mae did not improve from 22.63676\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.8779 - mae: 21.8779 - val_loss: 22.7682 - val_mae: 22.7682\n",
      "Epoch 56/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.8746 - mae: 21.8746\n",
      "Epoch 56: val_mae did not improve from 22.63676\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.8747 - mae: 21.8747 - val_loss: 22.7481 - val_mae: 22.7481\n",
      "Epoch 57/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.8710 - mae: 21.8710\n",
      "Epoch 57: val_mae did not improve from 22.63676\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.8710 - mae: 21.8710 - val_loss: 22.7939 - val_mae: 22.7939\n",
      "Epoch 58/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.8593 - mae: 21.8593\n",
      "Epoch 58: val_mae improved from 22.63676 to 22.63637, saving model to .\\RNN12_best_model.h5\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.8593 - mae: 21.8593 - val_loss: 22.6364 - val_mae: 22.6364\n",
      "Epoch 59/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.8560 - mae: 21.8560\n",
      "Epoch 59: val_mae improved from 22.63637 to 22.54129, saving model to .\\RNN12_best_model.h5\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.8561 - mae: 21.8561 - val_loss: 22.5413 - val_mae: 22.5413\n",
      "Epoch 60/250\n",
      "1706/1709 [============================>.] - ETA: 0s - loss: 21.8501 - mae: 21.8501\n",
      "Epoch 60: val_mae did not improve from 22.54129\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.8504 - mae: 21.8504 - val_loss: 22.5451 - val_mae: 22.5451\n",
      "Epoch 61/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.8442 - mae: 21.8442\n",
      "Epoch 61: val_mae did not improve from 22.54129\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.8442 - mae: 21.8442 - val_loss: 22.6807 - val_mae: 22.6807\n",
      "Epoch 62/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.8309 - mae: 21.8309\n",
      "Epoch 62: val_mae improved from 22.54129 to 22.46744, saving model to .\\RNN12_best_model.h5\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.8308 - mae: 21.8308 - val_loss: 22.4674 - val_mae: 22.4674\n",
      "Epoch 63/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.8264 - mae: 21.8264\n",
      "Epoch 63: val_mae did not improve from 22.46744\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.8264 - mae: 21.8264 - val_loss: 22.5475 - val_mae: 22.5475\n",
      "Epoch 64/250\n",
      "1706/1709 [============================>.] - ETA: 0s - loss: 21.8261 - mae: 21.8261\n",
      "Epoch 64: val_mae did not improve from 22.46744\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.8260 - mae: 21.8260 - val_loss: 22.8822 - val_mae: 22.8822\n",
      "Epoch 65/250\n",
      "1706/1709 [============================>.] - ETA: 0s - loss: 21.8148 - mae: 21.8148\n",
      "Epoch 65: val_mae did not improve from 22.46744\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.8149 - mae: 21.8149 - val_loss: 22.6482 - val_mae: 22.6482\n",
      "Epoch 66/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.8083 - mae: 21.8083\n",
      "Epoch 66: val_mae did not improve from 22.46744\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.8086 - mae: 21.8086 - val_loss: 22.4995 - val_mae: 22.4995\n",
      "Epoch 67/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.8029 - mae: 21.8029\n",
      "Epoch 67: val_mae did not improve from 22.46744\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.8029 - mae: 21.8029 - val_loss: 22.6171 - val_mae: 22.6171\n",
      "Epoch 68/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.7949 - mae: 21.7949\n",
      "Epoch 68: val_mae did not improve from 22.46744\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.7949 - mae: 21.7949 - val_loss: 22.6502 - val_mae: 22.6502\n",
      "Epoch 69/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.7920 - mae: 21.7920\n",
      "Epoch 69: val_mae improved from 22.46744 to 22.45271, saving model to .\\RNN12_best_model.h5\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.7917 - mae: 21.7917 - val_loss: 22.4527 - val_mae: 22.4527\n",
      "Epoch 70/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.7809 - mae: 21.7809\n",
      "Epoch 70: val_mae did not improve from 22.45271\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.7809 - mae: 21.7809 - val_loss: 22.5164 - val_mae: 22.5164\n",
      "Epoch 71/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.7819 - mae: 21.7819\n",
      "Epoch 71: val_mae did not improve from 22.45271\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.7818 - mae: 21.7818 - val_loss: 23.3345 - val_mae: 23.3345\n",
      "Epoch 72/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.7661 - mae: 21.7661\n",
      "Epoch 72: val_mae did not improve from 22.45271\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.7664 - mae: 21.7664 - val_loss: 22.5896 - val_mae: 22.5896\n",
      "Epoch 73/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.7637 - mae: 21.7637\n",
      "Epoch 73: val_mae did not improve from 22.45271\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.7638 - mae: 21.7638 - val_loss: 22.6070 - val_mae: 22.6070\n",
      "Epoch 74/250\n",
      "1706/1709 [============================>.] - ETA: 0s - loss: 21.7616 - mae: 21.7616\n",
      "Epoch 74: val_mae did not improve from 22.45271\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.7621 - mae: 21.7621 - val_loss: 23.1106 - val_mae: 23.1106\n",
      "Epoch 75/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.7573 - mae: 21.7573\n",
      "Epoch 75: val_mae did not improve from 22.45271\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.7571 - mae: 21.7571 - val_loss: 22.6913 - val_mae: 22.6913\n",
      "Epoch 76/250\n",
      "1706/1709 [============================>.] - ETA: 0s - loss: 21.7438 - mae: 21.7438\n",
      "Epoch 76: val_mae did not improve from 22.45271\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.7436 - mae: 21.7436 - val_loss: 22.5170 - val_mae: 22.5170\n",
      "Epoch 77/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.7371 - mae: 21.7371\n",
      "Epoch 77: val_mae did not improve from 22.45271\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.7370 - mae: 21.7370 - val_loss: 22.6531 - val_mae: 22.6531\n",
      "Epoch 78/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.7343 - mae: 21.7343\n",
      "Epoch 78: val_mae did not improve from 22.45271\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.7334 - mae: 21.7334 - val_loss: 22.6260 - val_mae: 22.6260\n",
      "Epoch 79/250\n",
      "1706/1709 [============================>.] - ETA: 0s - loss: 21.7329 - mae: 21.7329\n",
      "Epoch 79: val_mae did not improve from 22.45271\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.7328 - mae: 21.7328 - val_loss: 22.7765 - val_mae: 22.7765\n",
      "Epoch 80/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.7243 - mae: 21.7243\n",
      "Epoch 80: val_mae did not improve from 22.45271\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.7240 - mae: 21.7240 - val_loss: 22.5885 - val_mae: 22.5885\n",
      "Epoch 81/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.7167 - mae: 21.7167\n",
      "Epoch 81: val_mae did not improve from 22.45271\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.7166 - mae: 21.7166 - val_loss: 22.4634 - val_mae: 22.4634\n",
      "Epoch 82/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.7148 - mae: 21.7148\n",
      "Epoch 82: val_mae did not improve from 22.45271\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.7144 - mae: 21.7144 - val_loss: 22.5296 - val_mae: 22.5296\n",
      "Epoch 83/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.7064 - mae: 21.7064\n",
      "Epoch 83: val_mae did not improve from 22.45271\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.7064 - mae: 21.7064 - val_loss: 22.5767 - val_mae: 22.5767\n",
      "Epoch 84/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.7006 - mae: 21.7006\n",
      "Epoch 84: val_mae did not improve from 22.45271\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.7006 - mae: 21.7006 - val_loss: 22.5252 - val_mae: 22.5252\n",
      "Epoch 85/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.6964 - mae: 21.6964\n",
      "Epoch 85: val_mae did not improve from 22.45271\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.6964 - mae: 21.6964 - val_loss: 22.6287 - val_mae: 22.6287\n",
      "Epoch 86/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.6910 - mae: 21.6910\n",
      "Epoch 86: val_mae did not improve from 22.45271\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.6915 - mae: 21.6915 - val_loss: 22.5792 - val_mae: 22.5792\n",
      "Epoch 87/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.6924 - mae: 21.6924\n",
      "Epoch 87: val_mae did not improve from 22.45271\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.6924 - mae: 21.6924 - val_loss: 22.5770 - val_mae: 22.5770\n",
      "Epoch 88/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.6839 - mae: 21.6839\n",
      "Epoch 88: val_mae did not improve from 22.45271\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.6838 - mae: 21.6838 - val_loss: 22.4799 - val_mae: 22.4799\n",
      "Epoch 89/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.6774 - mae: 21.6774\n",
      "Epoch 89: val_mae improved from 22.45271 to 22.36050, saving model to .\\RNN12_best_model.h5\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.6777 - mae: 21.6777 - val_loss: 22.3605 - val_mae: 22.3605\n",
      "Epoch 90/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.6731 - mae: 21.6731\n",
      "Epoch 90: val_mae did not improve from 22.36050\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.6731 - mae: 21.6731 - val_loss: 22.4274 - val_mae: 22.4274\n",
      "Epoch 91/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.6673 - mae: 21.6673\n",
      "Epoch 91: val_mae did not improve from 22.36050\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.6673 - mae: 21.6673 - val_loss: 22.6230 - val_mae: 22.6230\n",
      "Epoch 92/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.6678 - mae: 21.6678\n",
      "Epoch 92: val_mae did not improve from 22.36050\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.6676 - mae: 21.6676 - val_loss: 22.4548 - val_mae: 22.4548\n",
      "Epoch 93/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.6617 - mae: 21.6617\n",
      "Epoch 93: val_mae did not improve from 22.36050\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.6621 - mae: 21.6621 - val_loss: 22.3775 - val_mae: 22.3775\n",
      "Epoch 94/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.6559 - mae: 21.6559\n",
      "Epoch 94: val_mae did not improve from 22.36050\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.6559 - mae: 21.6559 - val_loss: 23.0594 - val_mae: 23.0594\n",
      "Epoch 95/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.6569 - mae: 21.6569\n",
      "Epoch 95: val_mae did not improve from 22.36050\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.6569 - mae: 21.6569 - val_loss: 22.6583 - val_mae: 22.6583\n",
      "Epoch 96/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.6486 - mae: 21.6486\n",
      "Epoch 96: val_mae did not improve from 22.36050\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.6481 - mae: 21.6481 - val_loss: 22.5975 - val_mae: 22.5975\n",
      "Epoch 97/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.6434 - mae: 21.6434\n",
      "Epoch 97: val_mae did not improve from 22.36050\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.6433 - mae: 21.6433 - val_loss: 22.4202 - val_mae: 22.4202\n",
      "Epoch 98/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.6394 - mae: 21.6394\n",
      "Epoch 98: val_mae did not improve from 22.36050\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.6394 - mae: 21.6394 - val_loss: 22.5896 - val_mae: 22.5896\n",
      "Epoch 99/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.6344 - mae: 21.6344\n",
      "Epoch 99: val_mae did not improve from 22.36050\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.6345 - mae: 21.6345 - val_loss: 22.4268 - val_mae: 22.4268\n",
      "Epoch 100/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.6299 - mae: 21.6299\n",
      "Epoch 100: val_mae did not improve from 22.36050\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.6296 - mae: 21.6296 - val_loss: 22.4807 - val_mae: 22.4807\n",
      "Epoch 101/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.6271 - mae: 21.6271\n",
      "Epoch 101: val_mae did not improve from 22.36050\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.6270 - mae: 21.6270 - val_loss: 22.4958 - val_mae: 22.4958\n",
      "Epoch 102/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.6338 - mae: 21.6338\n",
      "Epoch 102: val_mae did not improve from 22.36050\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.6338 - mae: 21.6338 - val_loss: 22.5540 - val_mae: 22.5540\n",
      "Epoch 103/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.6242 - mae: 21.6242\n",
      "Epoch 103: val_mae improved from 22.36050 to 22.35937, saving model to .\\RNN12_best_model.h5\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.6242 - mae: 21.6242 - val_loss: 22.3594 - val_mae: 22.3594\n",
      "Epoch 104/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.6205 - mae: 21.6205\n",
      "Epoch 104: val_mae did not improve from 22.35937\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.6205 - mae: 21.6205 - val_loss: 23.0127 - val_mae: 23.0127\n",
      "Epoch 105/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.6161 - mae: 21.6161\n",
      "Epoch 105: val_mae did not improve from 22.35937\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.6159 - mae: 21.6159 - val_loss: 22.4294 - val_mae: 22.4294\n",
      "Epoch 106/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.6116 - mae: 21.6116\n",
      "Epoch 106: val_mae did not improve from 22.35937\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.6114 - mae: 21.6114 - val_loss: 22.3937 - val_mae: 22.3937\n",
      "Epoch 107/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.6108 - mae: 21.6108\n",
      "Epoch 107: val_mae did not improve from 22.35937\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.6107 - mae: 21.6107 - val_loss: 22.6429 - val_mae: 22.6429\n",
      "Epoch 108/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.6082 - mae: 21.6082\n",
      "Epoch 108: val_mae improved from 22.35937 to 22.31828, saving model to .\\RNN12_best_model.h5\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.6079 - mae: 21.6079 - val_loss: 22.3183 - val_mae: 22.3183\n",
      "Epoch 109/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.6017 - mae: 21.6017\n",
      "Epoch 109: val_mae did not improve from 22.31828\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.6017 - mae: 21.6017 - val_loss: 22.3396 - val_mae: 22.3396\n",
      "Epoch 110/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.5956 - mae: 21.5956\n",
      "Epoch 110: val_mae did not improve from 22.31828\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5956 - mae: 21.5956 - val_loss: 22.3236 - val_mae: 22.3236\n",
      "Epoch 111/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.5970 - mae: 21.5970\n",
      "Epoch 111: val_mae did not improve from 22.31828\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5966 - mae: 21.5966 - val_loss: 22.3828 - val_mae: 22.3828\n",
      "Epoch 112/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.5965 - mae: 21.5965\n",
      "Epoch 112: val_mae did not improve from 22.31828\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5968 - mae: 21.5968 - val_loss: 22.3828 - val_mae: 22.3828\n",
      "Epoch 113/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.5950 - mae: 21.5950\n",
      "Epoch 113: val_mae did not improve from 22.31828\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5950 - mae: 21.5950 - val_loss: 23.0108 - val_mae: 23.0108\n",
      "Epoch 114/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.5865 - mae: 21.5865\n",
      "Epoch 114: val_mae improved from 22.31828 to 22.29338, saving model to .\\RNN12_best_model.h5\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5865 - mae: 21.5865 - val_loss: 22.2934 - val_mae: 22.2934\n",
      "Epoch 115/250\n",
      "1706/1709 [============================>.] - ETA: 0s - loss: 21.5852 - mae: 21.5852\n",
      "Epoch 115: val_mae did not improve from 22.29338\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5858 - mae: 21.5858 - val_loss: 22.4228 - val_mae: 22.4228\n",
      "Epoch 116/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.5821 - mae: 21.5821\n",
      "Epoch 116: val_mae did not improve from 22.29338\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5821 - mae: 21.5821 - val_loss: 22.6989 - val_mae: 22.6989\n",
      "Epoch 117/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.5857 - mae: 21.5857\n",
      "Epoch 117: val_mae did not improve from 22.29338\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5857 - mae: 21.5857 - val_loss: 22.4483 - val_mae: 22.4483\n",
      "Epoch 118/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.5774 - mae: 21.5774\n",
      "Epoch 118: val_mae did not improve from 22.29338\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5774 - mae: 21.5774 - val_loss: 22.3882 - val_mae: 22.3882\n",
      "Epoch 119/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.5756 - mae: 21.5756\n",
      "Epoch 119: val_mae did not improve from 22.29338\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5756 - mae: 21.5756 - val_loss: 22.3550 - val_mae: 22.3550\n",
      "Epoch 120/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.5708 - mae: 21.5708\n",
      "Epoch 120: val_mae did not improve from 22.29338\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5706 - mae: 21.5706 - val_loss: 22.3368 - val_mae: 22.3368\n",
      "Epoch 121/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.5751 - mae: 21.5751\n",
      "Epoch 121: val_mae did not improve from 22.29338\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5751 - mae: 21.5751 - val_loss: 22.3385 - val_mae: 22.3385\n",
      "Epoch 122/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.5721 - mae: 21.5721\n",
      "Epoch 122: val_mae did not improve from 22.29338\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5721 - mae: 21.5721 - val_loss: 22.7997 - val_mae: 22.7997\n",
      "Epoch 123/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.5615 - mae: 21.5615\n",
      "Epoch 123: val_mae did not improve from 22.29338\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5614 - mae: 21.5614 - val_loss: 22.3693 - val_mae: 22.3693\n",
      "Epoch 124/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.5577 - mae: 21.5577\n",
      "Epoch 124: val_mae did not improve from 22.29338\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5577 - mae: 21.5577 - val_loss: 22.5235 - val_mae: 22.5235\n",
      "Epoch 125/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.5594 - mae: 21.5594\n",
      "Epoch 125: val_mae did not improve from 22.29338\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5594 - mae: 21.5594 - val_loss: 22.7756 - val_mae: 22.7756\n",
      "Epoch 126/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.5582 - mae: 21.5582\n",
      "Epoch 126: val_mae did not improve from 22.29338\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5581 - mae: 21.5581 - val_loss: 22.4104 - val_mae: 22.4104\n",
      "Epoch 127/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.5533 - mae: 21.5533\n",
      "Epoch 127: val_mae did not improve from 22.29338\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5532 - mae: 21.5532 - val_loss: 22.5585 - val_mae: 22.5585\n",
      "Epoch 128/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.5596 - mae: 21.5596\n",
      "Epoch 128: val_mae did not improve from 22.29338\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5595 - mae: 21.5595 - val_loss: 22.7535 - val_mae: 22.7535\n",
      "Epoch 129/250\n",
      "1706/1709 [============================>.] - ETA: 0s - loss: 21.5494 - mae: 21.5494\n",
      "Epoch 129: val_mae did not improve from 22.29338\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5496 - mae: 21.5496 - val_loss: 22.3191 - val_mae: 22.3191\n",
      "Epoch 130/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.5460 - mae: 21.5460\n",
      "Epoch 130: val_mae did not improve from 22.29338\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5463 - mae: 21.5463 - val_loss: 22.8514 - val_mae: 22.8514\n",
      "Epoch 131/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.5467 - mae: 21.5467\n",
      "Epoch 131: val_mae did not improve from 22.29338\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5471 - mae: 21.5471 - val_loss: 22.4393 - val_mae: 22.4393\n",
      "Epoch 132/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.5438 - mae: 21.5438\n",
      "Epoch 132: val_mae did not improve from 22.29338\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5436 - mae: 21.5436 - val_loss: 22.3245 - val_mae: 22.3245\n",
      "Epoch 133/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.5416 - mae: 21.5416\n",
      "Epoch 133: val_mae did not improve from 22.29338\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5416 - mae: 21.5416 - val_loss: 22.4533 - val_mae: 22.4533\n",
      "Epoch 134/250\n",
      "1706/1709 [============================>.] - ETA: 0s - loss: 21.5453 - mae: 21.5453\n",
      "Epoch 134: val_mae did not improve from 22.29338\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5450 - mae: 21.5450 - val_loss: 22.2954 - val_mae: 22.2954\n",
      "Epoch 135/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.5365 - mae: 21.5365\n",
      "Epoch 135: val_mae did not improve from 22.29338\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5365 - mae: 21.5365 - val_loss: 22.4725 - val_mae: 22.4725\n",
      "Epoch 136/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.5457 - mae: 21.5457\n",
      "Epoch 136: val_mae did not improve from 22.29338\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5456 - mae: 21.5456 - val_loss: 22.4124 - val_mae: 22.4124\n",
      "Epoch 137/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.5336 - mae: 21.5336\n",
      "Epoch 137: val_mae did not improve from 22.29338\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5335 - mae: 21.5335 - val_loss: 22.5763 - val_mae: 22.5763\n",
      "Epoch 138/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.5292 - mae: 21.5292\n",
      "Epoch 138: val_mae did not improve from 22.29338\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5292 - mae: 21.5292 - val_loss: 22.5808 - val_mae: 22.5808\n",
      "Epoch 139/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.5380 - mae: 21.5380\n",
      "Epoch 139: val_mae did not improve from 22.29338\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5380 - mae: 21.5380 - val_loss: 22.4458 - val_mae: 22.4458\n",
      "Epoch 140/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.5280 - mae: 21.5280\n",
      "Epoch 140: val_mae did not improve from 22.29338\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5280 - mae: 21.5280 - val_loss: 22.5242 - val_mae: 22.5242\n",
      "Epoch 141/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.5290 - mae: 21.5290\n",
      "Epoch 141: val_mae did not improve from 22.29338\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5293 - mae: 21.5293 - val_loss: 22.3811 - val_mae: 22.3811\n",
      "Epoch 142/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.5213 - mae: 21.5213\n",
      "Epoch 142: val_mae did not improve from 22.29338\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5217 - mae: 21.5217 - val_loss: 22.3368 - val_mae: 22.3368\n",
      "Epoch 143/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.5289 - mae: 21.5289\n",
      "Epoch 143: val_mae improved from 22.29338 to 22.26636, saving model to .\\RNN12_best_model.h5\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5289 - mae: 21.5289 - val_loss: 22.2664 - val_mae: 22.2664\n",
      "Epoch 144/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.5270 - mae: 21.5270\n",
      "Epoch 144: val_mae did not improve from 22.26636\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5270 - mae: 21.5270 - val_loss: 22.8192 - val_mae: 22.8192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.5201 - mae: 21.5201\n",
      "Epoch 145: val_mae did not improve from 22.26636\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5201 - mae: 21.5201 - val_loss: 22.5802 - val_mae: 22.5802\n",
      "Epoch 146/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.5269 - mae: 21.5269\n",
      "Epoch 146: val_mae did not improve from 22.26636\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5270 - mae: 21.5270 - val_loss: 22.5906 - val_mae: 22.5906\n",
      "Epoch 147/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.5219 - mae: 21.5219\n",
      "Epoch 147: val_mae did not improve from 22.26636\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5222 - mae: 21.5222 - val_loss: 22.3210 - val_mae: 22.3210\n",
      "Epoch 148/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.5213 - mae: 21.5213\n",
      "Epoch 148: val_mae did not improve from 22.26636\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5213 - mae: 21.5213 - val_loss: 22.4269 - val_mae: 22.4269\n",
      "Epoch 149/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.5240 - mae: 21.5240\n",
      "Epoch 149: val_mae did not improve from 22.26636\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5240 - mae: 21.5240 - val_loss: 22.3826 - val_mae: 22.3826\n",
      "Epoch 150/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.5149 - mae: 21.5149\n",
      "Epoch 150: val_mae did not improve from 22.26636\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5152 - mae: 21.5152 - val_loss: 22.5743 - val_mae: 22.5743\n",
      "Epoch 151/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.5099 - mae: 21.5099\n",
      "Epoch 151: val_mae did not improve from 22.26636\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5100 - mae: 21.5100 - val_loss: 22.7283 - val_mae: 22.7283\n",
      "Epoch 152/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.5122 - mae: 21.5122\n",
      "Epoch 152: val_mae did not improve from 22.26636\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5124 - mae: 21.5124 - val_loss: 22.3638 - val_mae: 22.3638\n",
      "Epoch 153/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.5103 - mae: 21.5103\n",
      "Epoch 153: val_mae did not improve from 22.26636\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5104 - mae: 21.5104 - val_loss: 22.4540 - val_mae: 22.4540\n",
      "Epoch 154/250\n",
      "1706/1709 [============================>.] - ETA: 0s - loss: 21.5158 - mae: 21.5158\n",
      "Epoch 154: val_mae did not improve from 22.26636\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5157 - mae: 21.5157 - val_loss: 22.6722 - val_mae: 22.6722\n",
      "Epoch 155/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.5060 - mae: 21.5060\n",
      "Epoch 155: val_mae did not improve from 22.26636\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5056 - mae: 21.5056 - val_loss: 22.4274 - val_mae: 22.4274\n",
      "Epoch 156/250\n",
      "1706/1709 [============================>.] - ETA: 0s - loss: 21.5102 - mae: 21.5102\n",
      "Epoch 156: val_mae did not improve from 22.26636\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5100 - mae: 21.5100 - val_loss: 22.6759 - val_mae: 22.6759\n",
      "Epoch 157/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.5081 - mae: 21.5081\n",
      "Epoch 157: val_mae improved from 22.26636 to 22.22688, saving model to .\\RNN12_best_model.h5\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5076 - mae: 21.5076 - val_loss: 22.2269 - val_mae: 22.2269\n",
      "Epoch 158/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.5102 - mae: 21.5102\n",
      "Epoch 158: val_mae did not improve from 22.22688\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5100 - mae: 21.5100 - val_loss: 22.6553 - val_mae: 22.6553\n",
      "Epoch 159/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.5092 - mae: 21.5092\n",
      "Epoch 159: val_mae did not improve from 22.22688\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5092 - mae: 21.5092 - val_loss: 22.5688 - val_mae: 22.5688\n",
      "Epoch 160/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.5043 - mae: 21.5043\n",
      "Epoch 160: val_mae did not improve from 22.22688\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5047 - mae: 21.5047 - val_loss: 22.4123 - val_mae: 22.4123\n",
      "Epoch 161/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.5030 - mae: 21.5030\n",
      "Epoch 161: val_mae did not improve from 22.22688\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5026 - mae: 21.5026 - val_loss: 22.7481 - val_mae: 22.7481\n",
      "Epoch 162/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.5020 - mae: 21.5020\n",
      "Epoch 162: val_mae did not improve from 22.22688\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5020 - mae: 21.5020 - val_loss: 22.4341 - val_mae: 22.4341\n",
      "Epoch 163/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4979 - mae: 21.4979\n",
      "Epoch 163: val_mae did not improve from 22.22688\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4980 - mae: 21.4980 - val_loss: 22.3729 - val_mae: 22.3729\n",
      "Epoch 164/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.4971 - mae: 21.4971\n",
      "Epoch 164: val_mae did not improve from 22.22688\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4972 - mae: 21.4972 - val_loss: 22.4508 - val_mae: 22.4508\n",
      "Epoch 165/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.5070 - mae: 21.5070\n",
      "Epoch 165: val_mae improved from 22.22688 to 22.19196, saving model to .\\RNN12_best_model.h5\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.5070 - mae: 21.5070 - val_loss: 22.1920 - val_mae: 22.1920\n",
      "Epoch 166/250\n",
      "1706/1709 [============================>.] - ETA: 0s - loss: 21.4997 - mae: 21.4997\n",
      "Epoch 166: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4996 - mae: 21.4996 - val_loss: 22.7889 - val_mae: 22.7889\n",
      "Epoch 167/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.4968 - mae: 21.4968\n",
      "Epoch 167: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4968 - mae: 21.4968 - val_loss: 22.5966 - val_mae: 22.5966\n",
      "Epoch 168/250\n",
      "1706/1709 [============================>.] - ETA: 0s - loss: 21.4950 - mae: 21.4950\n",
      "Epoch 168: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4955 - mae: 21.4955 - val_loss: 22.2473 - val_mae: 22.2473\n",
      "Epoch 169/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.4993 - mae: 21.4993\n",
      "Epoch 169: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4993 - mae: 21.4993 - val_loss: 22.3818 - val_mae: 22.3818\n",
      "Epoch 170/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.4942 - mae: 21.4942\n",
      "Epoch 170: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4942 - mae: 21.4942 - val_loss: 22.4600 - val_mae: 22.4600\n",
      "Epoch 171/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.4888 - mae: 21.4888\n",
      "Epoch 171: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4889 - mae: 21.4889 - val_loss: 22.3651 - val_mae: 22.3651\n",
      "Epoch 172/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.4881 - mae: 21.4881\n",
      "Epoch 172: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4881 - mae: 21.4881 - val_loss: 22.7768 - val_mae: 22.7768\n",
      "Epoch 173/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4884 - mae: 21.4884\n",
      "Epoch 173: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4885 - mae: 21.4885 - val_loss: 23.0137 - val_mae: 23.0137\n",
      "Epoch 174/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.4891 - mae: 21.4891\n",
      "Epoch 174: val_mae did not improve from 22.19196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4891 - mae: 21.4891 - val_loss: 22.4394 - val_mae: 22.4394\n",
      "Epoch 175/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4861 - mae: 21.4861\n",
      "Epoch 175: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4859 - mae: 21.4859 - val_loss: 22.4093 - val_mae: 22.4093\n",
      "Epoch 176/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4863 - mae: 21.4863\n",
      "Epoch 176: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4862 - mae: 21.4862 - val_loss: 22.4499 - val_mae: 22.4499\n",
      "Epoch 177/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4860 - mae: 21.4860\n",
      "Epoch 177: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4858 - mae: 21.4858 - val_loss: 22.6649 - val_mae: 22.6649\n",
      "Epoch 178/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.4815 - mae: 21.4815\n",
      "Epoch 178: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4815 - mae: 21.4815 - val_loss: 22.3240 - val_mae: 22.3240\n",
      "Epoch 179/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4847 - mae: 21.4847\n",
      "Epoch 179: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4851 - mae: 21.4851 - val_loss: 22.9278 - val_mae: 22.9278\n",
      "Epoch 180/250\n",
      "1706/1709 [============================>.] - ETA: 0s - loss: 21.4798 - mae: 21.4798\n",
      "Epoch 180: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4799 - mae: 21.4799 - val_loss: 22.4540 - val_mae: 22.4540\n",
      "Epoch 181/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4872 - mae: 21.4872\n",
      "Epoch 181: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4874 - mae: 21.4874 - val_loss: 22.6546 - val_mae: 22.6546\n",
      "Epoch 182/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.4816 - mae: 21.4816\n",
      "Epoch 182: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4816 - mae: 21.4816 - val_loss: 22.3101 - val_mae: 22.3101\n",
      "Epoch 183/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4766 - mae: 21.4766\n",
      "Epoch 183: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4768 - mae: 21.4768 - val_loss: 22.6541 - val_mae: 22.6541\n",
      "Epoch 184/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4839 - mae: 21.4839\n",
      "Epoch 184: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4842 - mae: 21.4842 - val_loss: 22.4245 - val_mae: 22.4245\n",
      "Epoch 185/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.4685 - mae: 21.4685\n",
      "Epoch 185: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4684 - mae: 21.4684 - val_loss: 22.3991 - val_mae: 22.3991\n",
      "Epoch 186/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.4799 - mae: 21.4799\n",
      "Epoch 186: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4799 - mae: 21.4799 - val_loss: 22.8112 - val_mae: 22.8112\n",
      "Epoch 187/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.4780 - mae: 21.4780\n",
      "Epoch 187: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4782 - mae: 21.4782 - val_loss: 22.4012 - val_mae: 22.4012\n",
      "Epoch 188/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.4768 - mae: 21.4768\n",
      "Epoch 188: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4770 - mae: 21.4770 - val_loss: 22.3690 - val_mae: 22.3690\n",
      "Epoch 189/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.4738 - mae: 21.4738\n",
      "Epoch 189: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4740 - mae: 21.4740 - val_loss: 22.4254 - val_mae: 22.4254\n",
      "Epoch 190/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4708 - mae: 21.4708\n",
      "Epoch 190: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4706 - mae: 21.4706 - val_loss: 22.3913 - val_mae: 22.3913\n",
      "Epoch 191/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.4730 - mae: 21.4730\n",
      "Epoch 191: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4726 - mae: 21.4726 - val_loss: 22.3028 - val_mae: 22.3028\n",
      "Epoch 192/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.4667 - mae: 21.4667\n",
      "Epoch 192: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4666 - mae: 21.4666 - val_loss: 22.6859 - val_mae: 22.6859\n",
      "Epoch 193/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.4724 - mae: 21.4724\n",
      "Epoch 193: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4726 - mae: 21.4726 - val_loss: 22.3661 - val_mae: 22.3661\n",
      "Epoch 194/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4748 - mae: 21.4748\n",
      "Epoch 194: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4746 - mae: 21.4746 - val_loss: 22.4939 - val_mae: 22.4939\n",
      "Epoch 195/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.4673 - mae: 21.4673\n",
      "Epoch 195: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4673 - mae: 21.4673 - val_loss: 22.3864 - val_mae: 22.3864\n",
      "Epoch 196/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.4713 - mae: 21.4713\n",
      "Epoch 196: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4716 - mae: 21.4716 - val_loss: 22.2806 - val_mae: 22.2806\n",
      "Epoch 197/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.4595 - mae: 21.4595\n",
      "Epoch 197: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4600 - mae: 21.4600 - val_loss: 22.3428 - val_mae: 22.3428\n",
      "Epoch 198/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.4679 - mae: 21.4679\n",
      "Epoch 198: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4679 - mae: 21.4679 - val_loss: 22.6353 - val_mae: 22.6353\n",
      "Epoch 199/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.4604 - mae: 21.4604\n",
      "Epoch 199: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4600 - mae: 21.4600 - val_loss: 22.8420 - val_mae: 22.8420\n",
      "Epoch 200/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.4644 - mae: 21.4644\n",
      "Epoch 200: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4647 - mae: 21.4647 - val_loss: 22.3755 - val_mae: 22.3755\n",
      "Epoch 201/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.4632 - mae: 21.4632\n",
      "Epoch 201: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4632 - mae: 21.4632 - val_loss: 22.2206 - val_mae: 22.2206\n",
      "Epoch 202/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.4588 - mae: 21.4588\n",
      "Epoch 202: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4588 - mae: 21.4588 - val_loss: 22.4446 - val_mae: 22.4446\n",
      "Epoch 203/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4599 - mae: 21.4599\n",
      "Epoch 203: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4599 - mae: 21.4599 - val_loss: 22.5369 - val_mae: 22.5369\n",
      "Epoch 204/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.4597 - mae: 21.4597\n",
      "Epoch 204: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4592 - mae: 21.4592 - val_loss: 22.3287 - val_mae: 22.3287\n",
      "Epoch 205/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4637 - mae: 21.4637\n",
      "Epoch 205: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4637 - mae: 21.4637 - val_loss: 22.2417 - val_mae: 22.2417\n",
      "Epoch 206/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4597 - mae: 21.4597\n",
      "Epoch 206: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4598 - mae: 21.4598 - val_loss: 22.2225 - val_mae: 22.2225\n",
      "Epoch 207/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.4572 - mae: 21.4572\n",
      "Epoch 207: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4567 - mae: 21.4567 - val_loss: 22.3994 - val_mae: 22.3994\n",
      "Epoch 208/250\n",
      "1706/1709 [============================>.] - ETA: 0s - loss: 21.4552 - mae: 21.4552\n",
      "Epoch 208: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4549 - mae: 21.4549 - val_loss: 22.3845 - val_mae: 22.3845\n",
      "Epoch 209/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.4554 - mae: 21.4554\n",
      "Epoch 209: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4554 - mae: 21.4554 - val_loss: 22.3303 - val_mae: 22.3303\n",
      "Epoch 210/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4530 - mae: 21.4530\n",
      "Epoch 210: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4531 - mae: 21.4531 - val_loss: 22.2285 - val_mae: 22.2285\n",
      "Epoch 211/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4545 - mae: 21.4545\n",
      "Epoch 211: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4546 - mae: 21.4546 - val_loss: 22.3901 - val_mae: 22.3901\n",
      "Epoch 212/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4456 - mae: 21.4456\n",
      "Epoch 212: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4457 - mae: 21.4457 - val_loss: 22.2650 - val_mae: 22.2650\n",
      "Epoch 213/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.4579 - mae: 21.4579\n",
      "Epoch 213: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4579 - mae: 21.4579 - val_loss: 22.6831 - val_mae: 22.6831\n",
      "Epoch 214/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4449 - mae: 21.4449\n",
      "Epoch 214: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4451 - mae: 21.4451 - val_loss: 22.4031 - val_mae: 22.4031\n",
      "Epoch 215/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.4514 - mae: 21.4514\n",
      "Epoch 215: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4514 - mae: 21.4514 - val_loss: 22.5282 - val_mae: 22.5282\n",
      "Epoch 216/250\n",
      "1706/1709 [============================>.] - ETA: 0s - loss: 21.4492 - mae: 21.4492\n",
      "Epoch 216: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4496 - mae: 21.4496 - val_loss: 22.7590 - val_mae: 22.7590\n",
      "Epoch 217/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.4469 - mae: 21.4469\n",
      "Epoch 217: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4469 - mae: 21.4469 - val_loss: 22.4362 - val_mae: 22.4362\n",
      "Epoch 218/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.4453 - mae: 21.4453\n",
      "Epoch 218: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4453 - mae: 21.4453 - val_loss: 22.7818 - val_mae: 22.7818\n",
      "Epoch 219/250\n",
      "1706/1709 [============================>.] - ETA: 0s - loss: 21.4422 - mae: 21.4422\n",
      "Epoch 219: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4426 - mae: 21.4426 - val_loss: 22.4531 - val_mae: 22.4531\n",
      "Epoch 220/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4429 - mae: 21.4429\n",
      "Epoch 220: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4429 - mae: 21.4429 - val_loss: 22.4403 - val_mae: 22.4403\n",
      "Epoch 221/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4400 - mae: 21.4400\n",
      "Epoch 221: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4397 - mae: 21.4397 - val_loss: 22.4075 - val_mae: 22.4075\n",
      "Epoch 222/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.4416 - mae: 21.4416\n",
      "Epoch 222: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4416 - mae: 21.4416 - val_loss: 22.4056 - val_mae: 22.4056\n",
      "Epoch 223/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.4394 - mae: 21.4394\n",
      "Epoch 223: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4394 - mae: 21.4394 - val_loss: 22.4782 - val_mae: 22.4782\n",
      "Epoch 224/250\n",
      "1706/1709 [============================>.] - ETA: 0s - loss: 21.4318 - mae: 21.4318\n",
      "Epoch 224: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4316 - mae: 21.4316 - val_loss: 22.6457 - val_mae: 22.6457\n",
      "Epoch 225/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.4399 - mae: 21.4399\n",
      "Epoch 225: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4400 - mae: 21.4400 - val_loss: 22.5025 - val_mae: 22.5025\n",
      "Epoch 226/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.4375 - mae: 21.4375\n",
      "Epoch 226: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4373 - mae: 21.4373 - val_loss: 22.9717 - val_mae: 22.9717\n",
      "Epoch 227/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4288 - mae: 21.4288\n",
      "Epoch 227: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4284 - mae: 21.4284 - val_loss: 22.5309 - val_mae: 22.5309\n",
      "Epoch 228/250\n",
      "1706/1709 [============================>.] - ETA: 0s - loss: 21.4417 - mae: 21.4417\n",
      "Epoch 228: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4420 - mae: 21.4420 - val_loss: 22.3355 - val_mae: 22.3355\n",
      "Epoch 229/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.4315 - mae: 21.4315\n",
      "Epoch 229: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4315 - mae: 21.4315 - val_loss: 22.4258 - val_mae: 22.4258\n",
      "Epoch 230/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.4329 - mae: 21.4329\n",
      "Epoch 230: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4330 - mae: 21.4330 - val_loss: 22.2534 - val_mae: 22.2534\n",
      "Epoch 231/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4342 - mae: 21.4342\n",
      "Epoch 231: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4344 - mae: 21.4344 - val_loss: 22.2779 - val_mae: 22.2779\n",
      "Epoch 232/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.4304 - mae: 21.4304\n",
      "Epoch 232: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4304 - mae: 21.4304 - val_loss: 22.2880 - val_mae: 22.2880\n",
      "Epoch 233/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.4274 - mae: 21.4274\n",
      "Epoch 233: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4271 - mae: 21.4271 - val_loss: 22.7365 - val_mae: 22.7365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 234/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.4257 - mae: 21.4257\n",
      "Epoch 234: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4254 - mae: 21.4254 - val_loss: 22.7976 - val_mae: 22.7976\n",
      "Epoch 235/250\n",
      "1707/1709 [============================>.] - ETA: 0s - loss: 21.4232 - mae: 21.4232\n",
      "Epoch 235: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4226 - mae: 21.4226 - val_loss: 22.2014 - val_mae: 22.2014\n",
      "Epoch 236/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4248 - mae: 21.4248\n",
      "Epoch 236: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4249 - mae: 21.4249 - val_loss: 22.2576 - val_mae: 22.2576\n",
      "Epoch 237/250\n",
      "1706/1709 [============================>.] - ETA: 0s - loss: 21.4206 - mae: 21.4206\n",
      "Epoch 237: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4205 - mae: 21.4205 - val_loss: 22.9125 - val_mae: 22.9125\n",
      "Epoch 238/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4185 - mae: 21.4185\n",
      "Epoch 238: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4187 - mae: 21.4187 - val_loss: 22.2924 - val_mae: 22.2924\n",
      "Epoch 239/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.4243 - mae: 21.4243\n",
      "Epoch 239: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4243 - mae: 21.4243 - val_loss: 22.3769 - val_mae: 22.3769\n",
      "Epoch 240/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.4234 - mae: 21.4234\n",
      "Epoch 240: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4234 - mae: 21.4234 - val_loss: 22.6587 - val_mae: 22.6587\n",
      "Epoch 241/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.4139 - mae: 21.4139\n",
      "Epoch 241: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4139 - mae: 21.4139 - val_loss: 22.7945 - val_mae: 22.7945\n",
      "Epoch 242/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.4229 - mae: 21.4229\n",
      "Epoch 242: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4229 - mae: 21.4229 - val_loss: 22.5632 - val_mae: 22.5632\n",
      "Epoch 243/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4170 - mae: 21.4170\n",
      "Epoch 243: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4171 - mae: 21.4171 - val_loss: 22.3851 - val_mae: 22.3851\n",
      "Epoch 244/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4136 - mae: 21.4136\n",
      "Epoch 244: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4140 - mae: 21.4140 - val_loss: 22.8169 - val_mae: 22.8169\n",
      "Epoch 245/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4143 - mae: 21.4143\n",
      "Epoch 245: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4144 - mae: 21.4144 - val_loss: 22.4704 - val_mae: 22.4704\n",
      "Epoch 246/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4110 - mae: 21.4110\n",
      "Epoch 246: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4113 - mae: 21.4113 - val_loss: 22.3588 - val_mae: 22.3588\n",
      "Epoch 247/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4090 - mae: 21.4090\n",
      "Epoch 247: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4090 - mae: 21.4090 - val_loss: 22.6089 - val_mae: 22.6089\n",
      "Epoch 248/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4075 - mae: 21.4075\n",
      "Epoch 248: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4074 - mae: 21.4074 - val_loss: 22.6105 - val_mae: 22.6105\n",
      "Epoch 249/250\n",
      "1709/1709 [==============================] - ETA: 0s - loss: 21.4103 - mae: 21.4103\n",
      "Epoch 249: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4103 - mae: 21.4103 - val_loss: 22.4677 - val_mae: 22.4677\n",
      "Epoch 250/250\n",
      "1708/1709 [============================>.] - ETA: 0s - loss: 21.4074 - mae: 21.4074\n",
      "Epoch 250: val_mae did not improve from 22.19196\n",
      "1709/1709 [==============================] - 32s 19ms/step - loss: 21.4074 - mae: 21.4074 - val_loss: 22.7071 - val_mae: 22.7071\n"
     ]
    }
   ],
   "source": [
    "seed = 60\n",
    "tf.keras.utils.set_random_seed(seed)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "checkpoint = ModelCheckpoint('./RNN12_best_model.h5',\n",
    "                        monitor = 'val_mae',\n",
    "                        verbose=1,\n",
    "                        save_best_only=True,\n",
    "                        mode='auto')  \n",
    "\n",
    "hist = model.fit(x_train, y_train, validation_data=(x_test, y_test), \n",
    "                 epochs=250, batch_size=16, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f75a3555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249/249 [==============================] - 2s 5ms/step - loss: 22.1920 - mae: 22.1920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[22.19196891784668, 22.19196891784668]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN12_model = tf.keras.models.load_model('./RNN12_best_model.h5')\n",
    "RNN12_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4c1eb705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264/264 [==============================] - 1s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "RNN12_pred = RNN12_model.predict(submission_x)\n",
    "pd.DataFrame(RNN12_pred).to_csv('RNN12_pred.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f39ec4a",
   "metadata": {},
   "source": [
    "## RNN13 / window size 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0f9e096c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27415, 48, 1) (27415, 336) (8040, 48, 1) (8040, 336) (8425, 48, 1) (8425, 336)\n"
     ]
    }
   ],
   "source": [
    "pre_day = 30 # (31 - pre_month) * 24 = windowsize /27 : 96//28 : 72//29 : 48//30 : 24//\n",
    "x_train, y_train, x_test, y_test, submission_x, submission_y = DataProcessing.data_form_descision(train_df, test_df, pre_day)\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape, submission_x.shape, submission_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "71e5e6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_36 (SimpleRNN)   (None, 48, 32)            1088      \n",
      "                                                                 \n",
      " simple_rnn_37 (SimpleRNN)   (None, 48, 16)            784       \n",
      "                                                                 \n",
      " simple_rnn_38 (SimpleRNN)   (None, 16)                528       \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 64)                1088      \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 336)               21840     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,328\n",
      "Trainable params: 25,328\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "initializer = tf.keras.initializers.GlorotNormal(seed=15)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(32, activation='relu', input_shape=(x_train[0].shape), \n",
    "               return_sequences=True, kernel_initializer=initializer))\n",
    "model.add(SimpleRNN(16, activation='relu',return_sequences=True, kernel_initializer=initializer))\n",
    "model.add(SimpleRNN(16, activation='relu', kernel_initializer=initializer))\n",
    "model.add(Dense(64, activation='relu', kernel_initializer=initializer))\n",
    "model.add(Dense(336, activation='linear', kernel_initializer=initializer))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0002)\n",
    "model.compile(loss='mae', optimizer=optimizer, metrics=['mae'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1f5e186a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1711/1714 [============================>.] - ETA: 0s - loss: 35.6022 - mae: 35.6022\n",
      "Epoch 1: val_mae improved from inf to 28.25721, saving model to .\\RNN13_best_model.h5\n",
      "1714/1714 [==============================] - 15s 8ms/step - loss: 35.5905 - mae: 35.5905 - val_loss: 28.2572 - val_mae: 28.2572\n",
      "Epoch 2/200\n",
      "1711/1714 [============================>.] - ETA: 0s - loss: 24.6277 - mae: 24.6277\n",
      "Epoch 2: val_mae improved from 28.25721 to 24.52867, saving model to .\\RNN13_best_model.h5\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 24.6259 - mae: 24.6259 - val_loss: 24.5287 - val_mae: 24.5287\n",
      "Epoch 3/200\n",
      "1710/1714 [============================>.] - ETA: 0s - loss: 23.5877 - mae: 23.5877\n",
      "Epoch 3: val_mae improved from 24.52867 to 24.03483, saving model to .\\RNN13_best_model.h5\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 23.5885 - mae: 23.5885 - val_loss: 24.0348 - val_mae: 24.0348\n",
      "Epoch 4/200\n",
      "1710/1714 [============================>.] - ETA: 0s - loss: 23.2764 - mae: 23.2764\n",
      "Epoch 4: val_mae improved from 24.03483 to 23.57581, saving model to .\\RNN13_best_model.h5\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 23.2751 - mae: 23.2751 - val_loss: 23.5758 - val_mae: 23.5758\n",
      "Epoch 5/200\n",
      "1712/1714 [============================>.] - ETA: 0s - loss: 22.9974 - mae: 22.9974\n",
      "Epoch 5: val_mae improved from 23.57581 to 23.43602, saving model to .\\RNN13_best_model.h5\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 22.9968 - mae: 22.9968 - val_loss: 23.4360 - val_mae: 23.4360\n",
      "Epoch 6/200\n",
      "1712/1714 [============================>.] - ETA: 0s - loss: 22.7756 - mae: 22.7756\n",
      "Epoch 6: val_mae improved from 23.43602 to 23.22397, saving model to .\\RNN13_best_model.h5\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 22.7761 - mae: 22.7761 - val_loss: 23.2240 - val_mae: 23.2240\n",
      "Epoch 7/200\n",
      "1709/1714 [============================>.] - ETA: 0s - loss: 22.6128 - mae: 22.6128\n",
      "Epoch 7: val_mae improved from 23.22397 to 23.13202, saving model to .\\RNN13_best_model.h5\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 22.6132 - mae: 22.6132 - val_loss: 23.1320 - val_mae: 23.1320\n",
      "Epoch 8/200\n",
      "1711/1714 [============================>.] - ETA: 0s - loss: 22.4846 - mae: 22.4846\n",
      "Epoch 8: val_mae improved from 23.13202 to 23.05802, saving model to .\\RNN13_best_model.h5\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 22.4855 - mae: 22.4855 - val_loss: 23.0580 - val_mae: 23.0580\n",
      "Epoch 9/200\n",
      "1711/1714 [============================>.] - ETA: 0s - loss: 22.3770 - mae: 22.3770\n",
      "Epoch 9: val_mae improved from 23.05802 to 22.95678, saving model to .\\RNN13_best_model.h5\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 22.3772 - mae: 22.3772 - val_loss: 22.9568 - val_mae: 22.9568\n",
      "Epoch 10/200\n",
      "1710/1714 [============================>.] - ETA: 0s - loss: 22.3100 - mae: 22.3100\n",
      "Epoch 10: val_mae improved from 22.95678 to 22.84082, saving model to .\\RNN13_best_model.h5\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 22.3101 - mae: 22.3101 - val_loss: 22.8408 - val_mae: 22.8408\n",
      "Epoch 11/200\n",
      "1710/1714 [============================>.] - ETA: 0s - loss: 22.2528 - mae: 22.2528\n",
      "Epoch 11: val_mae did not improve from 22.84082\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 22.2532 - mae: 22.2532 - val_loss: 22.8620 - val_mae: 22.8620\n",
      "Epoch 12/200\n",
      "1707/1714 [============================>.] - ETA: 0s - loss: 22.2079 - mae: 22.2079\n",
      "Epoch 12: val_mae improved from 22.84082 to 22.77704, saving model to .\\RNN13_best_model.h5\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 22.2083 - mae: 22.2083 - val_loss: 22.7770 - val_mae: 22.7770\n",
      "Epoch 13/200\n",
      "1713/1714 [============================>.] - ETA: 0s - loss: 22.1469 - mae: 22.1469\n",
      "Epoch 13: val_mae improved from 22.77704 to 22.74362, saving model to .\\RNN13_best_model.h5\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 22.1468 - mae: 22.1468 - val_loss: 22.7436 - val_mae: 22.7436\n",
      "Epoch 14/200\n",
      "1713/1714 [============================>.] - ETA: 0s - loss: 22.1152 - mae: 22.1152\n",
      "Epoch 14: val_mae did not improve from 22.74362\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 22.1153 - mae: 22.1153 - val_loss: 22.8180 - val_mae: 22.8180\n",
      "Epoch 15/200\n",
      "1713/1714 [============================>.] - ETA: 0s - loss: 22.0821 - mae: 22.0821\n",
      "Epoch 15: val_mae improved from 22.74362 to 22.72898, saving model to .\\RNN13_best_model.h5\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 22.0823 - mae: 22.0823 - val_loss: 22.7290 - val_mae: 22.7290\n",
      "Epoch 16/200\n",
      "1713/1714 [============================>.] - ETA: 0s - loss: 22.0519 - mae: 22.0519\n",
      "Epoch 16: val_mae did not improve from 22.72898\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 22.0519 - mae: 22.0519 - val_loss: 22.7296 - val_mae: 22.7296\n",
      "Epoch 17/200\n",
      "1709/1714 [============================>.] - ETA: 0s - loss: 22.0195 - mae: 22.0195\n",
      "Epoch 17: val_mae did not improve from 22.72898\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 22.0186 - mae: 22.0186 - val_loss: 23.2438 - val_mae: 23.2438\n",
      "Epoch 18/200\n",
      "1710/1714 [============================>.] - ETA: 0s - loss: 22.0109 - mae: 22.0109\n",
      "Epoch 18: val_mae improved from 22.72898 to 22.71883, saving model to .\\RNN13_best_model.h5\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 22.0111 - mae: 22.0111 - val_loss: 22.7188 - val_mae: 22.7188\n",
      "Epoch 19/200\n",
      "1712/1714 [============================>.] - ETA: 0s - loss: 21.9798 - mae: 21.9798\n",
      "Epoch 19: val_mae did not improve from 22.71883\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.9801 - mae: 21.9801 - val_loss: 22.9463 - val_mae: 22.9463\n",
      "Epoch 20/200\n",
      "1708/1714 [============================>.] - ETA: 0s - loss: 21.9641 - mae: 21.9641\n",
      "Epoch 20: val_mae improved from 22.71883 to 22.67683, saving model to .\\RNN13_best_model.h5\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.9642 - mae: 21.9642 - val_loss: 22.6768 - val_mae: 22.6768\n",
      "Epoch 21/200\n",
      "1711/1714 [============================>.] - ETA: 0s - loss: 21.9550 - mae: 21.9550\n",
      "Epoch 21: val_mae did not improve from 22.67683\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.9555 - mae: 21.9555 - val_loss: 23.3420 - val_mae: 23.3420\n",
      "Epoch 22/200\n",
      "1709/1714 [============================>.] - ETA: 0s - loss: 21.9426 - mae: 21.9426\n",
      "Epoch 22: val_mae did not improve from 22.67683\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.9427 - mae: 21.9427 - val_loss: 23.5768 - val_mae: 23.5768\n",
      "Epoch 23/200\n",
      "1708/1714 [============================>.] - ETA: 0s - loss: 21.9370 - mae: 21.9370\n",
      "Epoch 23: val_mae improved from 22.67683 to 22.60878, saving model to .\\RNN13_best_model.h5\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.9372 - mae: 21.9372 - val_loss: 22.6088 - val_mae: 22.6088\n",
      "Epoch 24/200\n",
      "1713/1714 [============================>.] - ETA: 0s - loss: 21.9178 - mae: 21.9178\n",
      "Epoch 24: val_mae did not improve from 22.60878\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.9176 - mae: 21.9176 - val_loss: 22.9448 - val_mae: 22.9448\n",
      "Epoch 25/200\n",
      "1709/1714 [============================>.] - ETA: 0s - loss: 21.9109 - mae: 21.9109\n",
      "Epoch 25: val_mae did not improve from 22.60878\n",
      "1714/1714 [==============================] - 15s 9ms/step - loss: 21.9115 - mae: 21.9115 - val_loss: 22.8683 - val_mae: 22.8683\n",
      "Epoch 26/200\n",
      "1709/1714 [============================>.] - ETA: 0s - loss: 21.8957 - mae: 21.8957\n",
      "Epoch 26: val_mae did not improve from 22.60878\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.8966 - mae: 21.8966 - val_loss: 22.7381 - val_mae: 22.7381\n",
      "Epoch 27/200\n",
      "1713/1714 [============================>.] - ETA: 0s - loss: 21.8911 - mae: 21.8911\n",
      "Epoch 27: val_mae did not improve from 22.60878\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.8911 - mae: 21.8911 - val_loss: 22.8080 - val_mae: 22.8080\n",
      "Epoch 28/200\n",
      "1711/1714 [============================>.] - ETA: 0s - loss: 21.8700 - mae: 21.8700\n",
      "Epoch 28: val_mae did not improve from 22.60878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.8699 - mae: 21.8699 - val_loss: 23.5132 - val_mae: 23.5132\n",
      "Epoch 29/200\n",
      "1712/1714 [============================>.] - ETA: 0s - loss: 21.8698 - mae: 21.8698\n",
      "Epoch 29: val_mae did not improve from 22.60878\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.8701 - mae: 21.8701 - val_loss: 22.6472 - val_mae: 22.6472\n",
      "Epoch 30/200\n",
      "1712/1714 [============================>.] - ETA: 0s - loss: 21.8529 - mae: 21.8529\n",
      "Epoch 30: val_mae improved from 22.60878 to 22.60467, saving model to .\\RNN13_best_model.h5\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.8527 - mae: 21.8527 - val_loss: 22.6047 - val_mae: 22.6047\n",
      "Epoch 31/200\n",
      "1711/1714 [============================>.] - ETA: 0s - loss: 21.8526 - mae: 21.8526\n",
      "Epoch 31: val_mae did not improve from 22.60467\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.8523 - mae: 21.8523 - val_loss: 22.7100 - val_mae: 22.7100\n",
      "Epoch 32/200\n",
      "1710/1714 [============================>.] - ETA: 0s - loss: 21.8445 - mae: 21.8445\n",
      "Epoch 32: val_mae did not improve from 22.60467\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.8446 - mae: 21.8446 - val_loss: 22.7995 - val_mae: 22.7995\n",
      "Epoch 33/200\n",
      "1714/1714 [==============================] - ETA: 0s - loss: 21.8335 - mae: 21.8335\n",
      "Epoch 33: val_mae improved from 22.60467 to 22.59386, saving model to .\\RNN13_best_model.h5\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.8335 - mae: 21.8335 - val_loss: 22.5939 - val_mae: 22.5939\n",
      "Epoch 34/200\n",
      "1709/1714 [============================>.] - ETA: 0s - loss: 21.8258 - mae: 21.8258\n",
      "Epoch 34: val_mae did not improve from 22.59386\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.8248 - mae: 21.8248 - val_loss: 22.9697 - val_mae: 22.9697\n",
      "Epoch 35/200\n",
      "1711/1714 [============================>.] - ETA: 0s - loss: 21.8250 - mae: 21.8250\n",
      "Epoch 35: val_mae did not improve from 22.59386\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.8252 - mae: 21.8252 - val_loss: 22.6720 - val_mae: 22.6720\n",
      "Epoch 36/200\n",
      "1709/1714 [============================>.] - ETA: 0s - loss: 21.8223 - mae: 21.8223\n",
      "Epoch 36: val_mae did not improve from 22.59386\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.8232 - mae: 21.8232 - val_loss: 23.5446 - val_mae: 23.5446\n",
      "Epoch 37/200\n",
      "1713/1714 [============================>.] - ETA: 0s - loss: 21.8070 - mae: 21.8070\n",
      "Epoch 37: val_mae did not improve from 22.59386\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.8071 - mae: 21.8071 - val_loss: 22.7671 - val_mae: 22.7671\n",
      "Epoch 38/200\n",
      "1711/1714 [============================>.] - ETA: 0s - loss: 21.8084 - mae: 21.8084\n",
      "Epoch 38: val_mae did not improve from 22.59386\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.8083 - mae: 21.8083 - val_loss: 22.6635 - val_mae: 22.6635\n",
      "Epoch 39/200\n",
      "1708/1714 [============================>.] - ETA: 0s - loss: 21.7942 - mae: 21.7942\n",
      "Epoch 39: val_mae did not improve from 22.59386\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.7942 - mae: 21.7942 - val_loss: 22.6527 - val_mae: 22.6527\n",
      "Epoch 40/200\n",
      "1713/1714 [============================>.] - ETA: 0s - loss: 21.7864 - mae: 21.7864\n",
      "Epoch 40: val_mae did not improve from 22.59386\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.7862 - mae: 21.7862 - val_loss: 22.7465 - val_mae: 22.7465\n",
      "Epoch 41/200\n",
      "1710/1714 [============================>.] - ETA: 0s - loss: 21.7832 - mae: 21.7832\n",
      "Epoch 41: val_mae improved from 22.59386 to 22.54781, saving model to .\\RNN13_best_model.h5\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.7828 - mae: 21.7828 - val_loss: 22.5478 - val_mae: 22.5478\n",
      "Epoch 42/200\n",
      "1710/1714 [============================>.] - ETA: 0s - loss: 21.7846 - mae: 21.7846\n",
      "Epoch 42: val_mae did not improve from 22.54781\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.7842 - mae: 21.7842 - val_loss: 23.1408 - val_mae: 23.1408\n",
      "Epoch 43/200\n",
      "1714/1714 [==============================] - ETA: 0s - loss: 21.7652 - mae: 21.7652\n",
      "Epoch 43: val_mae did not improve from 22.54781\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.7652 - mae: 21.7652 - val_loss: 22.5796 - val_mae: 22.5796\n",
      "Epoch 44/200\n",
      "1712/1714 [============================>.] - ETA: 0s - loss: 21.7686 - mae: 21.7686\n",
      "Epoch 44: val_mae improved from 22.54781 to 22.45724, saving model to .\\RNN13_best_model.h5\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.7686 - mae: 21.7686 - val_loss: 22.4572 - val_mae: 22.4572\n",
      "Epoch 45/200\n",
      "1711/1714 [============================>.] - ETA: 0s - loss: 21.7599 - mae: 21.7599\n",
      "Epoch 45: val_mae did not improve from 22.45724\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.7609 - mae: 21.7609 - val_loss: 22.6603 - val_mae: 22.6603\n",
      "Epoch 46/200\n",
      "1710/1714 [============================>.] - ETA: 0s - loss: 21.7523 - mae: 21.7523\n",
      "Epoch 46: val_mae did not improve from 22.45724\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.7521 - mae: 21.7521 - val_loss: 22.6473 - val_mae: 22.6473\n",
      "Epoch 47/200\n",
      "1712/1714 [============================>.] - ETA: 0s - loss: 21.7555 - mae: 21.7555\n",
      "Epoch 47: val_mae did not improve from 22.45724\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.7561 - mae: 21.7561 - val_loss: 22.6165 - val_mae: 22.6165\n",
      "Epoch 48/200\n",
      "1711/1714 [============================>.] - ETA: 0s - loss: 21.7521 - mae: 21.7521\n",
      "Epoch 48: val_mae did not improve from 22.45724\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.7515 - mae: 21.7515 - val_loss: 23.1991 - val_mae: 23.1991\n",
      "Epoch 49/200\n",
      "1708/1714 [============================>.] - ETA: 0s - loss: 21.7436 - mae: 21.7436\n",
      "Epoch 49: val_mae did not improve from 22.45724\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.7426 - mae: 21.7426 - val_loss: 22.8109 - val_mae: 22.8109\n",
      "Epoch 50/200\n",
      "1714/1714 [==============================] - ETA: 0s - loss: 21.7329 - mae: 21.7329\n",
      "Epoch 50: val_mae did not improve from 22.45724\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.7329 - mae: 21.7329 - val_loss: 22.7094 - val_mae: 22.7094\n",
      "Epoch 51/200\n",
      "1713/1714 [============================>.] - ETA: 0s - loss: 21.7266 - mae: 21.7266\n",
      "Epoch 51: val_mae did not improve from 22.45724\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.7267 - mae: 21.7267 - val_loss: 23.1295 - val_mae: 23.1295\n",
      "Epoch 52/200\n",
      "1710/1714 [============================>.] - ETA: 0s - loss: 21.7213 - mae: 21.7213\n",
      "Epoch 52: val_mae did not improve from 22.45724\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.7209 - mae: 21.7209 - val_loss: 22.8878 - val_mae: 22.8878\n",
      "Epoch 53/200\n",
      "1710/1714 [============================>.] - ETA: 0s - loss: 21.7240 - mae: 21.7240\n",
      "Epoch 53: val_mae did not improve from 22.45724\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.7234 - mae: 21.7234 - val_loss: 23.3090 - val_mae: 23.3090\n",
      "Epoch 54/200\n",
      "1710/1714 [============================>.] - ETA: 0s - loss: 21.7139 - mae: 21.7139\n",
      "Epoch 54: val_mae did not improve from 22.45724\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.7146 - mae: 21.7146 - val_loss: 22.5126 - val_mae: 22.5126\n",
      "Epoch 55/200\n",
      "1710/1714 [============================>.] - ETA: 0s - loss: 21.7021 - mae: 21.7021\n",
      "Epoch 55: val_mae did not improve from 22.45724\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.7022 - mae: 21.7022 - val_loss: 23.1732 - val_mae: 23.1732\n",
      "Epoch 56/200\n",
      "1710/1714 [============================>.] - ETA: 0s - loss: 21.7125 - mae: 21.7125\n",
      "Epoch 56: val_mae did not improve from 22.45724\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.7122 - mae: 21.7122 - val_loss: 22.7126 - val_mae: 22.7126\n",
      "Epoch 57/200\n",
      "1707/1714 [============================>.] - ETA: 0s - loss: 21.6982 - mae: 21.6982\n",
      "Epoch 57: val_mae did not improve from 22.45724\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.6976 - mae: 21.6976 - val_loss: 22.7368 - val_mae: 22.7368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "1707/1714 [============================>.] - ETA: 0s - loss: 21.6905 - mae: 21.6905\n",
      "Epoch 58: val_mae improved from 22.45724 to 22.37332, saving model to .\\RNN13_best_model.h5\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.6905 - mae: 21.6905 - val_loss: 22.3733 - val_mae: 22.3733\n",
      "Epoch 59/200\n",
      "1708/1714 [============================>.] - ETA: 0s - loss: 21.6886 - mae: 21.6886\n",
      "Epoch 59: val_mae did not improve from 22.37332\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.6891 - mae: 21.6891 - val_loss: 22.4984 - val_mae: 22.4984\n",
      "Epoch 60/200\n",
      "1712/1714 [============================>.] - ETA: 0s - loss: 21.6769 - mae: 21.6769\n",
      "Epoch 60: val_mae did not improve from 22.37332\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.6774 - mae: 21.6774 - val_loss: 22.3860 - val_mae: 22.3860\n",
      "Epoch 61/200\n",
      "1714/1714 [==============================] - ETA: 0s - loss: 21.6836 - mae: 21.6836\n",
      "Epoch 61: val_mae did not improve from 22.37332\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.6836 - mae: 21.6836 - val_loss: 22.6496 - val_mae: 22.6496\n",
      "Epoch 62/200\n",
      "1713/1714 [============================>.] - ETA: 0s - loss: 21.6749 - mae: 21.6749\n",
      "Epoch 62: val_mae did not improve from 22.37332\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.6749 - mae: 21.6749 - val_loss: 23.2227 - val_mae: 23.2227\n",
      "Epoch 63/200\n",
      "1710/1714 [============================>.] - ETA: 0s - loss: 21.6706 - mae: 21.6706\n",
      "Epoch 63: val_mae did not improve from 22.37332\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.6703 - mae: 21.6703 - val_loss: 22.3987 - val_mae: 22.3987\n",
      "Epoch 64/200\n",
      "1713/1714 [============================>.] - ETA: 0s - loss: 21.6676 - mae: 21.6676\n",
      "Epoch 64: val_mae did not improve from 22.37332\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.6675 - mae: 21.6675 - val_loss: 22.5440 - val_mae: 22.5440\n",
      "Epoch 65/200\n",
      "1713/1714 [============================>.] - ETA: 0s - loss: 21.6576 - mae: 21.6576\n",
      "Epoch 65: val_mae did not improve from 22.37332\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.6575 - mae: 21.6575 - val_loss: 22.8692 - val_mae: 22.8692\n",
      "Epoch 66/200\n",
      "1713/1714 [============================>.] - ETA: 0s - loss: 21.6554 - mae: 21.6554\n",
      "Epoch 66: val_mae did not improve from 22.37332\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.6555 - mae: 21.6555 - val_loss: 22.5404 - val_mae: 22.5404\n",
      "Epoch 67/200\n",
      "1710/1714 [============================>.] - ETA: 0s - loss: 21.6613 - mae: 21.6613\n",
      "Epoch 67: val_mae did not improve from 22.37332\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.6609 - mae: 21.6609 - val_loss: 22.4660 - val_mae: 22.4660\n",
      "Epoch 68/200\n",
      "1712/1714 [============================>.] - ETA: 0s - loss: 21.6622 - mae: 21.6622\n",
      "Epoch 68: val_mae did not improve from 22.37332\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.6622 - mae: 21.6622 - val_loss: 22.5330 - val_mae: 22.5330\n",
      "Epoch 69/200\n",
      "1710/1714 [============================>.] - ETA: 0s - loss: 21.6464 - mae: 21.6464\n",
      "Epoch 69: val_mae did not improve from 22.37332\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.6466 - mae: 21.6466 - val_loss: 22.9785 - val_mae: 22.9785\n",
      "Epoch 70/200\n",
      "1712/1714 [============================>.] - ETA: 0s - loss: 21.6508 - mae: 21.6508\n",
      "Epoch 70: val_mae did not improve from 22.37332\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.6504 - mae: 21.6504 - val_loss: 22.4136 - val_mae: 22.4136\n",
      "Epoch 71/200\n",
      "1706/1714 [============================>.] - ETA: 0s - loss: 21.6540 - mae: 21.6540\n",
      "Epoch 71: val_mae did not improve from 22.37332\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.6527 - mae: 21.6527 - val_loss: 22.8467 - val_mae: 22.8467\n",
      "Epoch 72/200\n",
      "1708/1714 [============================>.] - ETA: 0s - loss: 21.6373 - mae: 21.6373\n",
      "Epoch 72: val_mae did not improve from 22.37332\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.6365 - mae: 21.6365 - val_loss: 22.7347 - val_mae: 22.7347\n",
      "Epoch 73/200\n",
      "1709/1714 [============================>.] - ETA: 0s - loss: 21.6352 - mae: 21.6352\n",
      "Epoch 73: val_mae did not improve from 22.37332\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.6349 - mae: 21.6349 - val_loss: 22.4708 - val_mae: 22.4708\n",
      "Epoch 74/200\n",
      "1711/1714 [============================>.] - ETA: 0s - loss: 21.6368 - mae: 21.6368\n",
      "Epoch 74: val_mae did not improve from 22.37332\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.6374 - mae: 21.6374 - val_loss: 22.4230 - val_mae: 22.4230\n",
      "Epoch 75/200\n",
      "1710/1714 [============================>.] - ETA: 0s - loss: 21.6310 - mae: 21.6310\n",
      "Epoch 75: val_mae did not improve from 22.37332\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.6312 - mae: 21.6312 - val_loss: 22.9736 - val_mae: 22.9736\n",
      "Epoch 76/200\n",
      "1706/1714 [============================>.] - ETA: 0s - loss: 21.6244 - mae: 21.6244\n",
      "Epoch 76: val_mae did not improve from 22.37332\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.6242 - mae: 21.6242 - val_loss: 22.4927 - val_mae: 22.4927\n",
      "Epoch 77/200\n",
      "1712/1714 [============================>.] - ETA: 0s - loss: 21.6309 - mae: 21.6309\n",
      "Epoch 77: val_mae did not improve from 22.37332\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.6311 - mae: 21.6311 - val_loss: 22.5967 - val_mae: 22.5967\n",
      "Epoch 78/200\n",
      "1711/1714 [============================>.] - ETA: 0s - loss: 21.6250 - mae: 21.6250\n",
      "Epoch 78: val_mae did not improve from 22.37332\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.6242 - mae: 21.6242 - val_loss: 22.3991 - val_mae: 22.3991\n",
      "Epoch 79/200\n",
      "1709/1714 [============================>.] - ETA: 0s - loss: 21.6204 - mae: 21.6204\n",
      "Epoch 79: val_mae did not improve from 22.37332\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.6200 - mae: 21.6200 - val_loss: 22.5707 - val_mae: 22.5707\n",
      "Epoch 80/200\n",
      "1710/1714 [============================>.] - ETA: 0s - loss: 21.6166 - mae: 21.6166\n",
      "Epoch 80: val_mae improved from 22.37332 to 22.34626, saving model to .\\RNN13_best_model.h5\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.6163 - mae: 21.6163 - val_loss: 22.3463 - val_mae: 22.3463\n",
      "Epoch 81/200\n",
      "1711/1714 [============================>.] - ETA: 0s - loss: 21.6304 - mae: 21.6304\n",
      "Epoch 81: val_mae did not improve from 22.34626\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.6304 - mae: 21.6304 - val_loss: 22.9452 - val_mae: 22.9452\n",
      "Epoch 82/200\n",
      "1712/1714 [============================>.] - ETA: 0s - loss: 21.6074 - mae: 21.6074\n",
      "Epoch 82: val_mae did not improve from 22.34626\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.6076 - mae: 21.6076 - val_loss: 22.4111 - val_mae: 22.4111\n",
      "Epoch 83/200\n",
      "1708/1714 [============================>.] - ETA: 0s - loss: 21.6036 - mae: 21.6036\n",
      "Epoch 83: val_mae did not improve from 22.34626\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.6040 - mae: 21.6040 - val_loss: 22.9031 - val_mae: 22.9031\n",
      "Epoch 84/200\n",
      "1711/1714 [============================>.] - ETA: 0s - loss: 21.6047 - mae: 21.6047\n",
      "Epoch 84: val_mae did not improve from 22.34626\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.6043 - mae: 21.6043 - val_loss: 23.0294 - val_mae: 23.0294\n",
      "Epoch 85/200\n",
      "1708/1714 [============================>.] - ETA: 0s - loss: 21.6059 - mae: 21.6059\n",
      "Epoch 85: val_mae did not improve from 22.34626\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.6055 - mae: 21.6055 - val_loss: 22.7497 - val_mae: 22.7497\n",
      "Epoch 86/200\n",
      "1708/1714 [============================>.] - ETA: 0s - loss: 21.5992 - mae: 21.5992\n",
      "Epoch 86: val_mae improved from 22.34626 to 22.31105, saving model to .\\RNN13_best_model.h5\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.5992 - mae: 21.5992 - val_loss: 22.3111 - val_mae: 22.3111\n",
      "Epoch 87/200\n",
      "1712/1714 [============================>.] - ETA: 0s - loss: 21.5926 - mae: 21.5926\n",
      "Epoch 87: val_mae did not improve from 22.31105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.5924 - mae: 21.5924 - val_loss: 22.8453 - val_mae: 22.8453\n",
      "Epoch 88/200\n",
      "1714/1714 [==============================] - ETA: 0s - loss: 21.5886 - mae: 21.5886\n",
      "Epoch 88: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.5886 - mae: 21.5886 - val_loss: 23.0634 - val_mae: 23.0634\n",
      "Epoch 89/200\n",
      "1714/1714 [==============================] - ETA: 0s - loss: 21.5852 - mae: 21.5852\n",
      "Epoch 89: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.5852 - mae: 21.5852 - val_loss: 22.5215 - val_mae: 22.5215\n",
      "Epoch 90/200\n",
      "1711/1714 [============================>.] - ETA: 0s - loss: 21.5816 - mae: 21.5816\n",
      "Epoch 90: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.5817 - mae: 21.5817 - val_loss: 22.3138 - val_mae: 22.3138\n",
      "Epoch 91/200\n",
      "1714/1714 [==============================] - ETA: 0s - loss: 21.5889 - mae: 21.5889\n",
      "Epoch 91: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.5889 - mae: 21.5889 - val_loss: 22.7471 - val_mae: 22.7471\n",
      "Epoch 92/200\n",
      "1708/1714 [============================>.] - ETA: 0s - loss: 21.5776 - mae: 21.5776\n",
      "Epoch 92: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.5772 - mae: 21.5772 - val_loss: 22.7450 - val_mae: 22.7450\n",
      "Epoch 93/200\n",
      "1709/1714 [============================>.] - ETA: 0s - loss: 21.5766 - mae: 21.5766\n",
      "Epoch 93: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.5769 - mae: 21.5769 - val_loss: 22.3141 - val_mae: 22.3141\n",
      "Epoch 94/200\n",
      "1708/1714 [============================>.] - ETA: 0s - loss: 21.5711 - mae: 21.5711\n",
      "Epoch 94: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.5712 - mae: 21.5712 - val_loss: 22.8801 - val_mae: 22.8801\n",
      "Epoch 95/200\n",
      "1711/1714 [============================>.] - ETA: 0s - loss: 21.5738 - mae: 21.5738\n",
      "Epoch 95: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.5744 - mae: 21.5744 - val_loss: 22.5957 - val_mae: 22.5957\n",
      "Epoch 96/200\n",
      "1707/1714 [============================>.] - ETA: 0s - loss: 21.5604 - mae: 21.5604\n",
      "Epoch 96: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.5600 - mae: 21.5600 - val_loss: 22.8434 - val_mae: 22.8434\n",
      "Epoch 97/200\n",
      "1713/1714 [============================>.] - ETA: 0s - loss: 21.5688 - mae: 21.5688\n",
      "Epoch 97: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.5687 - mae: 21.5687 - val_loss: 23.1907 - val_mae: 23.1907\n",
      "Epoch 98/200\n",
      "1713/1714 [============================>.] - ETA: 0s - loss: 21.5594 - mae: 21.5594\n",
      "Epoch 98: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.5595 - mae: 21.5595 - val_loss: 23.3707 - val_mae: 23.3707\n",
      "Epoch 99/200\n",
      "1709/1714 [============================>.] - ETA: 0s - loss: 21.5630 - mae: 21.5630\n",
      "Epoch 99: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.5632 - mae: 21.5632 - val_loss: 22.9973 - val_mae: 22.9973\n",
      "Epoch 100/200\n",
      "1713/1714 [============================>.] - ETA: 0s - loss: 21.6121 - mae: 21.6121\n",
      "Epoch 100: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.6120 - mae: 21.6120 - val_loss: 22.5213 - val_mae: 22.5213\n",
      "Epoch 101/200\n",
      "1708/1714 [============================>.] - ETA: 0s - loss: 21.5559 - mae: 21.5559\n",
      "Epoch 101: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.5561 - mae: 21.5561 - val_loss: 22.4574 - val_mae: 22.4574\n",
      "Epoch 102/200\n",
      "1710/1714 [============================>.] - ETA: 0s - loss: 21.5545 - mae: 21.5545\n",
      "Epoch 102: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.5546 - mae: 21.5546 - val_loss: 22.9782 - val_mae: 22.9782\n",
      "Epoch 103/200\n",
      "1714/1714 [==============================] - ETA: 0s - loss: 21.5509 - mae: 21.5509\n",
      "Epoch 103: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.5509 - mae: 21.5509 - val_loss: 22.9110 - val_mae: 22.9110\n",
      "Epoch 104/200\n",
      "1714/1714 [==============================] - ETA: 0s - loss: 21.5460 - mae: 21.5460\n",
      "Epoch 104: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.5460 - mae: 21.5460 - val_loss: 22.6484 - val_mae: 22.6484\n",
      "Epoch 105/200\n",
      "1712/1714 [============================>.] - ETA: 0s - loss: 21.5449 - mae: 21.5449\n",
      "Epoch 105: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.5448 - mae: 21.5448 - val_loss: 22.9973 - val_mae: 22.9973\n",
      "Epoch 106/200\n",
      "1714/1714 [==============================] - ETA: 0s - loss: 21.5449 - mae: 21.5449\n",
      "Epoch 106: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.5449 - mae: 21.5449 - val_loss: 22.4215 - val_mae: 22.4215\n",
      "Epoch 107/200\n",
      "1711/1714 [============================>.] - ETA: 0s - loss: 21.5349 - mae: 21.5349\n",
      "Epoch 107: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.5345 - mae: 21.5345 - val_loss: 23.3561 - val_mae: 23.3561\n",
      "Epoch 108/200\n",
      "1708/1714 [============================>.] - ETA: 0s - loss: 21.5360 - mae: 21.5360\n",
      "Epoch 108: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.5357 - mae: 21.5357 - val_loss: 22.9488 - val_mae: 22.9488\n",
      "Epoch 109/200\n",
      "1707/1714 [============================>.] - ETA: 0s - loss: 21.5343 - mae: 21.5343\n",
      "Epoch 109: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.5336 - mae: 21.5336 - val_loss: 23.1767 - val_mae: 23.1767\n",
      "Epoch 110/200\n",
      "1708/1714 [============================>.] - ETA: 0s - loss: 21.5273 - mae: 21.5273\n",
      "Epoch 110: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.5283 - mae: 21.5283 - val_loss: 22.4331 - val_mae: 22.4331\n",
      "Epoch 111/200\n",
      "1709/1714 [============================>.] - ETA: 0s - loss: 21.5309 - mae: 21.5309\n",
      "Epoch 111: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.5305 - mae: 21.5305 - val_loss: 22.6476 - val_mae: 22.6476\n",
      "Epoch 112/200\n",
      "1711/1714 [============================>.] - ETA: 0s - loss: 21.5233 - mae: 21.5233\n",
      "Epoch 112: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.5232 - mae: 21.5232 - val_loss: 22.3914 - val_mae: 22.3914\n",
      "Epoch 113/200\n",
      "1712/1714 [============================>.] - ETA: 0s - loss: 21.5299 - mae: 21.5299\n",
      "Epoch 113: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.5294 - mae: 21.5294 - val_loss: 22.9923 - val_mae: 22.9923\n",
      "Epoch 114/200\n",
      "1709/1714 [============================>.] - ETA: 0s - loss: 21.5258 - mae: 21.5258\n",
      "Epoch 114: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.5265 - mae: 21.5265 - val_loss: 22.9555 - val_mae: 22.9555\n",
      "Epoch 115/200\n",
      "1710/1714 [============================>.] - ETA: 0s - loss: 21.5230 - mae: 21.5230\n",
      "Epoch 115: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.5231 - mae: 21.5231 - val_loss: 22.5539 - val_mae: 22.5539\n",
      "Epoch 116/200\n",
      "1711/1714 [============================>.] - ETA: 0s - loss: 21.5145 - mae: 21.5145\n",
      "Epoch 116: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.5140 - mae: 21.5140 - val_loss: 22.4349 - val_mae: 22.4349\n",
      "Epoch 117/200\n",
      "1714/1714 [==============================] - ETA: 0s - loss: 21.5122 - mae: 21.5122\n",
      "Epoch 117: val_mae did not improve from 22.31105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.5122 - mae: 21.5122 - val_loss: 23.3827 - val_mae: 23.3827\n",
      "Epoch 118/200\n",
      "1713/1714 [============================>.] - ETA: 0s - loss: 21.5160 - mae: 21.5160\n",
      "Epoch 118: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.5157 - mae: 21.5157 - val_loss: 22.3658 - val_mae: 22.3658\n",
      "Epoch 119/200\n",
      "1712/1714 [============================>.] - ETA: 0s - loss: 21.5138 - mae: 21.5138\n",
      "Epoch 119: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.5140 - mae: 21.5140 - val_loss: 22.9212 - val_mae: 22.9212\n",
      "Epoch 120/200\n",
      "1713/1714 [============================>.] - ETA: 0s - loss: 21.5147 - mae: 21.5147\n",
      "Epoch 120: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.5146 - mae: 21.5146 - val_loss: 22.6234 - val_mae: 22.6234\n",
      "Epoch 121/200\n",
      "1710/1714 [============================>.] - ETA: 0s - loss: 21.4950 - mae: 21.4950\n",
      "Epoch 121: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4956 - mae: 21.4956 - val_loss: 22.5535 - val_mae: 22.5535\n",
      "Epoch 122/200\n",
      "1709/1714 [============================>.] - ETA: 0s - loss: 21.5021 - mae: 21.5021\n",
      "Epoch 122: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.5020 - mae: 21.5020 - val_loss: 22.4333 - val_mae: 22.4333\n",
      "Epoch 123/200\n",
      "1711/1714 [============================>.] - ETA: 0s - loss: 21.5040 - mae: 21.5040\n",
      "Epoch 123: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.5046 - mae: 21.5046 - val_loss: 22.8566 - val_mae: 22.8566\n",
      "Epoch 124/200\n",
      "1712/1714 [============================>.] - ETA: 0s - loss: 21.4976 - mae: 21.4976\n",
      "Epoch 124: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4976 - mae: 21.4976 - val_loss: 22.4014 - val_mae: 22.4014\n",
      "Epoch 125/200\n",
      "1714/1714 [==============================] - ETA: 0s - loss: 21.5029 - mae: 21.5029\n",
      "Epoch 125: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.5029 - mae: 21.5029 - val_loss: 22.8402 - val_mae: 22.8402\n",
      "Epoch 126/200\n",
      "1710/1714 [============================>.] - ETA: 0s - loss: 21.4952 - mae: 21.4952\n",
      "Epoch 126: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4944 - mae: 21.4944 - val_loss: 22.5916 - val_mae: 22.5916\n",
      "Epoch 127/200\n",
      "1708/1714 [============================>.] - ETA: 0s - loss: 21.4956 - mae: 21.4956\n",
      "Epoch 127: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 15s 9ms/step - loss: 21.4949 - mae: 21.4949 - val_loss: 22.7121 - val_mae: 22.7121\n",
      "Epoch 128/200\n",
      "1711/1714 [============================>.] - ETA: 0s - loss: 21.4931 - mae: 21.4931\n",
      "Epoch 128: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4930 - mae: 21.4930 - val_loss: 22.8599 - val_mae: 22.8599\n",
      "Epoch 129/200\n",
      "1713/1714 [============================>.] - ETA: 0s - loss: 21.4898 - mae: 21.4898\n",
      "Epoch 129: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4898 - mae: 21.4898 - val_loss: 23.1881 - val_mae: 23.1881\n",
      "Epoch 130/200\n",
      "1714/1714 [==============================] - ETA: 0s - loss: 21.4854 - mae: 21.4854\n",
      "Epoch 130: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4854 - mae: 21.4854 - val_loss: 22.6310 - val_mae: 22.6310\n",
      "Epoch 131/200\n",
      "1711/1714 [============================>.] - ETA: 0s - loss: 21.4815 - mae: 21.4815\n",
      "Epoch 131: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4810 - mae: 21.4810 - val_loss: 22.6594 - val_mae: 22.6594\n",
      "Epoch 132/200\n",
      "1714/1714 [==============================] - ETA: 0s - loss: 21.4798 - mae: 21.4798\n",
      "Epoch 132: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4798 - mae: 21.4798 - val_loss: 22.5851 - val_mae: 22.5851\n",
      "Epoch 133/200\n",
      "1709/1714 [============================>.] - ETA: 0s - loss: 21.4837 - mae: 21.4837\n",
      "Epoch 133: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4833 - mae: 21.4833 - val_loss: 22.6119 - val_mae: 22.6119\n",
      "Epoch 134/200\n",
      "1714/1714 [==============================] - ETA: 0s - loss: 21.4840 - mae: 21.4840\n",
      "Epoch 134: val_mae did not improve from 22.31105\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4840 - mae: 21.4840 - val_loss: 22.4077 - val_mae: 22.4077\n",
      "Epoch 135/200\n",
      "1710/1714 [============================>.] - ETA: 0s - loss: 21.4773 - mae: 21.4773\n",
      "Epoch 135: val_mae improved from 22.31105 to 22.26526, saving model to .\\RNN13_best_model.h5\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4776 - mae: 21.4776 - val_loss: 22.2653 - val_mae: 22.2653\n",
      "Epoch 136/200\n",
      "1711/1714 [============================>.] - ETA: 0s - loss: 21.4757 - mae: 21.4757\n",
      "Epoch 136: val_mae did not improve from 22.26526\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4755 - mae: 21.4755 - val_loss: 23.1503 - val_mae: 23.1503\n",
      "Epoch 137/200\n",
      "1710/1714 [============================>.] - ETA: 0s - loss: 21.4727 - mae: 21.4727\n",
      "Epoch 137: val_mae did not improve from 22.26526\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4729 - mae: 21.4729 - val_loss: 22.4156 - val_mae: 22.4156\n",
      "Epoch 138/200\n",
      "1706/1714 [============================>.] - ETA: 0s - loss: 21.4728 - mae: 21.4728\n",
      "Epoch 138: val_mae did not improve from 22.26526\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4730 - mae: 21.4730 - val_loss: 22.7344 - val_mae: 22.7344\n",
      "Epoch 139/200\n",
      "1708/1714 [============================>.] - ETA: 0s - loss: 21.4683 - mae: 21.4683\n",
      "Epoch 139: val_mae did not improve from 22.26526\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4688 - mae: 21.4688 - val_loss: 22.8248 - val_mae: 22.8248\n",
      "Epoch 140/200\n",
      "1711/1714 [============================>.] - ETA: 0s - loss: 21.4755 - mae: 21.4755\n",
      "Epoch 140: val_mae did not improve from 22.26526\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4753 - mae: 21.4753 - val_loss: 22.3939 - val_mae: 22.3939\n",
      "Epoch 141/200\n",
      "1709/1714 [============================>.] - ETA: 0s - loss: 21.4698 - mae: 21.4698\n",
      "Epoch 141: val_mae did not improve from 22.26526\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4692 - mae: 21.4692 - val_loss: 22.8612 - val_mae: 22.8612\n",
      "Epoch 142/200\n",
      "1709/1714 [============================>.] - ETA: 0s - loss: 21.4681 - mae: 21.4681\n",
      "Epoch 142: val_mae did not improve from 22.26526\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4677 - mae: 21.4677 - val_loss: 22.4977 - val_mae: 22.4977\n",
      "Epoch 143/200\n",
      "1713/1714 [============================>.] - ETA: 0s - loss: 21.4624 - mae: 21.4624\n",
      "Epoch 143: val_mae did not improve from 22.26526\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4622 - mae: 21.4622 - val_loss: 22.6088 - val_mae: 22.6088\n",
      "Epoch 144/200\n",
      "1708/1714 [============================>.] - ETA: 0s - loss: 21.4654 - mae: 21.4654\n",
      "Epoch 144: val_mae did not improve from 22.26526\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4653 - mae: 21.4653 - val_loss: 22.5248 - val_mae: 22.5248\n",
      "Epoch 145/200\n",
      "1708/1714 [============================>.] - ETA: 0s - loss: 21.4598 - mae: 21.4598\n",
      "Epoch 145: val_mae did not improve from 22.26526\n",
      "1714/1714 [==============================] - 15s 8ms/step - loss: 21.4592 - mae: 21.4592 - val_loss: 23.0991 - val_mae: 23.0991\n",
      "Epoch 146/200\n",
      "1712/1714 [============================>.] - ETA: 0s - loss: 21.4530 - mae: 21.4530\n",
      "Epoch 146: val_mae did not improve from 22.26526\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4531 - mae: 21.4531 - val_loss: 22.7249 - val_mae: 22.7249\n",
      "Epoch 147/200\n",
      "1714/1714 [==============================] - ETA: 0s - loss: 21.4596 - mae: 21.4596\n",
      "Epoch 147: val_mae did not improve from 22.26526\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4596 - mae: 21.4596 - val_loss: 22.5888 - val_mae: 22.5888\n",
      "Epoch 148/200\n",
      "1711/1714 [============================>.] - ETA: 0s - loss: 21.4553 - mae: 21.4553\n",
      "Epoch 148: val_mae did not improve from 22.26526\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4551 - mae: 21.4551 - val_loss: 22.9940 - val_mae: 22.9940\n",
      "Epoch 149/200\n",
      "1713/1714 [============================>.] - ETA: 0s - loss: 21.4556 - mae: 21.4556\n",
      "Epoch 149: val_mae did not improve from 22.26526\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4554 - mae: 21.4554 - val_loss: 22.8707 - val_mae: 22.8707\n",
      "Epoch 150/200\n",
      "1711/1714 [============================>.] - ETA: 0s - loss: 21.4550 - mae: 21.4550\n",
      "Epoch 150: val_mae did not improve from 22.26526\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4550 - mae: 21.4550 - val_loss: 22.3706 - val_mae: 22.3706\n",
      "Epoch 151/200\n",
      "1713/1714 [============================>.] - ETA: 0s - loss: 21.4559 - mae: 21.4559\n",
      "Epoch 151: val_mae did not improve from 22.26526\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4558 - mae: 21.4558 - val_loss: 22.6554 - val_mae: 22.6554\n",
      "Epoch 152/200\n",
      "1711/1714 [============================>.] - ETA: 0s - loss: 21.4579 - mae: 21.4579\n",
      "Epoch 152: val_mae did not improve from 22.26526\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4582 - mae: 21.4582 - val_loss: 23.0375 - val_mae: 23.0375\n",
      "Epoch 153/200\n",
      "1711/1714 [============================>.] - ETA: 0s - loss: 21.4431 - mae: 21.4431\n",
      "Epoch 153: val_mae did not improve from 22.26526\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4435 - mae: 21.4435 - val_loss: 22.5444 - val_mae: 22.5444\n",
      "Epoch 154/200\n",
      "1707/1714 [============================>.] - ETA: 0s - loss: 21.4494 - mae: 21.4494\n",
      "Epoch 154: val_mae did not improve from 22.26526\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4497 - mae: 21.4497 - val_loss: 23.0360 - val_mae: 23.0360\n",
      "Epoch 155/200\n",
      "1711/1714 [============================>.] - ETA: 0s - loss: 21.4536 - mae: 21.4536\n",
      "Epoch 155: val_mae did not improve from 22.26526\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4537 - mae: 21.4537 - val_loss: 23.0801 - val_mae: 23.0801\n",
      "Epoch 156/200\n",
      "1707/1714 [============================>.] - ETA: 0s - loss: 21.4409 - mae: 21.4409\n",
      "Epoch 156: val_mae did not improve from 22.26526\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4410 - mae: 21.4410 - val_loss: 22.6463 - val_mae: 22.6463\n",
      "Epoch 157/200\n",
      "1710/1714 [============================>.] - ETA: 0s - loss: 21.4461 - mae: 21.4461\n",
      "Epoch 157: val_mae improved from 22.26526 to 22.25155, saving model to .\\RNN13_best_model.h5\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4459 - mae: 21.4459 - val_loss: 22.2516 - val_mae: 22.2516\n",
      "Epoch 158/200\n",
      "1714/1714 [==============================] - ETA: 0s - loss: 21.4369 - mae: 21.4369\n",
      "Epoch 158: val_mae did not improve from 22.25155\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4369 - mae: 21.4369 - val_loss: 22.3511 - val_mae: 22.3511\n",
      "Epoch 159/200\n",
      "1712/1714 [============================>.] - ETA: 0s - loss: 21.4317 - mae: 21.4317\n",
      "Epoch 159: val_mae did not improve from 22.25155\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4316 - mae: 21.4316 - val_loss: 22.5587 - val_mae: 22.5587\n",
      "Epoch 160/200\n",
      "1713/1714 [============================>.] - ETA: 0s - loss: 21.4464 - mae: 21.4464\n",
      "Epoch 160: val_mae did not improve from 22.25155\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4463 - mae: 21.4463 - val_loss: 22.7125 - val_mae: 22.7125\n",
      "Epoch 161/200\n",
      "1711/1714 [============================>.] - ETA: 0s - loss: 21.4357 - mae: 21.4357\n",
      "Epoch 161: val_mae did not improve from 22.25155\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4359 - mae: 21.4359 - val_loss: 22.7937 - val_mae: 22.7937\n",
      "Epoch 162/200\n",
      "1713/1714 [============================>.] - ETA: 0s - loss: 21.4335 - mae: 21.4335\n",
      "Epoch 162: val_mae did not improve from 22.25155\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4335 - mae: 21.4335 - val_loss: 23.0558 - val_mae: 23.0558\n",
      "Epoch 163/200\n",
      "1714/1714 [==============================] - ETA: 0s - loss: 21.4334 - mae: 21.4334\n",
      "Epoch 163: val_mae did not improve from 22.25155\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4334 - mae: 21.4334 - val_loss: 22.9379 - val_mae: 22.9379\n",
      "Epoch 164/200\n",
      "1710/1714 [============================>.] - ETA: 0s - loss: 21.4348 - mae: 21.4348\n",
      "Epoch 164: val_mae did not improve from 22.25155\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4349 - mae: 21.4349 - val_loss: 22.6518 - val_mae: 22.6518\n",
      "Epoch 165/200\n",
      "1713/1714 [============================>.] - ETA: 0s - loss: 21.4246 - mae: 21.4246\n",
      "Epoch 165: val_mae did not improve from 22.25155\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4245 - mae: 21.4245 - val_loss: 22.4421 - val_mae: 22.4421\n",
      "Epoch 166/200\n",
      "1710/1714 [============================>.] - ETA: 0s - loss: 21.4306 - mae: 21.4306\n",
      "Epoch 166: val_mae did not improve from 22.25155\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4301 - mae: 21.4301 - val_loss: 23.2251 - val_mae: 23.2251\n",
      "Epoch 167/200\n",
      "1708/1714 [============================>.] - ETA: 0s - loss: 21.4310 - mae: 21.4310\n",
      "Epoch 167: val_mae did not improve from 22.25155\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4308 - mae: 21.4308 - val_loss: 22.5177 - val_mae: 22.5177\n",
      "Epoch 168/200\n",
      "1710/1714 [============================>.] - ETA: 0s - loss: 21.4201 - mae: 21.4201\n",
      "Epoch 168: val_mae did not improve from 22.25155\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4205 - mae: 21.4205 - val_loss: 22.4518 - val_mae: 22.4518\n",
      "Epoch 169/200\n",
      "1711/1714 [============================>.] - ETA: 0s - loss: 21.4196 - mae: 21.4196\n",
      "Epoch 169: val_mae did not improve from 22.25155\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4194 - mae: 21.4194 - val_loss: 22.4457 - val_mae: 22.4457\n",
      "Epoch 170/200\n",
      "1706/1714 [============================>.] - ETA: 0s - loss: 21.4221 - mae: 21.4221\n",
      "Epoch 170: val_mae did not improve from 22.25155\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4226 - mae: 21.4226 - val_loss: 23.1819 - val_mae: 23.1819\n",
      "Epoch 171/200\n",
      "1708/1714 [============================>.] - ETA: 0s - loss: 21.4205 - mae: 21.4205\n",
      "Epoch 171: val_mae did not improve from 22.25155\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4208 - mae: 21.4208 - val_loss: 22.6484 - val_mae: 22.6484\n",
      "Epoch 172/200\n",
      "1706/1714 [============================>.] - ETA: 0s - loss: 21.4172 - mae: 21.4172\n",
      "Epoch 172: val_mae did not improve from 22.25155\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4174 - mae: 21.4174 - val_loss: 22.6760 - val_mae: 22.6760\n",
      "Epoch 173/200\n",
      "1710/1714 [============================>.] - ETA: 0s - loss: 21.4201 - mae: 21.4201\n",
      "Epoch 173: val_mae did not improve from 22.25155\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4195 - mae: 21.4195 - val_loss: 22.6942 - val_mae: 22.6942\n",
      "Epoch 174/200\n",
      "1708/1714 [============================>.] - ETA: 0s - loss: 21.4156 - mae: 21.4156\n",
      "Epoch 174: val_mae did not improve from 22.25155\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4160 - mae: 21.4160 - val_loss: 22.4260 - val_mae: 22.4260\n",
      "Epoch 175/200\n",
      "1709/1714 [============================>.] - ETA: 0s - loss: 21.4142 - mae: 21.4142\n",
      "Epoch 175: val_mae did not improve from 22.25155\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4142 - mae: 21.4142 - val_loss: 22.5882 - val_mae: 22.5882\n",
      "Epoch 176/200\n",
      "1709/1714 [============================>.] - ETA: 0s - loss: 21.4109 - mae: 21.4109\n",
      "Epoch 176: val_mae did not improve from 22.25155\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4115 - mae: 21.4115 - val_loss: 22.3368 - val_mae: 22.3368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177/200\n",
      "1707/1714 [============================>.] - ETA: 0s - loss: 21.4161 - mae: 21.4161\n",
      "Epoch 177: val_mae did not improve from 22.25155\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4160 - mae: 21.4160 - val_loss: 22.4577 - val_mae: 22.4577\n",
      "Epoch 178/200\n",
      "1714/1714 [==============================] - ETA: 0s - loss: 21.4030 - mae: 21.4030\n",
      "Epoch 178: val_mae did not improve from 22.25155\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4030 - mae: 21.4030 - val_loss: 22.5383 - val_mae: 22.5383\n",
      "Epoch 179/200\n",
      "1711/1714 [============================>.] - ETA: 0s - loss: 21.4092 - mae: 21.4092\n",
      "Epoch 179: val_mae did not improve from 22.25155\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4092 - mae: 21.4092 - val_loss: 22.9269 - val_mae: 22.9269\n",
      "Epoch 180/200\n",
      "1713/1714 [============================>.] - ETA: 0s - loss: 21.4093 - mae: 21.4093\n",
      "Epoch 180: val_mae did not improve from 22.25155\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4091 - mae: 21.4091 - val_loss: 22.7667 - val_mae: 22.7667\n",
      "Epoch 181/200\n",
      "1714/1714 [==============================] - ETA: 0s - loss: 21.4072 - mae: 21.4072\n",
      "Epoch 181: val_mae did not improve from 22.25155\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4072 - mae: 21.4072 - val_loss: 22.5734 - val_mae: 22.5734\n",
      "Epoch 182/200\n",
      "1709/1714 [============================>.] - ETA: 0s - loss: 21.4047 - mae: 21.4047\n",
      "Epoch 182: val_mae improved from 22.25155 to 22.24704, saving model to .\\RNN13_best_model.h5\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4061 - mae: 21.4061 - val_loss: 22.2470 - val_mae: 22.2470\n",
      "Epoch 183/200\n",
      "1708/1714 [============================>.] - ETA: 0s - loss: 21.3965 - mae: 21.3965\n",
      "Epoch 183: val_mae did not improve from 22.24704\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.3963 - mae: 21.3963 - val_loss: 23.7836 - val_mae: 23.7836\n",
      "Epoch 184/200\n",
      "1711/1714 [============================>.] - ETA: 0s - loss: 21.3999 - mae: 21.3999\n",
      "Epoch 184: val_mae did not improve from 22.24704\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4000 - mae: 21.4000 - val_loss: 23.3093 - val_mae: 23.3093\n",
      "Epoch 185/200\n",
      "1712/1714 [============================>.] - ETA: 0s - loss: 21.3928 - mae: 21.3928\n",
      "Epoch 185: val_mae did not improve from 22.24704\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.3929 - mae: 21.3929 - val_loss: 22.7788 - val_mae: 22.7788\n",
      "Epoch 186/200\n",
      "1708/1714 [============================>.] - ETA: 0s - loss: 21.4012 - mae: 21.4012\n",
      "Epoch 186: val_mae did not improve from 22.24704\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.4013 - mae: 21.4013 - val_loss: 22.5073 - val_mae: 22.5073\n",
      "Epoch 187/200\n",
      "1710/1714 [============================>.] - ETA: 0s - loss: 21.3999 - mae: 21.3999\n",
      "Epoch 187: val_mae did not improve from 22.24704\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.3996 - mae: 21.3996 - val_loss: 23.0109 - val_mae: 23.0109\n",
      "Epoch 188/200\n",
      "1710/1714 [============================>.] - ETA: 0s - loss: 21.3949 - mae: 21.3949\n",
      "Epoch 188: val_mae did not improve from 22.24704\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.3949 - mae: 21.3949 - val_loss: 22.4006 - val_mae: 22.4006\n",
      "Epoch 189/200\n",
      "1713/1714 [============================>.] - ETA: 0s - loss: 21.3962 - mae: 21.3962\n",
      "Epoch 189: val_mae did not improve from 22.24704\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.3962 - mae: 21.3962 - val_loss: 22.8996 - val_mae: 22.8996\n",
      "Epoch 190/200\n",
      "1709/1714 [============================>.] - ETA: 0s - loss: 21.3851 - mae: 21.3851\n",
      "Epoch 190: val_mae did not improve from 22.24704\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.3855 - mae: 21.3855 - val_loss: 23.2814 - val_mae: 23.2814\n",
      "Epoch 191/200\n",
      "1713/1714 [============================>.] - ETA: 0s - loss: 21.3911 - mae: 21.3911\n",
      "Epoch 191: val_mae did not improve from 22.24704\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.3910 - mae: 21.3910 - val_loss: 22.7390 - val_mae: 22.7390\n",
      "Epoch 192/200\n",
      "1707/1714 [============================>.] - ETA: 0s - loss: 21.3926 - mae: 21.3926\n",
      "Epoch 192: val_mae did not improve from 22.24704\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.3932 - mae: 21.3932 - val_loss: 23.3859 - val_mae: 23.3859\n",
      "Epoch 193/200\n",
      "1713/1714 [============================>.] - ETA: 0s - loss: 21.3943 - mae: 21.3943\n",
      "Epoch 193: val_mae did not improve from 22.24704\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.3944 - mae: 21.3944 - val_loss: 22.5687 - val_mae: 22.5687\n",
      "Epoch 194/200\n",
      "1709/1714 [============================>.] - ETA: 0s - loss: 21.3789 - mae: 21.3789\n",
      "Epoch 194: val_mae did not improve from 22.24704\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.3787 - mae: 21.3787 - val_loss: 22.6538 - val_mae: 22.6538\n",
      "Epoch 195/200\n",
      "1711/1714 [============================>.] - ETA: 0s - loss: 21.3857 - mae: 21.3857\n",
      "Epoch 195: val_mae did not improve from 22.24704\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.3863 - mae: 21.3863 - val_loss: 23.2549 - val_mae: 23.2549\n",
      "Epoch 196/200\n",
      "1710/1714 [============================>.] - ETA: 0s - loss: 21.3882 - mae: 21.3882\n",
      "Epoch 196: val_mae did not improve from 22.24704\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.3883 - mae: 21.3883 - val_loss: 22.8633 - val_mae: 22.8633\n",
      "Epoch 197/200\n",
      "1710/1714 [============================>.] - ETA: 0s - loss: 21.3833 - mae: 21.3833\n",
      "Epoch 197: val_mae did not improve from 22.24704\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.3830 - mae: 21.3830 - val_loss: 22.8938 - val_mae: 22.8938\n",
      "Epoch 198/200\n",
      "1712/1714 [============================>.] - ETA: 0s - loss: 21.3964 - mae: 21.3964\n",
      "Epoch 198: val_mae did not improve from 22.24704\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.3958 - mae: 21.3958 - val_loss: 22.7373 - val_mae: 22.7373\n",
      "Epoch 199/200\n",
      "1710/1714 [============================>.] - ETA: 0s - loss: 21.3796 - mae: 21.3796\n",
      "Epoch 199: val_mae did not improve from 22.24704\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.3788 - mae: 21.3788 - val_loss: 23.3144 - val_mae: 23.3144\n",
      "Epoch 200/200\n",
      "1713/1714 [============================>.] - ETA: 0s - loss: 21.3810 - mae: 21.3810\n",
      "Epoch 200: val_mae did not improve from 22.24704\n",
      "1714/1714 [==============================] - 14s 8ms/step - loss: 21.3810 - mae: 21.3810 - val_loss: 22.5728 - val_mae: 22.5728\n"
     ]
    }
   ],
   "source": [
    "random_seed = 15\n",
    "tf.keras.utils.set_random_seed(random_seed)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "file_path = './RNN13_best_model.h5'\n",
    "checkpoint = ModelCheckpoint(file_path,\n",
    "                            monitor = 'val_mae',\n",
    "                            verbose=1,\n",
    "                            save_best_only=True,\n",
    "                            mode='auto')  \n",
    "\n",
    "hist = model.fit(x_train, y_train, validation_data=(x_test, y_test), \n",
    "                 epochs=200, batch_size=16, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4f917e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252/252 [==============================] - 1s 3ms/step - loss: 22.2470 - mae: 22.2470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[22.247032165527344, 22.247032165527344]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN13_model = tf.keras.models.load_model('./RNN13_best_model.h5')\n",
    "RNN13_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e3d266c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264/264 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "RNN13_pred = RNN13_model.predict(submission_x)\n",
    "pd.DataFrame(RNN13_pred).to_csv('RNN13_pred.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769c7fd5",
   "metadata": {},
   "source": [
    "## # Model Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "132d200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN1_pred = pd.read_csv('./RNN1_pred.csv').drop(['Unnamed: 0'], axis=1)\n",
    "RNN3_pred = pd.read_csv('./RNN3_pred.csv').drop(['Unnamed: 0'], axis=1)\n",
    "RNN6_pred = pd.read_csv('./RNN6_pred.csv').drop(['Unnamed: 0'], axis=1)\n",
    "RNN7_pred = pd.read_csv('./RNN7_pred.csv').drop(['Unnamed: 0'], axis=1)\n",
    "RNN8_pred = pd.read_csv('./RNN8_pred.csv').drop(['Unnamed: 0'], axis=1)\n",
    "RNN9_pred = pd.read_csv('./RNN9_pred.csv').drop(['Unnamed: 0'], axis=1)\n",
    "RNN10_pred = pd.read_csv('./RNN10_pred.csv').drop(['Unnamed: 0'], axis=1)\n",
    "RNN11_pred = pd.read_csv('./RNN11_pred.csv').drop(['Unnamed: 0'], axis=1)  \n",
    "RNN12_pred = pd.read_csv('./RNN12_pred.csv').drop(['Unnamed: 0'], axis=1)  \n",
    "RNN13_pred = pd.read_csv('./RNN13_pred.csv').drop(['Unnamed: 0'], axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "26156315",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [RNN12_pred, RNN9_pred, RNN10_pred, RNN11_pred, RNN7_pred, RNN13_pred,\n",
    "         RNN8_pred, RNN6_pred, RNN3_pred, RNN1_pred] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "098b2607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mae 계산 함수\n",
    "def get_mae(pred):\n",
    "    mae = tf.keras.losses.MeanAbsoluteError()\n",
    "    res = mae(y_test[:7848], pred[:7848]).numpy()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "83d3d037",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 22.416403765458142,\n",
       " 1: 22.44698205790867,\n",
       " 2: 22.39072474532789,\n",
       " 3: 22.32834108300985,\n",
       " 4: 22.4983898411428,\n",
       " 5: 22.428699516590896,\n",
       " 6: 22.36342701209362,\n",
       " 7: 22.4357622653,\n",
       " 8: 22.63879799604464,\n",
       " 9: 22.644661477010374}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank = {}\n",
    "for no, x in enumerate(preds):\n",
    "    rank[no] = get_mae(x)\n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8ece7df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mae가 낮은 모델부터 오름차순 정렬\n",
    "rank.values\n",
    "ddd = rank.items()\n",
    "ranked_preds = sorted(ddd, key=lambda x: x[1])\n",
    "preds_sorted = []\n",
    "for i in ranked_preds:\n",
    "    preds_sorted.append(preds[i[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "21c19c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.18963503871918"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단순 평균 ensemble\n",
    "ensemble = (RNN12_pred + RNN11_pred + RNN9_pred + RNN8_pred + RNN10_pred + RNN6_pred + \n",
    "            RNN3_pred  + RNN7_pred + RNN1_pred + RNN13_pred)/10\n",
    "get_mae(ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b5e676b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18181818181818182\n",
      "0.16363636363636364\n",
      "0.14545454545454545\n",
      "0.12727272727272726\n",
      "0.10909090909090909\n",
      "0.09090909090909091\n",
      "0.07272727272727272\n",
      "0.05454545454545454\n",
      "0.03636363636363636\n",
      "0.01818181818181818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22.175341427334523"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 순위 가중치 ensemble\n",
    "new = 0\n",
    "for i, pred in enumerate(preds_sorted):\n",
    "    new += pred * (10-i)/55\n",
    "    print((10-i)/55)\n",
    "get_mae(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "90fb3873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1be4d3fd070>]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 최소 mae 찾기\n",
    "y_range = []\n",
    "x_range = range(1, 100)\n",
    "for i in x_range:\n",
    "    y_range.append(get_mae(new + i * 0.01))\n",
    "plt.plot(x_range, y_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "78b303f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.1697072703371"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mae(new + (np.argmin(y_range) + 1) * 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ef8964bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "last = new + (np.argmin(y_range) + 1) * 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f952b62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_res = pd.DataFrame(last)\n",
    "submission_res.to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
